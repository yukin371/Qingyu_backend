# AIæµå¼æ¥å£è§„èŒƒ

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
> **åˆ›å»ºæ—¶é—´**: 2025-10-21  
> **å®æ–½çŠ¶æ€**: è®¾è®¡é˜¶æ®µ

## ğŸ“‹ æ–‡æ¡£æ¦‚è¿°

æœ¬æ–‡æ¡£è§„å®šAIç”Ÿæˆæ¥å£å¿…é¡»ä½¿ç”¨æµå¼å“åº”ï¼Œä»¥é™ä½ç”¨æˆ·æ„ŸçŸ¥å»¶è¿Ÿï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚

## ğŸ¯ è®¾è®¡ç›®æ ‡

1. **å¼ºåˆ¶æµå¼**ï¼šæ‰€æœ‰AIç”Ÿæˆæ¥å£å¿…é¡»æ”¯æŒæµå¼å“åº”
2. **é™ä½å»¶è¿Ÿæ„ŸçŸ¥**ï¼šç”¨æˆ·å³æ—¶çœ‹åˆ°ç”Ÿæˆè¿‡ç¨‹
3. **å‰ç«¯å‹å¥½**ï¼šæä¾›æ ‡å‡†çš„SSE/WebSocketæ¥å£
4. **æ€§èƒ½ä¼˜åŒ–**ï¼šåˆç†çš„chunkå¤§å°å’Œæ¨é€é¢‘ç‡

---

## ä¸€ã€å¼ºåˆ¶æµå¼æ¥å£

### 1.1 æ¥å£è§„èŒƒ

```go
// âŒ ç¦æ­¢ï¼šéæµå¼æ¥å£ï¼ˆå·²åºŸå¼ƒï¼‰
func GenerateText(ctx context.Context, req *GenerateRequest) (*GenerateResponse, error)

// âœ… æ¨èï¼šæµå¼æ¥å£ï¼ˆä¸»æ¥å£ï¼‰
func GenerateTextStream(ctx context.Context, req *GenerateRequest) (<-chan *StreamChunk, error)
```

### 1.2 APIå±‚å®ç°

```go
package api

func (api *AIApi) GenerateText(c *gin.Context) {
    var req ai.GenerateRequest
    if err := c.ShouldBindJSON(&req); err != nil {
        response.Error(c, http.StatusBadRequest, "å‚æ•°é”™è¯¯", err.Error())
        return
    }
    
    // å¼ºåˆ¶ä½¿ç”¨æµå¼æ¥å£
    api.GenerateTextStream(c, &req)
}
```

---

## äºŒã€SSEå®ç°è§„èŒƒ

### 2.1 SSEå“åº”å¤´è®¾ç½®

```go
func (api *AIApi) GenerateTextStream(c *gin.Context, req *ai.GenerateRequest) {
    // 1. è®¾ç½®SSEå“åº”å¤´
    c.Header("Content-Type", "text/event-stream")
    c.Header("Cache-Control", "no-cache")
    c.Header("Connection", "keep-alive")
    c.Header("X-Accel-Buffering", "no")  // ç¦ç”¨Nginxç¼“å†²
    c.Header("Access-Control-Allow-Origin", "*")
    
    // 2. è·å–æµå¼channel
    chunkChan, err := api.proxyService.GenerateTextStream(c.Request.Context(), req)
    if err != nil {
        api.handleError(c, err)
        return
    }
    
    // 3. æµå¼æ¨é€
    c.Stream(func(w io.Writer) bool {
        select {
        case <-c.Request.Context().Done():
            // å®¢æˆ·ç«¯æ–­å¼€è¿æ¥
            return false
            
        case chunk, ok := <-chunkChan:
            if !ok {
                // channelå…³é—­
                return false
            }
            
            if chunk.Error != "" {
                // å‘é€é”™è¯¯äº‹ä»¶
                c.SSEvent("error", gin.H{
                    "error": chunk.Error,
                })
                return false
            }
            
            // å‘é€æ•°æ®äº‹ä»¶
            c.SSEvent("message", gin.H{
                "delta":   chunk.Delta,
                "isFinal": chunk.IsFinal,
            })
            
            return !chunk.IsFinal
        }
    })
}
```

### 2.2 SSEäº‹ä»¶æ ¼å¼

```
event: message
data: {"delta":"è¿™æ˜¯","isFinal":false}

event: message
data: {"delta":"ä¸€æ®µ","isFinal":false}

event: message
data: {"delta":"ç”Ÿæˆçš„","isFinal":false}

event: message
data: {"delta":"æ–‡æœ¬ã€‚","isFinal":true}
```

---

## ä¸‰ã€å‰ç«¯é›†æˆè§„èŒƒ

### 3.1 EventSourceä½¿ç”¨

```javascript
// å‰ç«¯ï¼šä½¿ç”¨EventSourceæ¥æ”¶SSE
function generateTextStream(prompt) {
    const eventSource = new EventSource(`/api/v1/ai/generate?stream=true`, {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${token}`
        },
        body: JSON.stringify({ prompt })
    });
    
    let fullText = '';
    
    eventSource.addEventListener('message', (event) => {
        const data = JSON.parse(event.data);
        
        fullText += data.delta;
        
        // å®æ—¶æ›´æ–°UI
        updateTextDisplay(fullText);
        
        if (data.isFinal) {
            eventSource.close();
            onComplete(fullText);
        }
    });
    
    eventSource.addEventListener('error', (event) => {
        const error = JSON.parse(event.data);
        console.error('ç”Ÿæˆå¤±è´¥:', error.error);
        eventSource.close();
        onError(error.error);
    });
    
    // è¶…æ—¶æ§åˆ¶
    setTimeout(() => {
        if (eventSource.readyState !== EventSource.CLOSED) {
            eventSource.close();
            onError('ç”Ÿæˆè¶…æ—¶');
        }
    }, 120000); // 2åˆ†é’Ÿè¶…æ—¶
}
```

### 3.2 Fetch APIæµå¼å¤„ç†ï¼ˆå¤‡é€‰ï¼‰

```javascript
async function generateTextStreamFetch(prompt) {
    const response = await fetch('/api/v1/ai/generate', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${token}`
        },
        body: JSON.stringify({ prompt, stream: true })
    });
    
    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    let fullText = '';
    
    while (true) {
        const { done, value } = await reader.read();
        
        if (done) break;
        
        const chunk = decoder.decode(value);
        const lines = chunk.split('\n\n');
        
        for (const line of lines) {
            if (line.startsWith('data: ')) {
                const data = JSON.parse(line.substring(6));
                fullText += data.delta;
                updateTextDisplay(fullText);
            }
        }
    }
    
    return fullText;
}
```

---

## å››ã€æ€§èƒ½ä¼˜åŒ–

### 4.1 Chunkå¤§å°æ§åˆ¶

```go
// Pythonç«¯ï¼šæ§åˆ¶chunkå¤§å°
async def generate_stream(prompt: str, model: str):
    """æµå¼ç”Ÿæˆ"""
    buffer = ""
    chunk_size = 5  # æ¯5ä¸ªå­—ç¬¦å‘é€ä¸€æ¬¡
    
    async for token in llm_client.generate_stream(prompt, model):
        buffer += token
        
        if len(buffer) >= chunk_size:
            yield StreamChunk(delta=buffer, is_final=False)
            buffer = ""
    
    # å‘é€å‰©ä½™å†…å®¹
    if buffer:
        yield StreamChunk(delta=buffer, is_final=True)
```

### 4.2 æ¨é€é¢‘ç‡æ§åˆ¶

```go
// Goç«¯ï¼šæ§åˆ¶æ¨é€é¢‘ç‡
func (s *AIProxyServiceImpl) handleStreamWithThrottle(
    ctx context.Context,
    stream pb.AIAgentService_GenerateTextStreamClient,
    chunkChan chan<- *StreamChunk,
) {
    defer close(chunkChan)
    
    ticker := time.NewTicker(50 * time.Millisecond) // æœ€å¿«æ¯50msæ¨é€ä¸€æ¬¡
    defer ticker.Stop()
    
    buffer := ""
    
    for {
        select {
        case <-ctx.Done():
            return
            
        case <-ticker.C:
            if buffer != "" {
                chunkChan <- &StreamChunk{Delta: buffer, IsFinal: false}
                buffer = ""
            }
            
        default:
            chunk, err := stream.Recv()
            if err == io.EOF {
                if buffer != "" {
                    chunkChan <- &StreamChunk{Delta: buffer, IsFinal: true}
                }
                return
            }
            if err != nil {
                chunkChan <- &StreamChunk{Error: err.Error()}
                return
            }
            
            buffer += chunk.Delta
        }
    }
}
```

### 4.3 å†…å­˜æ§åˆ¶

```go
// é™åˆ¶channelç¼“å†²åŒºå¤§å°
chunkChan := make(chan *StreamChunk, 100) // æœ€å¤šç¼“å†²100ä¸ªchunk

// è¶…æ—¶æ§åˆ¶
ctx, cancel := context.WithTimeout(ctx, 2*time.Minute)
defer cancel()
```

---

## äº”ã€é”™è¯¯å¤„ç†

### 5.1 æµå¼é”™è¯¯å“åº”

```go
// å‘é€é”™è¯¯äº‹ä»¶
c.SSEvent("error", gin.H{
    "error": "ç”Ÿæˆå¤±è´¥",
    "code":  "GENERATION_ERROR",
    "details": err.Error(),
})
```

### 5.2 è¿æ¥ä¿æ´»

```go
// å®šæœŸå‘é€å¿ƒè·³
ticker := time.NewTicker(15 * time.Second)
defer ticker.Stop()

for {
    select {
    case <-ticker.C:
        c.SSEvent("ping", gin.H{"timestamp": time.Now().Unix()})
        
    case chunk := <-chunkChan:
        // å¤„ç†chunk
    }
}
```

---

## å…­ã€æµ‹è¯•è§„èŒƒ

### 6.1 æ€§èƒ½æµ‹è¯•

```go
func BenchmarkGenerateTextStream(b *testing.B) {
    for i := 0; i < b.N; i++ {
        req := &ai.GenerateRequest{
            Prompt: "å†™ä¸€æ®µ500å­—çš„æ•…äº‹",
            Model:  "gpt-4",
        }
        
        chunkChan, err := proxyService.GenerateTextStream(context.Background(), req)
        if err != nil {
            b.Fatal(err)
        }
        
        for chunk := range chunkChan {
            if chunk.Error != "" {
                b.Fatal(chunk.Error)
            }
        }
    }
}
```

### 6.2 å‹åŠ›æµ‹è¯•

```bash
# ä½¿ç”¨k6è¿›è¡Œå‹åŠ›æµ‹è¯•
import http from 'k6/http';
import { check } from 'k6';

export default function() {
    const payload = JSON.stringify({
        prompt: 'å†™ä¸€æ®µæ•…äº‹',
        stream: true
    });
    
    const params = {
        headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${__ENV.TOKEN}`
        }
    };
    
    const res = http.post('http://localhost:8080/api/v1/ai/generate', payload, params);
    
    check(res, {
        'status is 200': (r) => r.status === 200,
        'is streaming': (r) => r.headers['Content-Type'] === 'text/event-stream'
    });
}
```

---

## ä¸ƒã€å®æ–½å»ºè®®

### 7.1 è¿ç§»è®¡åˆ’

1. **Week 1**: å®ç°SSEåŸºç¡€æ¡†æ¶
2. **Week 2**: æ”¹é€ æ‰€æœ‰AIæ¥å£ä¸ºæµå¼
3. **Week 3**: å‰ç«¯é›†æˆå’Œæµ‹è¯•
4. **Week 4**: æ€§èƒ½ä¼˜åŒ–å’Œç›‘æ§

### 7.2 ç›‘æ§æŒ‡æ ‡

| æŒ‡æ ‡ | ç›®æ ‡ | å‘Šè­¦é˜ˆå€¼ |
|------|------|---------|
| é¦–ä¸ªchunkå»¶è¿Ÿ | <500ms | >1s |
| å¹³å‡chunké—´éš” | <100ms | >200ms |
| æµå¼è¿æ¥æˆåŠŸç‡ | >99% | <95% |
| å¹¶å‘è¿æ¥æ•° | æ”¯æŒ1000+ | >1500 |

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¶é—´**: 2025-10-21  
**è´Ÿè´£äºº**: AIå›¢é˜Ÿ  
**å®¡æ ¸çŠ¶æ€**: å¾…è¯„å®¡

