# LangGraph Agent å·¥ä½œæµæ¶æ„

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0
> **åˆ›å»ºæ—¶é—´**: 2025-10-27
> **å®æ–½çŠ¶æ€**: è®¾è®¡é˜¶æ®µ
> **è´Ÿè´£äºº**: AIæ¶æ„ç»„

---

## ğŸ“‹ æ–‡æ¡£æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è®¾è®¡åŸºäº LangGraph çš„ Agent å·¥ä½œæµæ¶æ„ï¼ŒåŒ…æ‹¬ State Schema è®¾è®¡ã€Agent èŠ‚ç‚¹å®šä¹‰ã€æ¡ä»¶è·¯ç”±ã€å¹¶è¡Œæ‰§è¡Œã€é”™è¯¯æ¢å¤ç­‰æ ¸å¿ƒæœºåˆ¶ã€‚

**é€‚ç”¨èŒƒå›´**ï¼š
- LangGraph å·¥ä½œæµæ¶æ„
- State Schema è®¾è®¡
- Agent èŠ‚ç‚¹å®ç°
- æ¡ä»¶è·¯ç”±å’Œå¾ªç¯æ§åˆ¶
- å·¥ä½œæµå¯è§†åŒ–å’Œè°ƒè¯•

---

## ğŸ¯ è®¾è®¡ç›®æ ‡

### æ ¸å¿ƒç›®æ ‡

1. **æ¸…æ™°çš„çŠ¶æ€ç®¡ç†**ï¼šä½¿ç”¨ TypedDict å®šä¹‰æ˜¾å¼çŠ¶æ€
2. **çµæ´»çš„æµç¨‹æ§åˆ¶**ï¼šæ”¯æŒæ¡ä»¶åˆ†æ”¯ã€å¾ªç¯ã€å¹¶è¡Œ
3. **å¯è¿½è¸ªæ€§**ï¼šæ¯ä¸ªèŠ‚ç‚¹çš„è¾“å…¥è¾“å‡ºéƒ½å¯è¿½è¸ª
4. **å¯è°ƒè¯•æ€§**ï¼šæ”¯æŒæ–­ç‚¹è°ƒè¯•å’ŒçŠ¶æ€æ£€æŸ¥
5. **å¯æ‰©å±•æ€§**ï¼šæ˜“äºæ·»åŠ æ–°èŠ‚ç‚¹å’Œæ–°å·¥ä½œæµ

### éç›®æ ‡

- âŒ ä¸å®ç°ä¸šåŠ¡é€»è¾‘ï¼ˆç”± Tool å®Œæˆï¼‰
- âŒ ä¸ç›´æ¥æ“ä½œæ•°æ®åº“ï¼ˆè°ƒç”¨ Go APIï¼‰

---

## ä¸€ã€State Schema è®¾è®¡

### 1.1 åŸºç¡€ State

```python
# src/core/agents/states/base_state.py
from typing import TypedDict, Annotated, Sequence, List, Dict, Any, Optional
from langchain_core.messages import BaseMessage
import operator
from dataclasses import dataclass


class BaseAgentState(TypedDict):
    """Agent åŸºç¡€çŠ¶æ€"""
    
    # è¾“å…¥
    task: str                                    # ä»»åŠ¡æè¿°
    user_id: str                                 # ç”¨æˆ· ID
    project_id: str                              # é¡¹ç›® ID
    
    # æ¶ˆæ¯å†å²ï¼ˆè‡ªåŠ¨ç´¯ç§¯ï¼‰
    messages: Annotated[Sequence[BaseMessage], operator.add]
    
    # å·¥ä½œæµæ§åˆ¶
    current_step: str                            # å½“å‰æ­¥éª¤
    max_iterations: int                          # æœ€å¤§è¿­ä»£æ¬¡æ•°
    iteration_count: int                         # å½“å‰è¿­ä»£æ¬¡æ•°
    
    # é”™è¯¯å¤„ç†
    errors: Annotated[List[str], operator.add]   # é”™è¯¯åˆ—è¡¨
    warnings: Annotated[List[str], operator.add] # è­¦å‘Šåˆ—è¡¨
    
    # æ¨ç†è¿‡ç¨‹
    reasoning: Annotated[List[str], operator.add] # æ¨ç†æ­¥éª¤
    
    # å…ƒæ•°æ®
    metadata: Dict[str, Any]                     # å…ƒæ•°æ®


# Custom Reducer ç¤ºä¾‹
def merge_dict_values(current: Dict[str, Any], new: Dict[str, Any]) -> Dict[str, Any]:
    """åˆå¹¶å­—å…¸å€¼"""
    result = current.copy()
    result.update(new)
    return result
```

### 1.2 Creative Agent State

```python
# src/core/agents/states/creative_state.py
from typing import TypedDict, Annotated, Sequence, List, Dict, Any, Optional
from langchain_core.messages import BaseMessage
import operator


class CreativeAgentState(TypedDict):
    """åˆ›ä½œ Agent çŠ¶æ€"""
    
    # ===== è¾“å…¥ =====
    task: str                                    # åˆ›ä½œä»»åŠ¡
    user_id: str
    project_id: str
    
    # åˆ›ä½œçº¦æŸ
    constraints: Dict[str, Any]                  # åˆ›ä½œçº¦æŸï¼ˆå­—æ•°ã€ç±»å‹ç­‰ï¼‰
    context: Dict[str, Any]                      # ä¸Šä¸‹æ–‡ä¿¡æ¯
    
    # ===== æ¶ˆæ¯å’Œæ¨ç† =====
    messages: Annotated[Sequence[BaseMessage], operator.add]
    reasoning: Annotated[List[str], operator.add]
    
    # ===== å·¥ä½œæµçŠ¶æ€ =====
    current_step: str                            # å½“å‰æ­¥éª¤
    plan: List[Dict[str, Any]]                   # æ‰§è¡Œè®¡åˆ’
    current_plan_index: int                      # å½“å‰è®¡åˆ’ç´¢å¼•
    
    # ===== RAG æ£€ç´¢ =====
    rag_results: List[Dict[str, Any]]           # RAG æ£€ç´¢ç»“æœ
    retrieved_context: str                       # æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
    
    # ===== ç”Ÿæˆå†…å®¹ =====
    generated_content: str                       # ç”Ÿæˆçš„å†…å®¹
    content_draft: str                           # å†…å®¹è‰ç¨¿
    
    # ===== å·¥å…·è°ƒç”¨ =====
    tool_calls: Annotated[List[Dict[str, Any]], operator.add]
    tools_to_use: List[str]                      # å¾…ä½¿ç”¨çš„å·¥å…·
    
    # ===== å®¡æ ¸å’Œè¿­ä»£ =====
    review_result: Optional[Dict[str, Any]]      # å®¡æ ¸ç»“æœ
    review_passed: bool                          # å®¡æ ¸æ˜¯å¦é€šè¿‡
    retry_count: int                             # é‡è¯•æ¬¡æ•°
    max_retries: int                             # æœ€å¤§é‡è¯•æ¬¡æ•°
    
    # ===== æœ€ç»ˆè¾“å‡º =====
    final_output: str                            # æœ€ç»ˆè¾“å‡º
    output_metadata: Dict[str, Any]              # è¾“å‡ºå…ƒæ•°æ®
    
    # ===== é”™è¯¯å¤„ç† =====
    errors: Annotated[List[str], operator.add]
    warnings: Annotated[List[str], operator.add]
    
    # ===== æ€§èƒ½æŒ‡æ ‡ =====
    start_time: float                            # å¼€å§‹æ—¶é—´
    tokens_used: int                             # Token ä½¿ç”¨é‡
```

### 1.3 Outline Agent State

```python
# src/core/agents/states/outline_state.py
from typing import TypedDict, Annotated, List, Dict, Any, Optional
from langchain_core.messages import BaseMessage
import operator


class OutlineAgentState(TypedDict):
    """å¤§çº² Agent çŠ¶æ€"""
    
    # è¾“å…¥
    task: str                                    # ä»»åŠ¡æè¿°
    user_id: str
    project_id: str
    
    # å¤§çº²éœ€æ±‚
    outline_requirements: Dict[str, Any]         # å¤§çº²éœ€æ±‚ï¼ˆç« èŠ‚æ•°ã€ç»“æ„ç­‰ï¼‰
    genre: str                                   # å°è¯´ç±»å‹
    target_audience: str                         # ç›®æ ‡è¯»è€…
    
    # æ¶ˆæ¯å’Œæ¨ç†
    messages: Annotated[Sequence[BaseMessage], operator.add]
    reasoning: Annotated[List[str], operator.add]
    
    # RAG æ£€ç´¢
    rag_results: List[Dict[str, Any]]           # RAG æ£€ç´¢ç»“æœï¼ˆå‚è€ƒå¤§çº²ï¼‰
    
    # å¤§çº²ç”Ÿæˆ
    outline_structure: List[Dict[str, Any]]      # å¤§çº²ç»“æ„ï¼ˆæ ‘å½¢ï¼‰
    outline_summary: str                         # å¤§çº²æ€»ç»“
    chapter_count: int                           # ç« èŠ‚æ•°
    
    # å·¥å…·è°ƒç”¨
    tool_calls: Annotated[List[Dict[str, Any]], operator.add]
    
    # å®¡æ ¸
    review_result: Optional[Dict[str, Any]]
    review_passed: bool
    retry_count: int
    max_retries: int
    
    # è¾“å‡º
    final_outline: List[Dict[str, Any]]          # æœ€ç»ˆå¤§çº²
    
    # é”™è¯¯å¤„ç†
    errors: Annotated[List[str], operator.add]
```

---

## äºŒã€Agent èŠ‚ç‚¹å®ç°

### 2.1 Understanding Nodeï¼ˆç†è§£ä»»åŠ¡èŠ‚ç‚¹ï¼‰

```python
# src/core/agents/nodes/understanding.py
from typing import Dict, Any
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from core.agents.states.creative_state import CreativeAgentState
from utils.logging import get_logger

logger = get_logger(__name__)


async def understand_task_node(state: CreativeAgentState) -> CreativeAgentState:
    """ç†è§£ä»»åŠ¡èŠ‚ç‚¹
    
    èŒè´£ï¼š
    1. åˆ†æç”¨æˆ·ä»»åŠ¡
    2. æå–å…³é”®è¦ç´ 
    3. åˆ¶å®šæ‰§è¡Œè®¡åˆ’
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Returns:
        æ›´æ–°åçš„çŠ¶æ€
    """
    logger.info("Understanding task...", task=state["task"][:100])
    
    # åˆå§‹åŒ– LLM
    llm = ChatOpenAI(model="gpt-4-turbo-preview", temperature=0)
    
    # æ„å»º Prompt
    system_message = SystemMessage(content="""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†™ä½œåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯ç†è§£ç”¨æˆ·çš„åˆ›ä½œéœ€æ±‚ï¼Œå¹¶åˆ¶å®šè¯¦ç»†çš„æ‰§è¡Œè®¡åˆ’ã€‚

è¯·åˆ†æç”¨æˆ·çš„ä»»åŠ¡ï¼Œæå–ä»¥ä¸‹ä¿¡æ¯ï¼š
1. ä»»åŠ¡ç±»å‹ï¼ˆç»­å†™ã€åˆ›ä½œã€æ”¹å†™ç­‰ï¼‰
2. å…³é”®è¦ç´ ï¼ˆè§’è‰²ã€æƒ…èŠ‚ã€åœºæ™¯ç­‰ï¼‰
3. åˆ›ä½œçº¦æŸï¼ˆå­—æ•°ã€é£æ ¼ã€ç±»å‹ç­‰ï¼‰
4. æ‰€éœ€å·¥å…·ï¼ˆè§’è‰²å¡ã€å¤§çº²ã€RAG æ£€ç´¢ç­‰ï¼‰

è¾“å‡ºæ ¼å¼ï¼šJSON
{
  "task_type": "ä»»åŠ¡ç±»å‹",
  "key_elements": ["è¦ç´ 1", "è¦ç´ 2"],
  "constraints": {"å­—æ•°": 1000, "é£æ ¼": "æ‚¬ç–‘"},
  "required_tools": ["rag_tool", "character_tool"],
  "plan": [
    {"step": "æ£€ç´¢ç›¸å…³è®¾å®š", "tool": "rag_tool"},
    {"step": "æŸ¥è¯¢è§’è‰²ä¿¡æ¯", "tool": "character_tool"},
    {"step": "ç”Ÿæˆå†…å®¹", "tool": "llm"}
  ]
}
""")
    
    user_message = HumanMessage(content=f"""
ä»»åŠ¡ï¼š{state['task']}

é¡¹ç›® IDï¼š{state['project_id']}
ç”¨æˆ· IDï¼š{state['user_id']}

è¯·åˆ†æè¿™ä¸ªä»»åŠ¡å¹¶åˆ¶å®šæ‰§è¡Œè®¡åˆ’ã€‚
""")
    
    # è°ƒç”¨ LLM
    response = await llm.ainvoke([system_message, user_message])
    
    # è§£æå“åº”
    import json
    try:
        analysis = json.loads(response.content)
    except:
        analysis = {
            "task_type": "general",
            "key_elements": [],
            "constraints": {},
            "required_tools": ["rag_tool"],
            "plan": [
                {"step": "æ£€ç´¢ç›¸å…³ä¿¡æ¯", "tool": "rag_tool"},
                {"step": "ç”Ÿæˆå†…å®¹", "tool": "llm"}
            ]
        }
    
    # æ›´æ–°çŠ¶æ€
    return {
        **state,
        "messages": state["messages"] + [system_message, user_message, response],
        "plan": analysis.get("plan", []),
        "current_plan_index": 0,
        "constraints": analysis.get("constraints", {}),
        "tools_to_use": analysis.get("required_tools", []),
        "reasoning": state["reasoning"] + [
            f"ä»»åŠ¡åˆ†æå®Œæˆï¼š{analysis.get('task_type')}",
            f"å…³é”®è¦ç´ ï¼š{', '.join(analysis.get('key_elements', []))}",
            f"æ‰§è¡Œè®¡åˆ’ï¼š{len(analysis.get('plan', []))} ä¸ªæ­¥éª¤"
        ],
        "current_step": "rag_retrieval"
    }
```

### 2.2 RAG Retrieval Nodeï¼ˆRAG æ£€ç´¢èŠ‚ç‚¹ï¼‰

```python
# src/core/agents/nodes/retrieval.py
from typing import Dict, Any
from core.agents.states.creative_state import CreativeAgentState
from core.tools.langchain.rag_tool import RAGTool
from utils.logging import get_logger

logger = get_logger(__name__)


async def rag_retrieval_node(state: CreativeAgentState) -> CreativeAgentState:
    """RAG æ£€ç´¢èŠ‚ç‚¹
    
    èŒè´£ï¼š
    1. æ„å»ºæ£€ç´¢æŸ¥è¯¢
    2. è°ƒç”¨ RAG Tool
    3. ç»„ç»‡æ£€ç´¢ç»“æœ
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Returns:
        æ›´æ–°åçš„çŠ¶æ€
    """
    logger.info("Retrieving relevant knowledge...")
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦ RAG
    if "rag_tool" not in state.get("tools_to_use", []):
        logger.info("RAG not required, skipping...")
        return {
            **state,
            "current_step": "generation",
            "reasoning": state["reasoning"] + ["è·³è¿‡ RAG æ£€ç´¢"]
        }
    
    # æ„å»ºæŸ¥è¯¢ï¼ˆä»ä»»åŠ¡ä¸­æå–å…³é”®è¯ï¼‰
    query = state["task"]
    
    # è°ƒç”¨ RAG Tool
    rag_tool = state.get("_rag_tool")  # ä»å·¥ä½œæµä¸Šä¸‹æ–‡è·å–
    
    if rag_tool:
        result = await rag_tool.execute(
            params={
                "query": query,
                "project_id": state["project_id"],
                "content_types": ["character", "setting", "outline"],
                "top_k": 5,
                "enable_rerank": True
            },
            user_id=state["user_id"],
            project_id=state["project_id"]
        )
        
        if result.success:
            rag_results = result.data.get("results", [])
            
            # ç»„ç»‡æ£€ç´¢ç»“æœä¸ºä¸Šä¸‹æ–‡
            context_parts = []
            for i, res in enumerate(rag_results, 1):
                context_parts.append(f"""
ã€å‚è€ƒèµ„æ–™ {i}ã€‘ï¼ˆç±»å‹ï¼š{res.get('content_type')}ï¼‰
{res.get('content', '')}
""")
            
            retrieved_context = "\n".join(context_parts)
            
            return {
                **state,
                "rag_results": rag_results,
                "retrieved_context": retrieved_context,
                "current_step": "generation",
                "reasoning": state["reasoning"] + [
                    f"RAG æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(rag_results)} æ¡ç›¸å…³èµ„æ–™"
                ]
            }
    
    # RAG å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œ
    return {
        **state,
        "current_step": "generation",
        "warnings": state.get("warnings", []) + ["RAG æ£€ç´¢å¤±è´¥"],
        "reasoning": state["reasoning"] + ["RAG æ£€ç´¢å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œ"]
    }
```

### 2.3 Generation Nodeï¼ˆç”ŸæˆèŠ‚ç‚¹ï¼‰

```python
# src/core/agents/nodes/generation.py
from typing import Dict, Any
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from core.agents.states.creative_state import CreativeAgentState
from utils.logging import get_logger

logger = get_logger(__name__)


async def generation_node(state: CreativeAgentState) -> CreativeAgentState:
    """ç”ŸæˆèŠ‚ç‚¹
    
    èŒè´£ï¼š
    1. æ„å»ºå¢å¼º Prompt
    2. è°ƒç”¨ LLM ç”Ÿæˆå†…å®¹
    3. ä¿å­˜ç”Ÿæˆç»“æœ
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Returns:
        æ›´æ–°åçš„çŠ¶æ€
    """
    logger.info("Generating content...")
    
    # åˆå§‹åŒ– LLM
    llm = ChatOpenAI(model="gpt-4-turbo-preview", temperature=0.7, max_tokens=2000)
    
    # æ„å»ºç³»ç»Ÿæç¤º
    system_prompt = """
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç½‘ç»œå°è¯´ä½œå®¶ï¼Œæ“…é•¿åˆ›ä½œå¼•äººå…¥èƒœçš„æ•…äº‹ã€‚
è¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚å’Œå‚è€ƒèµ„æ–™ï¼Œåˆ›ä½œé«˜è´¨é‡çš„å†…å®¹ã€‚

åˆ›ä½œè¦æ±‚ï¼š
1. å†…å®¹è¦ç¬¦åˆç”¨æˆ·çš„å…·ä½“è¦æ±‚
2. ä¿æŒè§’è‰²æ€§æ ¼ä¸€è‡´
3. æƒ…èŠ‚åˆç†è¿è´¯
4. æ–‡ç¬”æµç•…è‡ªç„¶
"""
    
    # æ„å»ºç”¨æˆ·æç¤º
    user_prompt_parts = [f"åˆ›ä½œä»»åŠ¡ï¼š{state['task']}"]
    
    # æ·»åŠ  RAG æ£€ç´¢çš„ä¸Šä¸‹æ–‡
    if state.get("retrieved_context"):
        user_prompt_parts.append(f"\nå‚è€ƒèµ„æ–™ï¼š\n{state['retrieved_context']}")
    
    # æ·»åŠ çº¦æŸæ¡ä»¶
    if state.get("constraints"):
        constraints_str = "\n".join([f"- {k}: {v}" for k, v in state["constraints"].items()])
        user_prompt_parts.append(f"\nåˆ›ä½œçº¦æŸï¼š\n{constraints_str}")
    
    user_prompt = "\n".join(user_prompt_parts)
    
    # è°ƒç”¨ LLM
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_prompt)
    ]
    
    response = await llm.ainvoke(messages)
    generated_content = response.content
    
    # ç»Ÿè®¡ Token ä½¿ç”¨
    tokens_used = len(response.content) // 4  # ç²—ç•¥ä¼°è®¡
    
    return {
        **state,
        "messages": state["messages"] + messages + [response],
        "generated_content": generated_content,
        "content_draft": generated_content,
        "tokens_used": state.get("tokens_used", 0) + tokens_used,
        "current_step": "review",
        "reasoning": state["reasoning"] + [
            f"å†…å®¹ç”Ÿæˆå®Œæˆï¼Œå­—æ•°çº¦ {len(generated_content)}"
        ]
    }
```

### 2.4 Review Nodeï¼ˆå®¡æ ¸èŠ‚ç‚¹ï¼‰

```python
# src/core/agents/nodes/review.py
from typing import Dict, Any
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from core.agents.states.creative_state import CreativeAgentState
from utils.logging import get_logger

logger = get_logger(__name__)


async def review_node(state: CreativeAgentState) -> CreativeAgentState:
    """å®¡æ ¸èŠ‚ç‚¹
    
    èŒè´£ï¼š
    1. æ£€æŸ¥ç”Ÿæˆå†…å®¹è´¨é‡
    2. è¯„ä¼°æ˜¯å¦ç¬¦åˆè¦æ±‚
    3. æä¾›æ”¹è¿›å»ºè®®
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Returns:
        æ›´æ–°åçš„çŠ¶æ€
    """
    logger.info("Reviewing generated content...")
    
    # åˆå§‹åŒ– LLM
    llm = ChatOpenAI(model="gpt-4-turbo-preview", temperature=0)
    
    # æ„å»ºå®¡æ ¸ Prompt
    system_message = SystemMessage(content="""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å†…å®¹å®¡æ ¸ä¸“å®¶ã€‚è¯·è¯„ä¼°ç”Ÿæˆçš„å†…å®¹è´¨é‡ã€‚

è¯„ä¼°æ ‡å‡†ï¼š
1. å†…å®¹æ˜¯å¦ç¬¦åˆç”¨æˆ·è¦æ±‚
2. é€»è¾‘æ˜¯å¦è¿è´¯
3. è§’è‰²æ€§æ ¼æ˜¯å¦ä¸€è‡´
4. æ–‡ç¬”æ˜¯å¦æµç•…
5. æ˜¯å¦æœ‰æ˜æ˜¾é”™è¯¯

è¾“å‡ºæ ¼å¼ï¼šJSON
{
  "passed": true/false,
  "score": 85,
  "issues": ["é—®é¢˜1", "é—®é¢˜2"],
  "suggestions": ["å»ºè®®1", "å»ºè®®2"],
  "summary": "æ€»ä½“è¯„ä»·"
}
""")
    
    user_message = HumanMessage(content=f"""
åŸå§‹ä»»åŠ¡ï¼š{state['task']}

ç”Ÿæˆå†…å®¹ï¼š
{state['generated_content']}

è¯·è¯„ä¼°è¿™ä¸ªå†…å®¹çš„è´¨é‡ã€‚
""")
    
    # è°ƒç”¨ LLM
    response = await llm.ainvoke([system_message, user_message])
    
    # è§£æå®¡æ ¸ç»“æœ
    import json
    try:
        review_result = json.loads(response.content)
    except:
        # è§£æå¤±è´¥ï¼Œé»˜è®¤é€šè¿‡
        review_result = {
            "passed": True,
            "score": 75,
            "issues": [],
            "suggestions": [],
            "summary": "å†…å®¹å¯æ¥å—"
        }
    
    passed = review_result.get("passed", False) or review_result.get("score", 0) >= 70
    
    return {
        **state,
        "messages": state["messages"] + [system_message, user_message, response],
        "review_result": review_result,
        "review_passed": passed,
        "current_step": "finalize" if passed else "regenerate",
        "reasoning": state["reasoning"] + [
            f"å®¡æ ¸å®Œæˆï¼š{'é€šè¿‡' if passed else 'ä¸é€šè¿‡'}",
            f"è¯„åˆ†ï¼š{review_result.get('score', 0)}",
            f"é—®é¢˜ï¼š{len(review_result.get('issues', []))}"
        ]
    }
```

### 2.5 Finalize Nodeï¼ˆæœ€ç»ˆåŒ–èŠ‚ç‚¹ï¼‰

```python
# src/core/agents/nodes/finalize.py
from typing import Dict, Any
from core.agents.states.creative_state import CreativeAgentState
from utils.logging import get_logger

logger = get_logger(__name__)


async def finalize_node(state: CreativeAgentState) -> CreativeAgentState:
    """æœ€ç»ˆåŒ–èŠ‚ç‚¹
    
    èŒè´£ï¼š
    1. æ•´ç†æœ€ç»ˆè¾“å‡º
    2. æ·»åŠ å…ƒæ•°æ®
    3. å‡†å¤‡è¿”å›ç»“æœ
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Returns:
        æ›´æ–°åçš„çŠ¶æ€
    """
    logger.info("Finalizing output...")
    
    # æ„å»ºè¾“å‡ºå…ƒæ•°æ®
    output_metadata = {
        "tokens_used": state.get("tokens_used", 0),
        "retry_count": state.get("retry_count", 0),
        "review_score": state.get("review_result", {}).get("score", 0),
        "rag_sources_count": len(state.get("rag_results", [])),
        "tool_calls_count": len(state.get("tool_calls", [])),
        "reasoning_steps": len(state.get("reasoning", []))
    }
    
    return {
        **state,
        "final_output": state["generated_content"],
        "output_metadata": output_metadata,
        "current_step": "completed",
        "reasoning": state["reasoning"] + [
            "ä»»åŠ¡å®Œæˆ",
            f"æ€» Token ä½¿ç”¨ï¼š{output_metadata['tokens_used']}"
        ]
    }
```

---

## ä¸‰ã€æ¡ä»¶è·¯ç”±å’Œå¾ªç¯æ§åˆ¶

### 3.1 è·¯ç”±å‡½æ•°

```python
# src/core/agents/workflows/routers.py
from core.agents.states.creative_state import CreativeAgentState
from utils.logging import get_logger

logger = get_logger(__name__)


def should_regenerate(state: CreativeAgentState) -> str:
    """å†³å®šæ˜¯å¦é‡æ–°ç”Ÿæˆ
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Returns:
        ä¸‹ä¸€ä¸ªèŠ‚ç‚¹åç§°
    """
    # å¦‚æœå®¡æ ¸é€šè¿‡ï¼Œè¿›å…¥æœ€ç»ˆåŒ–
    if state.get("review_passed", False):
        logger.info("Review passed, proceeding to finalize")
        return "finalize"
    
    # æ£€æŸ¥é‡è¯•æ¬¡æ•°
    retry_count = state.get("retry_count", 0)
    max_retries = state.get("max_retries", 3)
    
    if retry_count >= max_retries:
        logger.warning(f"Max retries ({max_retries}) reached, forcing finalize")
        return "force_finalize"
    
    # æ£€æŸ¥ä¸¥é‡é—®é¢˜
    review_result = state.get("review_result", {})
    score = review_result.get("score", 0)
    
    if score < 40:
        # åˆ†æ•°å¤ªä½ï¼Œéœ€è¦é‡æ–°ç†è§£ä»»åŠ¡
        logger.info("Score too low, restarting from understanding")
        return "restart"
    
    # æ™®é€šé‡è¯•ï¼Œå›åˆ°ç”ŸæˆèŠ‚ç‚¹
    logger.info(f"Review failed (score: {score}), regenerating...")
    return "regenerate"


def should_continue_plan(state: CreativeAgentState) -> str:
    """å†³å®šæ˜¯å¦ç»§ç»­æ‰§è¡Œè®¡åˆ’
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Returns:
        ä¸‹ä¸€ä¸ªèŠ‚ç‚¹åç§°
    """
    plan = state.get("plan", [])
    current_index = state.get("current_plan_index", 0)
    
    if current_index >= len(plan):
        logger.info("Plan completed, proceeding to generation")
        return "generation"
    
    # è·å–å½“å‰è®¡åˆ’æ­¥éª¤
    current_step = plan[current_index]
    tool = current_step.get("tool", "")
    
    # æ ¹æ®å·¥å…·ç±»å‹è·¯ç”±åˆ°ä¸åŒèŠ‚ç‚¹
    if tool == "rag_tool":
        return "rag_retrieval"
    elif tool in ["character_tool", "outline_tool", "timeline_tool"]:
        return "tool_execution"
    else:
        return "generation"


def check_errors(state: CreativeAgentState) -> str:
    """æ£€æŸ¥æ˜¯å¦æœ‰ä¸¥é‡é”™è¯¯
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Returns:
        ä¸‹ä¸€ä¸ªèŠ‚ç‚¹åç§°
    """
    errors = state.get("errors", [])
    
    if errors:
        logger.error(f"Errors detected: {len(errors)}")
        return "error_handler"
    
    return "continue"
```

---

## å››ã€å·¥ä½œæµæ„å»º

### 4.1 Creative Workflow

```python
# src/core/agents/workflows/creative.py
from langgraph.graph import StateGraph, END
from core.agents.states.creative_state import CreativeAgentState
from core.agents.nodes import (
    understand_task_node,
    rag_retrieval_node,
    generation_node,
    review_node,
    finalize_node
)
from core.agents.workflows.routers import should_regenerate
from utils.logging import get_logger

logger = get_logger(__name__)


def create_creative_workflow():
    """åˆ›å»ºåˆ›ä½œå·¥ä½œæµ
    
    Returns:
        ç¼–è¯‘åçš„å·¥ä½œæµ
    """
    logger.info("Creating creative workflow...")
    
    # åˆ›å»ºçŠ¶æ€å›¾
    workflow = StateGraph(CreativeAgentState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("understand", understand_task_node)
    workflow.add_node("rag_retrieval", rag_retrieval_node)
    workflow.add_node("generation", generation_node)
    workflow.add_node("review", review_node)
    workflow.add_node("finalize", finalize_node)
    
    # æ·»åŠ  regenerate èŠ‚ç‚¹ï¼ˆå¢åŠ é‡è¯•è®¡æ•°ï¼‰
    async def regenerate_node(state: CreativeAgentState) -> CreativeAgentState:
        return {
            **state,
            "retry_count": state.get("retry_count", 0) + 1,
            "reasoning": state["reasoning"] + ["é‡è¯•ç”Ÿæˆ"]
        }
    workflow.add_node("regenerate", regenerate_node)
    
    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("understand")
    
    # æ·»åŠ è¾¹
    workflow.add_edge("understand", "rag_retrieval")
    workflow.add_edge("rag_retrieval", "generation")
    workflow.add_edge("generation", "review")
    
    # æ¡ä»¶è¾¹ï¼šå®¡æ ¸åçš„è·¯ç”±
    workflow.add_conditional_edges(
        "review",
        should_regenerate,
        {
            "finalize": "finalize",
            "regenerate": "regenerate",
            "restart": "understand",
            "force_finalize": "finalize"
        }
    )
    
    # regenerate å›åˆ° generation
    workflow.add_edge("regenerate", "generation")
    
    # æœ€ç»ˆåŒ–åç»“æŸ
    workflow.add_edge("finalize", END)
    
    # ç¼–è¯‘
    app = workflow.compile()
    
    logger.info("Creative workflow created successfully")
    return app
```

### 4.2 å·¥ä½œæµå¯è§†åŒ–

```python
# ç”Ÿæˆå·¥ä½œæµå›¾
from IPython.display import Image, display

workflow = create_creative_workflow()

# ç”Ÿæˆ Mermaid å›¾
mermaid_png = workflow.get_graph().draw_mermaid_png()

# ä¿å­˜åˆ°æ–‡ä»¶
with open("creative_workflow.png", "wb") as f:
    f.write(mermaid_png)

# æˆ–åœ¨ Jupyter ä¸­æ˜¾ç¤º
display(Image(mermaid_png))
```

ç”Ÿæˆçš„æµç¨‹å›¾ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ understand   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚rag_retrieval â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ generation   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
       â”‚                   â”‚
       â–¼                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   review     â”‚           â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
       â”‚                   â”‚
       â”œâ”€â”€â”€(ä¸é€šè¿‡)â”€â”€â”€â”€â”€â”€â”€â”€â”¤
       â”‚              regenerate
       â”‚
       â”œâ”€â”€â”€(é€šè¿‡)â”€â”€â”€â”€â”€â”€â–ºâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚ finalize â”‚
                       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                          [END]
```

---

## äº”ã€å¹¶è¡Œæ‰§è¡Œ

### 5.1 å¹¶è¡ŒèŠ‚ç‚¹ç¤ºä¾‹

```python
# src/core/agents/workflows/parallel_example.py
from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated, List
import operator


class ParallelState(TypedDict):
    """å¹¶è¡Œæ‰§è¡ŒçŠ¶æ€"""
    task: str
    character_info: str
    setting_info: str
    outline_info: str
    combined_context: str


async def fetch_character_node(state: ParallelState) -> ParallelState:
    """è·å–è§’è‰²ä¿¡æ¯ï¼ˆå¹¶è¡Œï¼‰"""
    # æ¨¡æ‹Ÿå¹¶è¡Œè·å–
    character_info = "è§’è‰²ä¿¡æ¯..."
    return {**state, "character_info": character_info}


async def fetch_setting_node(state: ParallelState) -> ParallelState:
    """è·å–è®¾å®šä¿¡æ¯ï¼ˆå¹¶è¡Œï¼‰"""
    setting_info = "è®¾å®šä¿¡æ¯..."
    return {**state, "setting_info": setting_info}


async def fetch_outline_node(state: ParallelState) -> ParallelState:
    """è·å–å¤§çº²ä¿¡æ¯ï¼ˆå¹¶è¡Œï¼‰"""
    outline_info = "å¤§çº²ä¿¡æ¯..."
    return {**state, "outline_info": outline_info}


async def combine_node(state: ParallelState) -> ParallelState:
    """æ±‡èšèŠ‚ç‚¹"""
    combined = f"{state['character_info']}\n{state['setting_info']}\n{state['outline_info']}"
    return {**state, "combined_context": combined}


def create_parallel_workflow():
    """åˆ›å»ºå¹¶è¡Œå·¥ä½œæµ"""
    workflow = StateGraph(ParallelState)
    
    # æ·»åŠ å¹¶è¡ŒèŠ‚ç‚¹
    workflow.add_node("fetch_character", fetch_character_node)
    workflow.add_node("fetch_setting", fetch_setting_node)
    workflow.add_node("fetch_outline", fetch_outline_node)
    workflow.add_node("combine", combine_node)
    
    # è®¾ç½®å…¥å£ï¼ˆå¹¶è¡Œèµ·ç‚¹ï¼‰
    workflow.set_entry_point("fetch_character")
    workflow.set_entry_point("fetch_setting")
    workflow.set_entry_point("fetch_outline")
    
    # å¹¶è¡ŒèŠ‚ç‚¹éƒ½æŒ‡å‘æ±‡èšç‚¹
    workflow.add_edge("fetch_character", "combine")
    workflow.add_edge("fetch_setting", "combine")
    workflow.add_edge("fetch_outline", "combine")
    
    # æ±‡èšåç»“æŸ
    workflow.add_edge("combine", END)
    
    return workflow.compile()
```

---

## å…­ã€é”™è¯¯æ¢å¤å’Œé™çº§

### 6.1 é”™è¯¯å¤„ç†èŠ‚ç‚¹

```python
# src/core/agents/nodes/error_handler.py
from core.agents.states.creative_state import CreativeAgentState
from utils.logging import get_logger

logger = get_logger(__name__)


async def error_handler_node(state: CreativeAgentState) -> CreativeAgentState:
    """é”™è¯¯å¤„ç†èŠ‚ç‚¹
    
    èŒè´£ï¼š
    1. åˆ†æé”™è¯¯ç±»å‹
    2. å°è¯•æ¢å¤
    3. é™çº§å¤„ç†
    """
    errors = state.get("errors", [])
    
    logger.error(f"Handling errors: {len(errors)}")
    
    # åˆ†æé”™è¯¯ç±»å‹
    critical_errors = [e for e in errors if "critical" in e.lower()]
    
    if critical_errors:
        # ä¸¥é‡é”™è¯¯ï¼Œæ— æ³•æ¢å¤
        return {
            **state,
            "final_output": "æŠ±æ­‰ï¼Œé‡åˆ°ä¸¥é‡é”™è¯¯ï¼Œæ— æ³•å®Œæˆä»»åŠ¡ã€‚",
            "output_metadata": {"error": True, "errors": errors},
            "current_step": "completed"
        }
    
    # éä¸¥é‡é”™è¯¯ï¼Œå°è¯•é™çº§å¤„ç†
    # ä½¿ç”¨æ›´ç®€å•çš„ç­–ç•¥é‡æ–°ç”Ÿæˆ
    return {
        **state,
        "retry_count": 0,
        "max_retries": 1,  # é™çº§ï¼šå‡å°‘é‡è¯•æ¬¡æ•°
        "tools_to_use": [],  # é™çº§ï¼šä¸ä½¿ç”¨å·¥å…·
        "current_step": "generation",
        "reasoning": state["reasoning"] + [
            "é‡åˆ°é”™è¯¯ï¼Œå°è¯•é™çº§å¤„ç†",
            "ç§»é™¤å·¥å…·è°ƒç”¨ï¼Œç›´æ¥ç”Ÿæˆ"
        ]
    }
```

---

## ä¸ƒã€æ–­ç‚¹è°ƒè¯•å’ŒçŠ¶æ€æ£€æŸ¥

### 7.1 Human-in-the-Loop

```python
# src/core/agents/workflows/human_in_loop.py
from langgraph.graph import interrupt


async def human_review_node(state: CreativeAgentState) -> CreativeAgentState:
    """äººå·¥å®¡æ ¸èŠ‚ç‚¹ï¼ˆä¸­æ–­ç­‰å¾…ï¼‰"""
    
    # ä¸­æ–­å·¥ä½œæµï¼Œç­‰å¾…äººå·¥è¾“å…¥
    human_feedback = interrupt({
        "message": "è¯·å®¡æ ¸ç”Ÿæˆçš„å†…å®¹",
        "content": state["generated_content"],
        "review_result": state.get("review_result")
    })
    
    # æ ¹æ®äººå·¥åé¦ˆå†³å®šä¸‹ä¸€æ­¥
    if human_feedback.get("approved"):
        return {
            **state,
            "review_passed": True,
            "reasoning": state["reasoning"] + ["äººå·¥å®¡æ ¸ï¼šé€šè¿‡"]
        }
    else:
        feedback = human_feedback.get("feedback", "")
        return {
            **state,
            "review_passed": False,
            "constraints": {
                **state.get("constraints", {}),
                "human_feedback": feedback
            },
            "reasoning": state["reasoning"] + [f"äººå·¥å®¡æ ¸ï¼šä¸é€šè¿‡ - {feedback}"]
        }
```

### 7.2 Checkpointerï¼ˆçŠ¶æ€æŒä¹…åŒ–ï¼‰

```python
# src/core/agents/workflows/checkpointer_example.py
from langgraph.checkpoint.postgres import PostgresSaver

# åˆ›å»º Checkpointer
checkpointer = PostgresSaver.from_conn_string(
    "postgresql://user:pass@localhost/qingyu_db"
)

# ç¼–è¯‘å·¥ä½œæµæ—¶ä¼ å…¥
app = workflow.compile(checkpointer=checkpointer)

# æ‰§è¡Œæ—¶æŒ‡å®š thread_id
result = await app.ainvoke(
    initial_state,
    config={"configurable": {"thread_id": "user123_session001"}}
)

# æ¢å¤å·¥ä½œæµ
continued_result = await app.ainvoke(
    None,  # è‡ªåŠ¨ä» checkpoint åŠ è½½
    config={"configurable": {"thread_id": "user123_session001"}}
)
```

---

## å…«ã€ç›‘æ§å’Œè°ƒè¯•

### 8.1 äº‹ä»¶è¿½è¸ª

```python
# ä½¿ç”¨ astream_events è¿½è¸ªæ‰§è¡Œè¿‡ç¨‹
async for event in app.astream_events(initial_state, version="v1"):
    print(f"Event: {event['event']}")
    print(f"Name: {event.get('name')}")
    print(f"Data: {event.get('data')}")
    print("---")
```

### 8.2 çŠ¶æ€æ£€æŸ¥

```python
# è·å–æ‰€æœ‰ checkpoint
history = checkpointer.list(
    config={"configurable": {"thread_id": "session001"}}
)

for checkpoint in history:
    print(f"Step: {checkpoint.step}")
    print(f"State: {checkpoint.state}")
    print(f"Current Step: {checkpoint.state.get('current_step')}")
```

---

## ä¹ã€æ€»ç»“

æœ¬æ–‡æ¡£è¯¦ç»†è®¾è®¡äº†åŸºäº LangGraph çš„ Agent å·¥ä½œæµæ¶æ„ï¼ŒåŒ…æ‹¬ï¼š

- âœ… æ¸…æ™°çš„ State Schema è®¾è®¡ï¼ˆTypedDictï¼‰
- âœ… å®Œæ•´çš„èŠ‚ç‚¹å®ç°ï¼ˆç†è§£ã€æ£€ç´¢ã€ç”Ÿæˆã€å®¡æ ¸ã€æœ€ç»ˆåŒ–ï¼‰
- âœ… çµæ´»çš„æ¡ä»¶è·¯ç”±å’Œå¾ªç¯æ§åˆ¶
- âœ… å¹¶è¡Œæ‰§è¡Œæ”¯æŒ
- âœ… å®Œå–„çš„é”™è¯¯æ¢å¤å’Œé™çº§æœºåˆ¶
- âœ… äººå·¥ä»‹å…¥å’ŒçŠ¶æ€æŒä¹…åŒ–
- âœ… å·¥ä½œæµå¯è§†åŒ–å’Œè°ƒè¯•

**å…³é”®ç‰¹æ€§**ï¼š
- æ˜¾å¼çŠ¶æ€ç®¡ç†ï¼ˆTypedDict + Annotatedï¼‰
- å£°æ˜å¼æµç¨‹å®šä¹‰
- æ”¯æŒæ¡ä»¶åˆ†æ”¯ã€å¾ªç¯ã€å¹¶è¡Œ
- å®Œæ•´çš„å¯è§‚æµ‹æ€§
- æ˜“äºæ‰©å±•å’Œæµ‹è¯•

**åç»­å·¥ä½œ**ï¼š
- å®ç°å…·ä½“çš„ A2A åˆ›ä½œæµæ°´çº¿
- å®Œå–„é”™è¯¯å¤„ç†å’Œé™çº§ç­–ç•¥
- æ€§èƒ½ä¼˜åŒ–å’Œæµ‹è¯•

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¶é—´**: 2025-10-27
**ç»´æŠ¤è€…**: AIæ¶æ„ç»„
