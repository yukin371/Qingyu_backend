# Python AI Service API è®¾è®¡

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0
> **åˆ›å»ºæ—¶é—´**: 2025-10-27
> **å®æ–½çŠ¶æ€**: è®¾è®¡é˜¶æ®µ
> **è´Ÿè´£äºº**: AIæ¶æ„ç»„

---

## ğŸ“‹ æ–‡æ¡£æ¦‚è¿°

æœ¬æ–‡æ¡£è®¾è®¡ Python AI Service çš„ gRPC å’Œ RESTful API æ¥å£ã€‚

---

## ä¸€ã€gRPC Service å®šä¹‰

### 1.1 Proto æ–‡ä»¶

```protobuf
// proto/ai_agent_service.proto
syntax = "proto3";

package ai_agent;

// AI Agent æœåŠ¡
service AIAgentService {
  // Agent å·¥ä½œæµæ‰§è¡Œ
  rpc ExecuteAgent (AgentRequest) returns (AgentResponse);
  rpc ExecuteAgentStream (AgentRequest) returns (stream AgentStreamChunk);
  
  // RAG æ£€ç´¢
  rpc RAGSearch (RAGSearchRequest) returns (RAGSearchResponse);
  
  // å†…å®¹ç”Ÿæˆ
  rpc GenerateContent (GenerateRequest) returns (GenerateResponse);
  rpc GenerateContentStream (GenerateRequest) returns (stream GenerateStreamChunk);
  
  // A2A åˆ›ä½œæµæ°´çº¿
  rpc ExecutePipeline (PipelineRequest) returns (PipelineResponse);
  rpc ExecutePipelineStream (PipelineRequest) returns (stream PipelineStreamChunk);
  
  // å¥åº·æ£€æŸ¥
  rpc Health (HealthRequest) returns (HealthResponse);
}

// Agent è¯·æ±‚
message AgentRequest {
  string agent_type = 1;  // creative, outline, character, plot
  string task = 2;
  string user_id = 3;
  string project_id = 4;
  map<string, string> parameters = 5;
}

// Agent å“åº”
message AgentResponse {
  bool success = 1;
  string result = 2;
  string error = 3;
  map<string, string> metadata = 4;
}

// Agent æµå¼å“åº”
message AgentStreamChunk {
  string chunk_type = 1;  // reasoning, tool_call, content, metadata
  string content = 2;
  map<string, string> metadata = 3;
}

// RAG æ£€ç´¢è¯·æ±‚
message RAGSearchRequest {
  string query = 1;
  string user_id = 2;
  string project_id = 3;
  repeated string content_types = 4;
  int32 top_k = 5;
  bool enable_rerank = 6;
}

// RAG æ£€ç´¢å“åº”
message RAGSearchResponse {
  repeated RAGResult results = 1;
  int32 total = 2;
  map<string, string> metadata = 3;
}

message RAGResult {
  string content = 1;
  float score = 2;
  string content_type = 3;
  string document_id = 4;
  map<string, string> source = 5;
}

// å†…å®¹ç”Ÿæˆè¯·æ±‚
message GenerateRequest {
  string prompt = 1;
  string user_id = 2;
  string project_id = 3;
  string model = 4;
  float temperature = 5;
  int32 max_tokens = 6;
  map<string, string> context = 7;
}

// å†…å®¹ç”Ÿæˆå“åº”
message GenerateResponse {
  string content = 1;
  int32 tokens_used = 2;
  map<string, string> metadata = 3;
}

// æµå¼ç”Ÿæˆå“åº”
message GenerateStreamChunk {
  string content = 1;
  bool is_final = 2;
}

// A2A æµæ°´çº¿è¯·æ±‚
message PipelineRequest {
  string user_requirement = 1;
  string user_id = 2;
  string project_id = 3;
  map<string, string> config = 4;
}

// A2A æµæ°´çº¿å“åº”
message PipelineResponse {
  bool success = 1;
  PipelineResult result = 2;
  string error = 3;
}

message PipelineResult {
  repeated OutlineNode outline_nodes = 1;
  repeated Character characters = 2;
  repeated TimelineEvent timeline_events = 3;
  ReviewResult review_result = 4;
}

message OutlineNode {
  string id = 1;
  string name = 2;
  string description = 3;
}

message Character {
  string id = 1;
  string name = 2;
  repeated string traits = 3;
}

message TimelineEvent {
  string id = 1;
  string title = 2;
  string description = 3;
}

message ReviewResult {
  bool passed = 1;
  int32 quality_score = 2;
  repeated string issues = 3;
}

// æµæ°´çº¿æµå¼å“åº”
message PipelineStreamChunk {
  string stage = 1;  // outline, character, plot, review
  string message = 2;
  map<string, string> data = 3;
}

// å¥åº·æ£€æŸ¥
message HealthRequest {}

message HealthResponse {
  string status = 1;
  string version = 2;
}
```

### 1.2 gRPC Service å®ç°

```python
# src/grpc_server/ai_agent_service.py
import grpc
from concurrent import futures
from proto import ai_agent_service_pb2
from proto import ai_agent_service_pb2_grpc
from core.agents.workflows import create_creative_workflow, create_a2a_pipeline
from core.rag.smart_retriever import SmartRetriever
from utils.logging import get_logger

logger = get_logger(__name__)


class AIAgentServiceImpl(ai_agent_service_pb2_grpc.AIAgentServiceServicer):
    """AI Agent Service å®ç°"""
    
    def __init__(self, dependencies):
        self.creative_workflow = create_creative_workflow()
        self.a2a_pipeline = create_a2a_pipeline()
        self.smart_retriever = dependencies["smart_retriever"]
    
    async def ExecuteAgent(self, request, context):
        """æ‰§è¡Œ Agent"""
        try:
            logger.info(f"ExecuteAgent: {request.agent_type}")
            
            # æ ¹æ® agent_type é€‰æ‹©å·¥ä½œæµ
            if request.agent_type == "creative":
                result = await self._execute_creative(request)
            else:
                return ai_agent_service_pb2.AgentResponse(
                    success=False,
                    error=f"Unknown agent type: {request.agent_type}"
                )
            
            return ai_agent_service_pb2.AgentResponse(
                success=True,
                result=result.get("final_output", ""),
                metadata=result.get("output_metadata", {})
            )
            
        except Exception as e:
            logger.error(f"ExecuteAgent failed: {e}")
            return ai_agent_service_pb2.AgentResponse(
                success=False,
                error=str(e)
            )
    
    async def ExecuteAgentStream(self, request, context):
        """æµå¼æ‰§è¡Œ Agent"""
        try:
            # ä½¿ç”¨ astream_events æµå¼è¿”å›
            async for event in self.creative_workflow.astream_events(
                self._build_agent_state(request),
                version="v1"
            ):
                yield ai_agent_service_pb2.AgentStreamChunk(
                    chunk_type=event.get("event", ""),
                    content=str(event.get("data", "")),
                    metadata=event.get("metadata", {})
                )
                
        except Exception as e:
            logger.error(f"ExecuteAgentStream failed: {e}")
            yield ai_agent_service_pb2.AgentStreamChunk(
                chunk_type="error",
                content=str(e)
            )
    
    async def RAGSearch(self, request, context):
        """RAG æ£€ç´¢"""
        try:
            results = await self.smart_retriever.retrieve_for_agent(
                query=request.query,
                context={
                    "user_id": request.user_id,
                    "project_id": request.project_id
                }
            )
            
            rag_results = []
            for result in results.get("results", []):
                rag_results.append(
                    ai_agent_service_pb2.RAGResult(
                        content=result.get("content", ""),
                        score=result.get("score", 0),
                        content_type=result.get("content_type", ""),
                        document_id=result.get("document_id", ""),
                        source=result.get("source", {})
                    )
                )
            
            return ai_agent_service_pb2.RAGSearchResponse(
                results=rag_results,
                total=len(rag_results),
                metadata=results.get("retrieval_metadata", {})
            )
            
        except Exception as e:
            logger.error(f"RAGSearch failed: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(str(e))
            return ai_agent_service_pb2.RAGSearchResponse()
    
    async def ExecutePipeline(self, request, context):
        """æ‰§è¡Œ A2A æµæ°´çº¿"""
        try:
            result = await self.a2a_pipeline.ainvoke(
                self._build_pipeline_state(request)
            )
            
            # æ„å»ºå“åº”
            pipeline_result = ai_agent_service_pb2.PipelineResult(
                outline_nodes=[
                    ai_agent_service_pb2.OutlineNode(
                        id=node.get("id", ""),
                        name=node.get("name", ""),
                        description=node.get("description", "")
                    )
                    for node in result.get("outline_nodes", [])
                ],
                characters=[
                    ai_agent_service_pb2.Character(
                        id=char.get("id", ""),
                        name=char.get("name", ""),
                        traits=char.get("traits", [])
                    )
                    for char in result.get("characters", [])
                ],
                review_result=ai_agent_service_pb2.ReviewResult(
                    passed=result.get("review_passed", False),
                    quality_score=result.get("quality_score", 0)
                )
            )
            
            return ai_agent_service_pb2.PipelineResponse(
                success=True,
                result=pipeline_result
            )
            
        except Exception as e:
            logger.error(f"ExecutePipeline failed: {e}")
            return ai_agent_service_pb2.PipelineResponse(
                success=False,
                error=str(e)
            )
    
    async def Health(self, request, context):
        """å¥åº·æ£€æŸ¥"""
        return ai_agent_service_pb2.HealthResponse(
            status="healthy",
            version="1.0.0"
        )
```

---

## äºŒã€RESTful APIï¼ˆFastAPIï¼‰

### 2.1 API è·¯ç”±å®šä¹‰

```python
# src/api/routes/agent.py
from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel
from typing import Dict, Any, List, Optional
from sse_starlette.sse import EventSourceResponse
import asyncio

router = APIRouter(prefix="/api/v1/agents", tags=["AI Agents"])


class AgentExecuteRequest(BaseModel):
    """Agent æ‰§è¡Œè¯·æ±‚"""
    agent_type: str  # creative, outline, character
    task: str
    project_id: str
    parameters: Optional[Dict[str, Any]] = {}


class AgentExecuteResponse(BaseModel):
    """Agent æ‰§è¡Œå“åº”"""
    success: bool
    result: str
    metadata: Dict[str, Any]


@router.post("/execute", response_model=AgentExecuteResponse)
async def execute_agent(request: AgentExecuteRequest, user_id: str = Depends(get_current_user_id)):
    """æ‰§è¡Œ Agent"""
    from core.agents.workflows import create_creative_workflow
    
    workflow = create_creative_workflow()
    
    state = {
        "task": request.task,
        "user_id": user_id,
        "project_id": request.project_id,
        **request.parameters
    }
    
    result = await workflow.ainvoke(state)
    
    return AgentExecuteResponse(
        success=True,
        result=result.get("final_output", ""),
        metadata=result.get("output_metadata", {})
    )


@router.post("/execute/stream")
async def execute_agent_stream(request: AgentExecuteRequest, user_id: str = Depends(get_current_user_id)):
    """æµå¼æ‰§è¡Œ Agentï¼ˆSSEï¼‰"""
    from core.agents.workflows import create_creative_workflow
    
    workflow = create_creative_workflow()
    
    async def event_generator():
        try:
            async for event in workflow.astream_events({...}, version="v1"):
                yield {
                    "event": event.get("event"),
                    "data": event.get("data")
                }
        except Exception as e:
            yield {"event": "error", "data": str(e)}
    
    return EventSourceResponse(event_generator())


# RAG API
@router.post("/rag/search")
async def rag_search(
    query: str,
    project_id: str,
    top_k: int = 5,
    user_id: str = Depends(get_current_user_id)
):
    """RAG æ£€ç´¢"""
    # å®ç°é€»è¾‘
    pass


# A2A Pipeline API
@router.post("/pipeline/execute")
async def execute_pipeline(
    requirement: str,
    project_id: str,
    user_id: str = Depends(get_current_user_id)
):
    """æ‰§è¡Œ A2A åˆ›ä½œæµæ°´çº¿"""
    from core.agents.workflows import create_a2a_pipeline
    
    pipeline = create_a2a_pipeline()
    
    result = await pipeline.ainvoke({
        "user_requirement": requirement,
        "user_id": user_id,
        "project_id": project_id,
        "max_iterations": 3
    })
    
    return {
        "success": True,
        "outline_count": len(result.get("outline_nodes", [])),
        "character_count": len(result.get("characters", [])),
        "timeline_event_count": len(result.get("timeline_events", [])),
        "quality_score": result.get("quality_score", 0),
        "review_passed": result.get("review_passed", False)
    }
```

---

## ä¸‰ã€API æ–‡æ¡£ï¼ˆOpenAPI/Swaggerï¼‰

### 3.1 è‡ªåŠ¨ç”Ÿæˆæ–‡æ¡£

```python
# src/main.py
from fastapi import FastAPI
from fastapi.openapi.docs import get_swagger_ui_html

app = FastAPI(
    title="Qingyu AI Service",
    description="AI Agent æœåŠ¡ API",
    version="1.0.0"
)

# Swagger UI
@app.get("/docs", include_in_schema=False)
async def custom_swagger_ui_html():
    return get_swagger_ui_html(
        openapi_url="/openapi.json",
        title="Qingyu AI Service API"
    )
```

---

## å››ã€æ€»ç»“

æœ¬æ–‡æ¡£è®¾è®¡äº† Python AI Service çš„å®Œæ•´ APIï¼š

- âœ… gRPC Serviceï¼ˆ4 ä¸ªä¸»è¦ RPCï¼‰
- âœ… RESTful APIï¼ˆAgent æ‰§è¡Œã€RAG æ£€ç´¢ã€A2A æµæ°´çº¿ï¼‰
- âœ… æµå¼å“åº”æ”¯æŒï¼ˆgRPC Stream + SSEï¼‰
- âœ… API æ–‡æ¡£ï¼ˆOpenAPIï¼‰

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¶é—´**: 2025-10-27
**ç»´æŠ¤è€…**: AIæ¶æ„ç»„
