# 阶段 2.1：向量化引擎完善 - 实施计划

**日期**: 2025-10-28  
**状态**: 🚧 进行中  
**预计时间**: Week 2（2-3小时）

---

## 🎯 目标

在阶段1.3的基础上，完善向量化引擎，支持多模型、文本分块和性能优化，为RAG系统提供强大的向量化能力。

---

## 📋 核心任务

### 任务 1: 多模型支持（40分钟）

#### 1.1 创建模型管理器
**文件**: `python_ai_service/src/rag/embedding_manager.py`（新建）

**实现内容**:
- `EmbeddingManager` 类 - 统一的模型管理接口
- 支持的模型类型:
  - `local` - 本地模型（BGE等）
  - `openai` - OpenAI Embedding API
  - `custom` - 自定义模型

**核心方法**:
```python
class EmbeddingManager:
    def __init__(self, model_type: str, config: Dict):
        """初始化模型管理器"""
        
    async def embed_texts(self, texts: List[str]) -> List[List[float]]:
        """统一的文本向量化接口"""
        
    async def embed_query(self, query: str) -> List[float]:
        """统一的查询向量化接口"""
        
    def get_dimension(self) -> int:
        """获取向量维度"""
```

#### 1.2 实现 OpenAI Embedding
**文件**: `python_ai_service/src/rag/openai_embedding.py`（新建）

**实现内容**:
- 使用 OpenAI SDK
- 模型: `text-embedding-3-small` (1536维) 或 `text-embedding-3-large` (3072维)
- 批量处理（最大2048个token/请求）
- 重试机制
- 速率限制处理

---

### 任务 2: 文本分块策略（45分钟）

#### 2.1 创建文本分块器
**文件**: `python_ai_service/src/rag/text_splitter.py`（新建）

**实现内容**:
- `RecursiveCharacterTextSplitter` - 递归字符分块
  - 按段落、句子、字符分割
  - 支持中文分词
  - 智能重叠（overlap）
  
- `SemanticTextSplitter` - 语义分块（可选）
  - 基于embedding相似度分割
  - 保持语义完整性

**核心参数**:
```python
class TextSplitter:
    def __init__(
        self,
        chunk_size: int = 500,          # 块大小
        chunk_overlap: int = 50,        # 重叠大小
        separators: List[str] = None,   # 分隔符优先级
        length_function: Callable = len # 长度计算函数
    ):
        ...
        
    def split_text(self, text: str) -> List[str]:
        """分割文本"""
        
    def split_documents(
        self, 
        documents: List[Dict]
    ) -> List[Dict]:
        """分割文档（保留元数据）"""
```

#### 2.2 更新 MilvusClient
**文件**: `python_ai_service/src/rag/milvus_client.py`

**修改内容**:
- 支持文档级别插入（自动分块）
- 添加 `chunk_id` 和 `document_id` 字段
- 支持按文档ID查询所有chunk
- 支持按文档ID删除所有chunk

---

### 任务 3: 模型缓存机制（30分钟）

#### 3.1 实现模型缓存
**文件**: `python_ai_service/src/rag/embedding_cache.py`（新建）

**实现内容**:
- Redis缓存层
  - Key: `embed:{model}:{text_hash}`
  - Value: 向量JSON
  - TTL: 7天（可配置）
  
- 内存LRU缓存
  - 大小: 1000条（可配置）
  - 快速访问常用向量

**核心方法**:
```python
class EmbeddingCache:
    def __init__(self, redis_client=None, lru_size: int = 1000):
        """初始化缓存"""
        
    async def get(self, text: str, model: str) -> Optional[List[float]]:
        """获取缓存的向量"""
        
    async def set(
        self, 
        text: str, 
        model: str, 
        embedding: List[float],
        ttl: int = 604800  # 7天
    ):
        """设置缓存"""
        
    async def get_batch(
        self, 
        texts: List[str], 
        model: str
    ) -> Dict[str, List[float]]:
        """批量获取"""
```

#### 3.2 集成到 EmbeddingManager
**修改**: `python_ai_service/src/rag/embedding_manager.py`

- 在 `embed_texts()` 中添加缓存查询
- 缓存未命中时调用模型
- 缓存新生成的向量

---

### 任务 4: 性能优化（25分钟）

#### 4.1 异步处理
**实现内容**:
- 所有网络调用改为异步（OpenAI API、Redis）
- 使用 `asyncio.gather()` 并发处理
- 批量操作优化

#### 4.2 批量处理优化
**实现内容**:
- 动态batch size（根据文本长度）
- 进度回调（大批量处理）
- 内存管理（避免OOM）

#### 4.3 性能监控
**文件**: `python_ai_service/src/core/metrics.py`（更新）

**添加指标**:
- `embedding_duration_seconds` - 向量化耗时
- `embedding_cache_hit_rate` - 缓存命中率
- `embedding_batch_size` - 批量大小
- `embedding_token_count` - Token数量

---

### 任务 5: 配置管理（10分钟）

#### 5.1 更新配置
**文件**: `python_ai_service/src/core/config.py`

**添加配置项**:
```python
class Settings(BaseSettings):
    # 向量化配置
    embedding_provider: str = "local"  # local, openai, custom
    embedding_model_name: str = "BAAI/bge-large-zh-v1.5"
    embedding_cache_enabled: bool = True
    embedding_cache_ttl: int = 604800  # 7天
    
    # OpenAI配置
    openai_embedding_model: str = "text-embedding-3-small"
    openai_embedding_batch_size: int = 100
    openai_embedding_max_retries: int = 3
    
    # 文本分块配置
    text_chunk_size: int = 500
    text_chunk_overlap: int = 50
    text_splitter_type: str = "recursive"  # recursive, semantic
```

---

### 任务 6: 测试与文档（40分钟）

#### 6.1 单元测试
**文件**: `python_ai_service/tests/test_embedding_manager.py`（新建）

**测试用例**:
- 测试本地模型加载
- 测试OpenAI模型调用（Mock）
- 测试模型切换
- 测试错误处理

#### 6.2 集成测试
**文件**: `python_ai_service/tests/test_text_splitter.py`（新建）

**测试用例**:
- 测试中文文本分块
- 测试重叠策略
- 测试元数据保留

#### 6.3 性能测试
**文件**: `python_ai_service/tests/test_embedding_performance.py`（新建）

**测试场景**:
- 100条文本批量向量化（耗时）
- 缓存命中率测试
- 并发处理测试

#### 6.4 中文文档
**文件**: `doc/implementation/00进度指导/阶段2.1_向量化引擎完善_实施报告.md`（新建）

**文档结构**:
```markdown
# 阶段 2.1：向量化引擎完善实施报告

## 实施概览
- 实施日期
- 核心成果
- 技术亮点

## 多模型支持
- 模型管理器设计
- OpenAI Embedding 集成
- 模型切换机制

## 文本分块策略
- 分块算法说明
- 最佳实践
- 使用示例

## 缓存机制
- Redis 缓存层
- LRU 内存缓存
- 性能提升

## 性能优化
- 异步处理
- 批量优化
- 监控指标

## 使用指南
- 配置说明
- API 示例
- 故障排查

## 性能测试结果
- 向量化速度
- 缓存命中率
- 资源消耗

## 后续规划
- 阶段 2.2：结构化 RAG
```

---

## 🗂️ 文件清单

### 新建文件（7个）
1. `python_ai_service/src/rag/embedding_manager.py` - 模型管理器
2. `python_ai_service/src/rag/openai_embedding.py` - OpenAI集成
3. `python_ai_service/src/rag/text_splitter.py` - 文本分块器
4. `python_ai_service/src/rag/embedding_cache.py` - 缓存管理
5. `python_ai_service/tests/test_embedding_manager.py` - 单元测试
6. `python_ai_service/tests/test_text_splitter.py` - 分块测试
7. `python_ai_service/tests/test_embedding_performance.py` - 性能测试

### 更新文件（3个）
8. `python_ai_service/src/rag/milvus_client.py` - 添加文档级操作
9. `python_ai_service/src/core/config.py` - 添加配置项
10. `python_ai_service/src/core/metrics.py` - 添加监控指标

### 文档文件（1个）
11. `doc/implementation/00进度指导/阶段2.1_向量化引擎完善_实施报告.md`

---

## ⏱️ 时间分配

| 任务 | 预计时间 | 优先级 |
|------|---------|-------|
| 1. 多模型支持 | 40分钟 | P0 |
| 2. 文本分块策略 | 45分钟 | P0 |
| 3. 模型缓存机制 | 30分钟 | P1 |
| 4. 性能优化 | 25分钟 | P1 |
| 5. 配置管理 | 10分钟 | P0 |
| 6. 测试与文档 | 40分钟 | P0 |
| **总计** | **2.5小时** | |

---

## ✅ 验收标准

- [ ] EmbeddingManager 支持至少2种模型（local + openai）
- [ ] 文本分块器正确处理中文
- [ ] 缓存机制工作正常（Redis + LRU）
- [ ] 所有单元测试通过
- [ ] 性能测试达标：
  - 100条文本向量化 < 10秒（本地模型）
  - 缓存命中率 > 80%（重复查询场景）
- [ ] 中文文档完整清晰
- [ ] 代码无 lint 错误

---

## 🔧 技术要点

### 多模型抽象

```python
# 统一接口，屏蔽底层差异
manager = EmbeddingManager("openai", config)
embeddings = await manager.embed_texts(texts)

# 切换模型只需修改配置
manager = EmbeddingManager("local", config)
```

### 智能分块

```python
# 递归分块：段落 → 句子 → 字符
splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50,
    separators=["\n\n", "\n", "。", "！", "？", " "]
)
chunks = splitter.split_text(long_text)
```

### 多级缓存

```text
查询流程：
1. 检查内存LRU缓存（毫秒级）
2. 检查Redis缓存（毫秒级）
3. 调用模型（秒级）
4. 更新缓存
```

---

## 📊 预期成果

**代码量**: ~800行
- EmbeddingManager: ~200行
- OpenAI Embedding: ~150行
- TextSplitter: ~200行
- EmbeddingCache: ~150行
- Tests: ~100行

**性能提升**:
- 缓存命中时：10x-100x 加速
- 批量处理：5x 加速
- 异步并发：3x 加速

**功能完善度**:
- 模型支持：2+ 种
- 分块策略：递归分块
- 缓存层级：2 层（内存+Redis）

---

## 🚀 下一步

完成阶段2.1后，将进入：

**阶段 2.2：结构化 RAG 实现**（Week 3）
- RAGPipeline 类
- Reranker 集成
- 混合检索（向量+关键词）
- 上下文组装

---

**创建日期**: 2025-10-28  
**预计完成**: 2025-10-28  
**维护者**: 青羽后端架构团队

