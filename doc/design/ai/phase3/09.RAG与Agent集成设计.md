# RAG ä¸ Agent é›†æˆè®¾è®¡

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0
> **åˆ›å»ºæ—¶é—´**: 2025-10-27
> **å®æ–½çŠ¶æ€**: è®¾è®¡é˜¶æ®µ
> **è´Ÿè´£äºº**: AIæ¶æ„ç»„

---

## ğŸ“‹ æ–‡æ¡£æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è®¾è®¡ RAG ç³»ç»Ÿä¸ Agent çš„é›†æˆæ–¹æ¡ˆï¼ŒåŒ…æ‹¬ RAG Tool å°è£…ã€ä¸Šä¸‹æ–‡æ„å»ºã€Prompt å¢å¼ºã€å¼•ç”¨æ ‡æ³¨å’Œç¼“å­˜ç­–ç•¥ã€‚

---

## ä¸€ã€RAG Tool å¢å¼ºå°è£…

### 1.1 æ™ºèƒ½æ£€ç´¢ç­–ç•¥

```python
# src/core/rag/smart_retriever.py
from typing import List, Dict, Any, Optional
from core.rag.retriever import HybridSearchEngine
from core.rag.query_analyzer import QueryAnalyzer
from utils.logging import get_logger

logger = get_logger(__name__)


class SmartRetriever:
    """æ™ºèƒ½æ£€ç´¢å™¨ï¼ˆAgent ä¸“ç”¨ï¼‰"""
    
    def __init__(self, search_engine: HybridSearchEngine):
        self.search_engine = search_engine
        self.query_analyzer = QueryAnalyzer()
    
    async def retrieve_for_agent(
        self,
        query: str,
        context: Dict[str, Any],
        retrieval_mode: str = "auto"  # auto, semantic, keyword, hybrid
    ) -> Dict[str, Any]:
        """ä¸º Agent æ£€ç´¢ä¿¡æ¯
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            context: Agent ä¸Šä¸‹æ–‡ï¼ˆproject_id, user_id ç­‰ï¼‰
            retrieval_mode: æ£€ç´¢æ¨¡å¼
            
        Returns:
            æ£€ç´¢ç»“æœ + å…ƒæ•°æ®
        """
        project_id = context.get("project_id")
        
        # 1. åˆ†ææŸ¥è¯¢æ„å›¾
        query_info = self.query_analyzer.analyze(query)
        
        # 2. ç¡®å®šæ£€ç´¢æ¨¡å¼
        if retrieval_mode == "auto":
            retrieval_mode = self._determine_retrieval_mode(query_info)
        
        # 3. åŠ¨æ€è°ƒæ•´ top_k
        top_k = self._calculate_top_k(query_info)
        
        # 4. ç¡®å®šå†…å®¹ç±»å‹è¿‡æ»¤
        content_types = self._determine_content_types(query_info)
        
        # 5. æ‰§è¡Œæ£€ç´¢
        results = await self.search_engine.search(
            query=query,
            user_id=context.get("user_id"),
            project_id=project_id,
            top_k=top_k,
            content_types=content_types,
            enable_hybrid=(retrieval_mode == "hybrid")
        )
        
        # 6. åå¤„ç†
        processed_results = self._post_process_results(results, query_info)
        
        return {
            "results": processed_results,
            "retrieval_metadata": {
                "mode": retrieval_mode,
                "query_intent": query_info.get("intent"),
                "content_types": content_types,
                "top_k": top_k,
                "total_found": len(results)
            }
        }
    
    def _determine_retrieval_mode(self, query_info: Dict) -> str:
        """ç¡®å®šæ£€ç´¢æ¨¡å¼"""
        intent = query_info.get("intent", "general")
        
        # ç²¾ç¡®æŸ¥æ‰¾ -> å…³é”®è¯
        if intent in ["find_specific", "lookup"]:
            return "keyword"
        
        # æ¦‚å¿µç†è§£ -> è¯­ä¹‰
        elif intent in ["understand", "explore"]:
            return "semantic"
        
        # é»˜è®¤æ··åˆ
        return "hybrid"
    
    def _calculate_top_k(self, query_info: Dict) -> int:
        """åŠ¨æ€è®¡ç®— top_k"""
        complexity = query_info.get("complexity", "medium")
        
        if complexity == "simple":
            return 3
        elif complexity == "complex":
            return 10
        else:
            return 5
    
    def _determine_content_types(self, query_info: Dict) -> Optional[List[str]]:
        """ç¡®å®šå†…å®¹ç±»å‹è¿‡æ»¤"""
        entities = query_info.get("entities", [])
        
        # å¦‚æœæåˆ°è§’è‰² -> åªæ£€ç´¢è§’è‰²ç›¸å…³
        if any(e["type"] == "character" for e in entities):
            return ["character", "character_relation"]
        
        # å¦‚æœæåˆ°å¤§çº²ã€ç« èŠ‚ -> åªæ£€ç´¢å¤§çº²
        if any(e["type"] in ["outline", "chapter"] for e in entities):
            return ["outline"]
        
        # å¦åˆ™ä¸è¿‡æ»¤
        return None
    
    def _post_process_results(self, results: List, query_info: Dict) -> List[Dict]:
        """åå¤„ç†æ£€ç´¢ç»“æœ"""
        processed = []
        
        for result in results:
            processed.append({
                "content": result.chunk_text,
                "score": result.score,
                "content_type": result.metadata.get("content_type"),
                "document_id": result.document_id,
                "source": {
                    "type": result.metadata.get("content_type"),
                    "name": result.metadata.get("title", "æœªçŸ¥"),
                    "id": result.document_id
                },
                "highlights": result.highlights
            })
        
        return processed
```

### 1.2 æŸ¥è¯¢åˆ†æå™¨

```python
# src/core/rag/query_analyzer.py
from typing import Dict, List, Any
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
import json


class QueryAnalyzer:
    """æŸ¥è¯¢åˆ†æå™¨"""
    
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
    
    async def analyze(self, query: str) -> Dict[str, Any]:
        """åˆ†ææŸ¥è¯¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            
        Returns:
            æŸ¥è¯¢åˆ†æç»“æœ
        """
        system_message = SystemMessage(content="""
åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œæå–å…³é”®ä¿¡æ¯ã€‚

è¾“å‡ºæ ¼å¼ï¼šJSON
{
  "intent": "find_specific",  // find_specific, understand, explore, compare
  "complexity": "simple",     // simple, medium, complex
  "entities": [
    {"type": "character", "value": "å¼ ä¸‰"},
    {"type": "chapter", "value": "ç¬¬ä¸€ç« "}
  ],
  "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"]
}
""")
        
        user_message = HumanMessage(content=f"æŸ¥è¯¢ï¼š{query}")
        
        response = await self.llm.ainvoke([system_message, user_message])
        
        try:
            return json.loads(response.content)
        except:
            return {
                "intent": "general",
                "complexity": "medium",
                "entities": [],
                "keywords": []
            }
```

---

## äºŒã€ä¸Šä¸‹æ–‡æ„å»ºç­–ç•¥

### 2.1 Context Builder

```python
# src/core/rag/context_builder.py
from typing import List, Dict, Any
from utils.logging import get_logger

logger = get_logger(__name__)


class ContextBuilder:
    """ä¸Šä¸‹æ–‡æ„å»ºå™¨"""
    
    def __init__(self, max_context_length: int = 4000):
        self.max_context_length = max_context_length
    
    def build_context(
        self,
        query: str,
        rag_results: List[Dict[str, Any]],
        context_type: str = "standard"  # standard, detailed, summary
    ) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡
        
        Args:
            query: æŸ¥è¯¢
            rag_results: RAG æ£€ç´¢ç»“æœ
            context_type: ä¸Šä¸‹æ–‡ç±»å‹
            
        Returns:
            æ„å»ºçš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        if context_type == "standard":
            return self._build_standard_context(rag_results)
        elif context_type == "detailed":
            return self._build_detailed_context(rag_results)
        elif context_type == "summary":
            return self._build_summary_context(rag_results)
        else:
            return self._build_standard_context(rag_results)
    
    def _build_standard_context(self, results: List[Dict]) -> str:
        """æ„å»ºæ ‡å‡†ä¸Šä¸‹æ–‡"""
        if not results:
            return ""
        
        context_parts = ["ã€å‚è€ƒèµ„æ–™ã€‘\n"]
        
        for i, result in enumerate(results, 1):
            source = result.get("source", {})
            content = result.get("content", "")
            
            # é•¿åº¦é™åˆ¶
            if len(content) > 500:
                content = content[:500] + "..."
            
            context_parts.append(f"""
{i}. ã€{source.get('type', 'æœªçŸ¥')}ã€‘{source.get('name', '')}
{content}
---
""")
        
        full_context = "\n".join(context_parts)
        
        # æ€»é•¿åº¦é™åˆ¶
        if len(full_context) > self.max_context_length:
            full_context = full_context[:self.max_context_length] + "\n...(å†…å®¹å·²æˆªæ–­)"
        
        return full_context
    
    def _build_detailed_context(self, results: List[Dict]) -> str:
        """æ„å»ºè¯¦ç»†ä¸Šä¸‹æ–‡ï¼ˆåŒ…å«å…ƒæ•°æ®ï¼‰"""
        if not results:
            return ""
        
        context_parts = ["ã€è¯¦ç»†å‚è€ƒèµ„æ–™ã€‘\n"]
        
        for i, result in enumerate(results, 1):
            source = result.get("source", {})
            content = result.get("content", "")
            score = result.get("score", 0)
            
            context_parts.append(f"""
â”â”â” èµ„æ–™ {i} â”â”â”
ç±»å‹ï¼š{source.get('type', 'æœªçŸ¥')}
åç§°ï¼š{source.get('name', '')}
ç›¸å…³åº¦ï¼š{score:.2f}

å†…å®¹ï¼š
{content}

â”â”â”â”â”â”â”â”â”â”â”â”â”
""")
        
        return "\n".join(context_parts)
    
    def _build_summary_context(self, results: List[Dict]) -> str:
        """æ„å»ºæ‘˜è¦ä¸Šä¸‹æ–‡"""
        if not results:
            return ""
        
        # æŒ‰å†…å®¹ç±»å‹åˆ†ç»„
        by_type = {}
        for result in results:
            content_type = result.get("source", {}).get("type", "å…¶ä»–")
            if content_type not in by_type:
                by_type[content_type] = []
            by_type[content_type].append(result)
        
        context_parts = ["ã€å‚è€ƒèµ„æ–™æ‘˜è¦ã€‘\n"]
        
        for content_type, items in by_type.items():
            context_parts.append(f"\nã€{content_type}ã€‘ï¼ˆ{len(items)}æ¡ï¼‰")
            for item in items[:3]:  # æ¯ç±»æœ€å¤š3æ¡
                name = item.get("source", {}).get("name", "")
                content = item.get("content", "")[:100]
                context_parts.append(f"- {name}: {content}...")
        
        return "\n".join(context_parts)
```

---

## ä¸‰ã€Prompt å¢å¼ºæ¨¡æ¿

### 3.1 Prompt Enhancer

```python
# src/core/rag/prompt_enhancer.py
from typing import Dict, Any, Optional


class PromptEnhancer:
    """Prompt å¢å¼ºå™¨"""
    
    @staticmethod
    def enhance_prompt(
        original_prompt: str,
        rag_context: str,
        enhancement_type: str = "standard"
    ) -> str:
        """å¢å¼º Prompt
        
        Args:
            original_prompt: åŸå§‹ Prompt
            rag_context: RAG ä¸Šä¸‹æ–‡
            enhancement_type: å¢å¼ºç±»å‹
            
        Returns:
            å¢å¼ºåçš„ Prompt
        """
        if enhancement_type == "standard":
            return PromptEnhancer._standard_enhancement(original_prompt, rag_context)
        elif enhancement_type == "creative":
            return PromptEnhancer._creative_enhancement(original_prompt, rag_context)
        elif enhancement_type == "analytical":
            return PromptEnhancer._analytical_enhancement(original_prompt, rag_context)
        else:
            return original_prompt
    
    @staticmethod
    def _standard_enhancement(prompt: str, context: str) -> str:
        """æ ‡å‡†å¢å¼º"""
        if not context:
            return prompt
        
        return f"""
{context}

åŸºäºä»¥ä¸Šå‚è€ƒèµ„æ–™ï¼Œ{prompt}

è¦æ±‚ï¼š
1. å……åˆ†å‚è€ƒèµ„æ–™ä¸­çš„ä¿¡æ¯
2. ä¿æŒä¸å·²æœ‰è®¾å®šä¸€è‡´
3. å¦‚æœèµ„æ–™ä¸­æœ‰ç›¸å…³å†…å®¹ï¼Œè¯·ä¼˜å…ˆä½¿ç”¨
"""
    
    @staticmethod
    def _creative_enhancement(prompt: str, context: str) -> str:
        """åˆ›ä½œå¢å¼º"""
        if not context:
            return prompt
        
        return f"""
{context}

åˆ›ä½œä»»åŠ¡ï¼š{prompt}

åˆ›ä½œæŒ‡å—ï¼š
1. å‚è€ƒèµ„æ–™ä»…ä½œå‚è€ƒï¼Œå¯ä»¥åˆ›æ–°
2. ä¿æŒè§’è‰²æ€§æ ¼ä¸€è‡´
3. ç¡®ä¿æƒ…èŠ‚ç¬¦åˆå¤§çº²
4. ä¿æŒä¸–ç•Œè§‚è®¾å®šç»Ÿä¸€
"""
    
    @staticmethod
    def _analytical_enhancement(prompt: str, context: str) -> str:
        """åˆ†æå¢å¼º"""
        if not context:
            return prompt
        
        return f"""
{context}

åˆ†æä»»åŠ¡ï¼š{prompt}

åˆ†æè¦æ±‚ï¼š
1. åŸºäºå‚è€ƒèµ„æ–™è¿›è¡Œåˆ†æ
2. æŒ‡å‡ºèµ„æ–™ä¸­çš„å…³é”®ä¿¡æ¯
3. æä¾›æ•°æ®æ”¯æŒ
4. ç»™å‡ºåˆç†æ¨ç†
"""
```

---

## å››ã€å¼•ç”¨æ ‡æ³¨å’Œæº¯æº

### 4.1 Citation Manager

```python
# src/core/rag/citation_manager.py
from typing import List, Dict, Any
import re


class CitationManager:
    """å¼•ç”¨æ ‡æ³¨ç®¡ç†å™¨"""
    
    @staticmethod
    def add_citations(
        generated_text: str,
        rag_results: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """æ·»åŠ å¼•ç”¨æ ‡æ³¨
        
        Args:
            generated_text: ç”Ÿæˆçš„æ–‡æœ¬
            rag_results: RAG æ£€ç´¢ç»“æœ
            
        Returns:
            åŒ…å«å¼•ç”¨çš„ç»“æœ
        """
        citations = []
        
        # å°è¯•åŒ¹é…ç”Ÿæˆæ–‡æœ¬ä¸­çš„å†…å®¹ä¸ RAG ç»“æœ
        for i, result in enumerate(rag_results, 1):
            source_content = result.get("content", "")
            
            # ç®€å•åŒ¹é…ï¼ˆå®é™…åº”è¯¥ç”¨æ›´å¤æ‚çš„ç®—æ³•ï¼‰
            if CitationManager._is_content_used(generated_text, source_content):
                citation = {
                    "id": i,
                    "source": result.get("source"),
                    "relevance": result.get("score", 0)
                }
                citations.append(citation)
        
        return {
            "text": generated_text,
            "citations": citations,
            "citation_count": len(citations)
        }
    
    @staticmethod
    def _is_content_used(generated: str, source: str) -> bool:
        """æ£€æµ‹å†…å®¹æ˜¯å¦è¢«ä½¿ç”¨"""
        # ç®€åŒ–å®ç°ï¼šæ£€æµ‹æ˜¯å¦æœ‰å¤§æ®µç›¸ä¼¼æ–‡æœ¬
        # å®é™…åº”è¯¥ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦æˆ– n-gram åŒ¹é…
        
        # æå–å…³é”®çŸ­è¯­ï¼ˆ3-gramï¼‰
        def get_ngrams(text: str, n: int = 3) -> set:
            words = text.split()
            return set(" ".join(words[i:i+n]) for i in range(len(words)-n+1))
        
        generated_ngrams = get_ngrams(generated)
        source_ngrams = get_ngrams(source)
        
        # è®¡ç®—äº¤é›†
        intersection = generated_ngrams & source_ngrams
        
        # å¦‚æœæœ‰è¶…è¿‡ 2 ä¸ªç›¸åŒçš„ 3-gramï¼Œè®¤ä¸ºä½¿ç”¨äº†è¯¥èµ„æ–™
        return len(intersection) >= 2
    
    @staticmethod
    def format_citations(citations: List[Dict]) -> str:
        """æ ¼å¼åŒ–å¼•ç”¨
        
        Args:
            citations: å¼•ç”¨åˆ—è¡¨
            
        Returns:
            æ ¼å¼åŒ–çš„å¼•ç”¨æ–‡æœ¬
        """
        if not citations:
            return ""
        
        formatted = ["\n\nã€å‚è€ƒæ¥æºã€‘"]
        
        for citation in citations:
            source = citation.get("source", {})
            formatted.append(
                f"[{citation['id']}] {source.get('type', 'æœªçŸ¥')} - {source.get('name', 'æœªçŸ¥')}"
            )
        
        return "\n".join(formatted)
```

---

## äº”ã€æ£€ç´¢ç»“æœç¼“å­˜

### 5.1 RAG Cache

```python
# src/core/rag/cache.py
from typing import Optional, List, Dict, Any
import hashlib
import json
from datetime import datetime, timedelta
from utils.logging import get_logger

logger = get_logger(__name__)


class RAGCache:
    """RAG æ£€ç´¢ç¼“å­˜"""
    
    def __init__(self, redis_client, ttl_seconds: int = 3600):
        """åˆå§‹åŒ–
        
        Args:
            redis_client: Redis å®¢æˆ·ç«¯
            ttl_seconds: ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.redis = redis_client
        self.ttl = ttl_seconds
    
    def _generate_cache_key(
        self,
        query: str,
        project_id: str,
        content_types: Optional[List[str]]
    ) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_data = {
            "query": query,
            "project_id": project_id,
            "content_types": sorted(content_types) if content_types else []
        }
        
        key_str = json.dumps(key_data, sort_keys=True)
        hash_key = hashlib.md5(key_str.encode()).hexdigest()
        
        return f"rag_cache:{project_id}:{hash_key}"
    
    async def get(
        self,
        query: str,
        project_id: str,
        content_types: Optional[List[str]] = None
    ) -> Optional[List[Dict[str, Any]]]:
        """è·å–ç¼“å­˜
        
        Returns:
            ç¼“å­˜çš„æ£€ç´¢ç»“æœï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
        """
        cache_key = self._generate_cache_key(query, project_id, content_types)
        
        try:
            cached_data = await self.redis.get(cache_key)
            
            if cached_data:
                logger.info(f"RAG cache hit: {cache_key}")
                return json.loads(cached_data)
            else:
                logger.info(f"RAG cache miss: {cache_key}")
                return None
                
        except Exception as e:
            logger.error(f"RAG cache get failed: {e}")
            return None
    
    async def set(
        self,
        query: str,
        project_id: str,
        content_types: Optional[List[str]],
        results: List[Dict[str, Any]]
    ):
        """è®¾ç½®ç¼“å­˜"""
        cache_key = self._generate_cache_key(query, project_id, content_types)
        
        try:
            await self.redis.setex(
                cache_key,
                self.ttl,
                json.dumps(results)
            )
            logger.info(f"RAG cache set: {cache_key}")
            
        except Exception as e:
            logger.error(f"RAG cache set failed: {e}")
    
    async def invalidate_project(self, project_id: str):
        """ä½¿é¡¹ç›®çš„æ‰€æœ‰ç¼“å­˜å¤±æ•ˆ"""
        pattern = f"rag_cache:{project_id}:*"
        
        try:
            keys = await self.redis.keys(pattern)
            if keys:
                await self.redis.delete(*keys)
                logger.info(f"Invalidated {len(keys)} RAG cache entries for project {project_id}")
                
        except Exception as e:
            logger.error(f"RAG cache invalidation failed: {e}")
```

---

## å…­ã€ä¸ Agent é›†æˆ

### 6.1 Agent RAG Mixin

```python
# src/core/agents/mixins/rag_mixin.py
from typing import Dict, Any, Optional
from core.rag.smart_retriever import SmartRetriever
from core.rag.context_builder import ContextBuilder
from core.rag.prompt_enhancer import PromptEnhancer


class RAGMixin:
    """Agent RAG æ··å…¥ï¼ˆä¸º Agent æ·»åŠ  RAG èƒ½åŠ›ï¼‰"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.smart_retriever: Optional[SmartRetriever] = None
        self.context_builder = ContextBuilder()
        self.prompt_enhancer = PromptEnhancer()
    
    async def retrieve_context(
        self,
        query: str,
        state: Dict[str, Any],
        retrieval_mode: str = "auto",
        context_type: str = "standard"
    ) -> Dict[str, Any]:
        """æ£€ç´¢å¹¶æ„å»ºä¸Šä¸‹æ–‡
        
        Args:
            query: æŸ¥è¯¢
            state: Agent çŠ¶æ€
            retrieval_mode: æ£€ç´¢æ¨¡å¼
            context_type: ä¸Šä¸‹æ–‡ç±»å‹
            
        Returns:
            åŒ…å«ä¸Šä¸‹æ–‡å’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        if not self.smart_retriever:
            return {"context": "", "metadata": {}}
        
        # æ£€ç´¢
        retrieval_result = await self.smart_retriever.retrieve_for_agent(
            query=query,
            context={
                "project_id": state.get("project_id"),
                "user_id": state.get("user_id")
            },
            retrieval_mode=retrieval_mode
        )
        
        rag_results = retrieval_result.get("results", [])
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context = self.context_builder.build_context(
            query=query,
            rag_results=rag_results,
            context_type=context_type
        )
        
        return {
            "context": context,
            "rag_results": rag_results,
            "metadata": retrieval_result.get("retrieval_metadata", {})
        }
    
    def enhance_prompt_with_rag(
        self,
        prompt: str,
        rag_context: str,
        enhancement_type: str = "standard"
    ) -> str:
        """ä½¿ç”¨ RAG å¢å¼º Prompt"""
        return self.prompt_enhancer.enhance_prompt(
            original_prompt=prompt,
            rag_context=rag_context,
            enhancement_type=enhancement_type
        )
```

### 6.2 ä½¿ç”¨ç¤ºä¾‹

```python
# åœ¨ Agent èŠ‚ç‚¹ä¸­ä½¿ç”¨ RAG
from core.agents.mixins.rag_mixin import RAGMixin

class EnhancedCreativeAgent(RAGMixin):
    """å¢å¼ºçš„åˆ›ä½œ Agentï¼ˆå¸¦ RAGï¼‰"""
    
    async def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
        task = state["task"]
        
        # 1. RAG æ£€ç´¢
        rag_data = await self.retrieve_context(
            query=task,
            state=state,
            retrieval_mode="auto",
            context_type="standard"
        )
        
        # 2. å¢å¼º Prompt
        enhanced_prompt = self.enhance_prompt_with_rag(
            prompt=task,
            rag_context=rag_data["context"],
            enhancement_type="creative"
        )
        
        # 3. è°ƒç”¨ LLM ç”Ÿæˆ
        # ...
        
        return {
            **state,
            "rag_context": rag_data["context"],
            "rag_metadata": rag_data["metadata"]
        }
```

---

## ä¸ƒã€æ€»ç»“

æœ¬æ–‡æ¡£è¯¦ç»†è®¾è®¡äº† RAG ä¸ Agent çš„é›†æˆæ–¹æ¡ˆï¼ŒåŒ…æ‹¬ï¼š

- âœ… æ™ºèƒ½æ£€ç´¢ç­–ç•¥ï¼ˆæŸ¥è¯¢åˆ†æã€åŠ¨æ€ top_kï¼‰
- âœ… ä¸Šä¸‹æ–‡æ„å»ºï¼ˆæ ‡å‡†ã€è¯¦ç»†ã€æ‘˜è¦ï¼‰
- âœ… Prompt å¢å¼ºï¼ˆæ ‡å‡†ã€åˆ›ä½œã€åˆ†æï¼‰
- âœ… å¼•ç”¨æ ‡æ³¨å’Œæº¯æº
- âœ… æ£€ç´¢ç»“æœç¼“å­˜
- âœ… Agent RAG Mixin

**å…³é”®ç‰¹æ€§**ï¼š
- æŸ¥è¯¢æ„å›¾åˆ†æ
- åŠ¨æ€æ£€ç´¢ç­–ç•¥
- å¤šç§ä¸Šä¸‹æ–‡æ ¼å¼
- å®Œæ•´çš„å¼•ç”¨è¿½è¸ª
- é«˜æ•ˆçš„ç¼“å­˜æœºåˆ¶

**åç»­å·¥ä½œ**ï¼š
- ä¼˜åŒ–æ£€ç´¢ç®—æ³•
- å®Œå–„å¼•ç”¨æ£€æµ‹
- æ€§èƒ½ä¼˜åŒ–

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¶é—´**: 2025-10-27
**ç»´æŠ¤è€…**: AIæ¶æ„ç»„
