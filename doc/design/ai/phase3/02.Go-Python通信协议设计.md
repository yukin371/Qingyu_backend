# Go-Python 通信协议设计

> **文档版本**: v1.0  
> **创建时间**: 2025-10-27  
> **实施状态**: 设计阶段  
> **负责人**: AI架构组

---

## 📋 文档概述

本文档详细设计 Go 后端与 Python AI 服务之间的通信协议，包括 gRPC Proto 定义、Go AI Proxy Service 实现、流式响应代理、错误处理等关键机制。

**适用范围**：
- gRPC 协议定义
- Go AI Proxy Service 实现
- 流式响应代理机制
- 认证授权传递
- 超时控制和重试策略

---

## 🎯 设计目标

### 核心目标

1. **高性能通信**：基于 gRPC，支持双向流式传输
2. **统一协议**：标准化的请求/响应格式
3. **流式代理**：支持 SSE/WebSocket 流式响应
4. **完整错误处理**：gRPC 错误到 Go 错误的完整转换
5. **安全传递**：JWT Token 和用户上下文的安全传递

### 非目标

- ❌ 不重新发明轮子（使用 gRPC 标准功能）
- ❌ 不实现自定义加密（依赖 TLS）

---

## 一、gRPC Proto 定义

### 1.1 Proto 文件结构

```
proto/
├── common.proto          # 通用消息定义
├── ai_agent.proto        # Agent 服务
├── rag.proto             # RAG 服务
└── tool.proto            # 工具服务
```

### 1.2 common.proto

```protobuf
// proto/common.proto
syntax = "proto3";

package qingyu.ai.common;

option go_package = "Qingyu_backend/proto/ai/common";

// 通用响应状态
message Status {
  int32 code = 1;           // 状态码
  string message = 2;       // 消息
  string details = 3;       // 详细信息
}

// 元数据
message Metadata {
  string request_id = 1;    // 请求 ID
  string user_id = 2;       // 用户 ID
  string project_id = 3;    // 项目 ID
  int64 timestamp = 4;      // 时间戳
  map<string, string> extra = 5;  // 额外信息
}

// 工具调用记录
message ToolCall {
  string tool_name = 1;     // 工具名称
  string parameters = 2;    // 参数（JSON 格式）
  string result = 3;        // 结果（JSON 格式）
  int64 duration_ms = 4;    // 执行时长（毫秒）
  Status status = 5;        // 执行状态
}

// 消息（对话）
message Message {
  string role = 1;          // 角色：system/user/assistant
  string content = 2;       // 内容
  map<string, string> metadata = 3;  // 元数据
}
```

### 1.3 ai_agent.proto

```protobuf
// proto/ai_agent.proto
syntax = "proto3";

package qingyu.ai.agent;

import "common.proto";

option go_package = "Qingyu_backend/proto/ai/agent";

// Agent 服务
service AIAgentService {
  // 执行 Agent（同步）
  rpc ExecuteAgent(AgentRequest) returns (AgentResponse);
  
  // 执行 Agent（流式）
  rpc ExecuteAgentStream(AgentRequest) returns (stream AgentStreamChunk);
  
  // 对话（同步）
  rpc Chat(ChatRequest) returns (ChatResponse);
  
  // 对话（流式）
  rpc ChatStream(ChatRequest) returns (stream ChatStreamChunk);
  
  // 健康检查
  rpc HealthCheck(HealthRequest) returns (HealthResponse);
}

// Agent 执行请求
message AgentRequest {
  string agent_type = 1;           // Agent 类型：creative, outline, character, plot, review
  string task = 2;                 // 任务描述
  map<string, string> context = 3; // 上下文信息
  repeated string tools = 4;       // 可用工具列表
  string user_id = 5;              // 用户 ID
  string project_id = 6;           // 项目 ID
  common.Metadata metadata = 7;    // 元数据
  
  // 高级选项
  AgentOptions options = 8;
}

// Agent 选项
message AgentOptions {
  string model = 1;                // LLM 模型
  float temperature = 2;           // 温度参数
  int32 max_tokens = 3;            // 最大 Token 数
  int32 max_retries = 4;           // 最大重试次数
  int32 timeout_seconds = 5;       // 超时时间（秒）
  bool enable_reasoning = 6;       // 启用推理过程
}

// Agent 执行响应
message AgentResponse {
  string output = 1;                     // 输出结果
  repeated common.ToolCall tool_calls = 2;  // 工具调用记录
  string status = 3;                     // 状态：completed, failed, timeout
  repeated string reasoning = 4;         // 推理过程
  common.Status response_status = 5;     // 响应状态
  common.Metadata metadata = 6;          // 元数据
  
  // 统计信息
  AgentStats stats = 7;
}

// Agent 统计信息
message AgentStats {
  int32 tokens_used = 1;           // Token 使用量
  int64 duration_ms = 2;           // 总耗时（毫秒）
  int32 tool_calls_count = 3;      // 工具调用次数
  int32 retry_count = 4;           // 重试次数
}

// Agent 流式响应块
message AgentStreamChunk {
  string delta = 1;                // 增量内容
  string chunk_type = 2;           // 类型：text, tool_start, tool_end, reasoning
  map<string, string> metadata = 3;  // 元数据
  bool is_final = 4;               // 是否最后一块
}

// 对话请求
message ChatRequest {
  string session_id = 1;                 // 会话 ID
  repeated common.Message messages = 2;  // 消息历史
  string model = 3;                      // 模型
  float temperature = 4;                 // 温度
  int32 max_tokens = 5;                  // 最大 Token 数
  map<string, string> context = 6;       // 上下文
  common.Metadata metadata = 7;          // 元数据
}

// 对话响应
message ChatResponse {
  common.Message message = 1;            // 助手消息
  int32 tokens_used = 2;                 // Token 使用量
  common.Status status = 3;              // 状态
}

// 对话流式响应块
message ChatStreamChunk {
  string delta = 1;                      // 增量内容
  bool is_final = 2;                     // 是否最后一块
}

// 健康检查请求
message HealthRequest {}

// 健康检查响应
message HealthResponse {
  string status = 1;                     // 状态：healthy, unhealthy
  map<string, string> details = 2;       // 详细信息
  int64 uptime_seconds = 3;              // 运行时长（秒）
}
```

### 1.4 rag.proto

```protobuf
// proto/rag.proto
syntax = "proto3";

package qingyu.ai.rag;

import "common.proto";

option go_package = "Qingyu_backend/proto/ai/rag";

// RAG 服务
service RAGService {
  // 搜索
  rpc Search(SearchRequest) returns (SearchResponse);
  
  // 索引文档
  rpc IndexDocument(IndexRequest) returns (IndexResponse);
  
  // 删除文档
  rpc DeleteDocument(DeleteRequest) returns (DeleteResponse);
  
  // 批量索引
  rpc BatchIndex(stream IndexRequest) returns (BatchIndexResponse);
}

// 搜索请求
message SearchRequest {
  string query = 1;                    // 查询文本
  string user_id = 2;                  // 用户 ID
  string project_id = 3;               // 项目 ID
  repeated string content_types = 4;   // 内容类型过滤
  int32 top_k = 5;                     // 返回数量
  SearchOptions options = 6;           // 搜索选项
  common.Metadata metadata = 7;        // 元数据
}

// 搜索选项
message SearchOptions {
  float min_score = 1;                 // 最小相似度分数
  bool enable_rerank = 2;              // 启用重排序
  bool enable_hybrid = 3;              // 启用混合检索
  map<string, string> filters = 4;     // 额外过滤条件
}

// 搜索响应
message SearchResponse {
  repeated SearchResult results = 1;   // 搜索结果
  int64 total_count = 2;               // 总数
  int64 duration_ms = 3;               // 耗时（毫秒）
  common.Status status = 4;            // 状态
}

// 搜索结果
message SearchResult {
  string document_id = 1;              // 文档 ID
  string content = 2;                  // 内容
  float score = 3;                     // 相似度分数
  map<string, string> metadata = 4;    // 元数据
  string content_type = 5;             // 内容类型
  repeated string highlights = 6;      // 高亮片段
}

// 索引请求
message IndexRequest {
  string document_id = 1;              // 文档 ID
  string content = 2;                  // 内容
  string content_type = 3;             // 内容类型
  string user_id = 4;                  // 用户 ID
  string project_id = 5;               // 项目 ID
  map<string, string> metadata = 6;    // 元数据
}

// 索引响应
message IndexResponse {
  string document_id = 1;              // 文档 ID
  bool success = 2;                    // 是否成功
  string message = 3;                  // 消息
  int32 chunks_count = 4;              // 分块数量
}

// 批量索引响应
message BatchIndexResponse {
  int32 total = 1;                     // 总数
  int32 success_count = 2;             // 成功数
  int32 failed_count = 3;              // 失败数
  repeated string failed_ids = 4;      // 失败的文档 ID
}

// 删除请求
message DeleteRequest {
  string document_id = 1;              // 文档 ID
  string user_id = 2;                  // 用户 ID
}

// 删除响应
message DeleteResponse {
  bool success = 1;                    // 是否成功
  string message = 2;                  // 消息
}
```

### 1.5 tool.proto

```protobuf
// proto/tool.proto
syntax = "proto3";

package qingyu.ai.tool;

import "common.proto";

option go_package = "Qingyu_backend/proto/ai/tool";

// 工具服务
service ToolService {
  // 调用工具
  rpc CallTool(ToolRequest) returns (ToolResponse);
  
  // 获取工具列表
  rpc ListTools(ListToolsRequest) returns (ListToolsResponse);
  
  // 获取工具信息
  rpc GetToolInfo(GetToolInfoRequest) returns (ToolInfo);
}

// 工具请求
message ToolRequest {
  string tool_name = 1;                // 工具名称
  string parameters = 2;               // 参数（JSON 格式）
  string user_id = 3;                  // 用户 ID
  string project_id = 4;               // 项目 ID
  common.Metadata metadata = 5;        // 元数据
}

// 工具响应
message ToolResponse {
  string result = 1;                   // 结果（JSON 格式）
  bool success = 2;                    // 是否成功
  string error = 3;                    // 错误信息
  int64 duration_ms = 4;               // 耗时（毫秒）
  common.Status status = 5;            // 状态
}

// 工具列表请求
message ListToolsRequest {
  string category = 1;                 // 分类过滤
}

// 工具列表响应
message ListToolsResponse {
  repeated ToolInfo tools = 1;         // 工具列表
}

// 获取工具信息请求
message GetToolInfoRequest {
  string tool_name = 1;                // 工具名称
}

// 工具信息
message ToolInfo {
  string name = 1;                     // 工具名称
  string description = 2;              // 描述
  string category = 3;                 // 分类
  repeated ToolParameter parameters = 4;  // 参数定义
  bool requires_auth = 5;              // 是否需要认证
}

// 工具参数
message ToolParameter {
  string name = 1;                     // 参数名
  string type = 2;                     // 类型
  string description = 3;              // 描述
  bool required = 4;                   // 是否必需
  string default_value = 5;            // 默认值
}
```

---

## 二、Go AI Proxy Service 实现

### 2.1 Service 接口定义

```go
// service/ai/proxy_service.go
package ai

import (
	"context"
	"io"
	"time"
)

// AIProxyService AI代理服务接口
type AIProxyService interface {
	// Agent 相关
	ExecuteAgent(ctx context.Context, req *AgentRequest) (*AgentResponse, error)
	ExecuteAgentStream(ctx context.Context, req *AgentRequest) (<-chan *StreamChunk, error)
	
	// 对话相关
	Chat(ctx context.Context, req *ChatRequest) (*ChatResponse, error)
	ChatStream(ctx context.Context, req *ChatRequest) (<-chan *StreamChunk, error)
	
	// RAG 相关
	RAGSearch(ctx context.Context, req *RAGSearchRequest) (*RAGSearchResponse, error)
	RAGIndex(ctx context.Context, req *RAGIndexRequest) error
	
	// 工具相关
	CallTool(ctx context.Context, req *ToolRequest) (*ToolResponse, error)
	ListTools(ctx context.Context, category string) ([]*ToolInfo, error)
	
	// 健康检查
	Health(ctx context.Context) error
	
	// 关闭
	Close() error
}

// AgentRequest Agent 执行请求
type AgentRequest struct {
	AgentType   string            `json:"agentType" validate:"required,oneof=creative outline character plot review"`
	Task        string            `json:"task" validate:"required"`
	Context     map[string]string `json:"context"`
	Tools       []string          `json:"tools"`
	UserID      string            `json:"userId"`
	ProjectID   string            `json:"projectId"`
	Options     *AgentOptions     `json:"options"`
	Stream      bool              `json:"stream"`
}

// AgentOptions Agent 选项
type AgentOptions struct {
	Model           string  `json:"model"`
	Temperature     float32 `json:"temperature"`
	MaxTokens       int     `json:"maxTokens"`
	MaxRetries      int     `json:"maxRetries"`
	TimeoutSeconds  int     `json:"timeoutSeconds"`
	EnableReasoning bool    `json:"enableReasoning"`
}

// AgentResponse Agent 执行响应
type AgentResponse struct {
	Output    string              `json:"output"`
	ToolCalls []ToolCallRecord    `json:"toolCalls"`
	Status    string              `json:"status"`
	Reasoning []string            `json:"reasoning"`
	Stats     *AgentStats         `json:"stats"`
}

// AgentStats Agent 统计信息
type AgentStats struct {
	TokensUsed     int   `json:"tokensUsed"`
	DurationMs     int64 `json:"durationMs"`
	ToolCallsCount int   `json:"toolCallsCount"`
	RetryCount     int   `json:"retryCount"`
}

// StreamChunk 流式响应块
type StreamChunk struct {
	Delta     string            `json:"delta"`
	ChunkType string            `json:"chunkType"`
	Metadata  map[string]string `json:"metadata"`
	IsFinal   bool              `json:"isFinal"`
	Error     string            `json:"error,omitempty"`
}

// ToolCallRecord 工具调用记录
type ToolCallRecord struct {
	ToolName   string                 `json:"toolName"`
	Parameters map[string]interface{} `json:"parameters"`
	Result     interface{}            `json:"result"`
	DurationMs int64                  `json:"durationMs"`
	Success    bool                   `json:"success"`
}
```

### 2.2 Service 实现

```go
// service/ai/proxy_service_impl.go
package ai

import (
	"context"
	"fmt"
	"io"
	"sync"
	"time"
	
	"google.golang.org/grpc"
	"google.golang.org/grpc/codes"
	"google.golang.org/grpc/credentials/insecure"
	"google.golang.org/grpc/keepalive"
	"google.golang.org/grpc/status"
	
	pb "Qingyu_backend/proto/ai/agent"
	ragpb "Qingyu_backend/proto/ai/rag"
	toolpb "Qingyu_backend/proto/ai/tool"
	"Qingyu_backend/pkg/errors"
	"Qingyu_backend/pkg/logger"
)

// AIProxyServiceImpl AI代理服务实现
type AIProxyServiceImpl struct {
	// gRPC 客户端
	agentClient pb.AIAgentServiceClient
	ragClient   ragpb.RAGServiceClient
	toolClient  toolpb.ToolServiceClient
	conn        *grpc.ClientConn
	
	// 服务保护
	circuitBreaker *CircuitBreaker
	rateLimiter    *RateLimiter
	
	// 配置
	config *ProxyConfig
	
	// 日志
	logger logger.Logger
	
	// 状态
	mu      sync.RWMutex
	healthy bool
}

// ProxyConfig 代理配置
type ProxyConfig struct {
	PythonAddr       string        `mapstructure:"python_addr"`
	Timeout          time.Duration `mapstructure:"timeout"`
	MaxRetries       int           `mapstructure:"max_retries"`
	RateLimit        int           `mapstructure:"rate_limit"` // QPS
	CircuitMaxFails  int           `mapstructure:"circuit_max_fails"`
	CircuitResetTime time.Duration `mapstructure:"circuit_reset_time"`
	EnableMetrics    bool          `mapstructure:"enable_metrics"`
}

// NewAIProxyService 创建 AI 代理服务
func NewAIProxyService(config *ProxyConfig, logger logger.Logger) (*AIProxyServiceImpl, error) {
	// 建立 gRPC 连接
	conn, err := grpc.Dial(
		config.PythonAddr,
		grpc.WithTransportCredentials(insecure.NewCredentials()),
		grpc.WithBlock(),
		grpc.WithTimeout(10*time.Second),
		grpc.WithKeepaliveParams(keepalive.ClientParameters{
			Time:                10 * time.Second,
			Timeout:             3 * time.Second,
			PermitWithoutStream: true,
		}),
	)
	if err != nil {
		return nil, fmt.Errorf("连接 Python AI 服务失败: %w", err)
	}
	
	// 创建 gRPC 客户端
	agentClient := pb.NewAIAgentServiceClient(conn)
	ragClient := ragpb.NewRAGServiceClient(conn)
	toolClient := toolpb.NewToolServiceClient(conn)
	
	// 创建服务保护组件
	circuitBreaker := NewCircuitBreaker(
		config.CircuitMaxFails,
		config.CircuitResetTime,
	)
	
	rateLimiter := NewRateLimiter(
		config.RateLimit,
		time.Second,
	)
	
	service := &AIProxyServiceImpl{
		agentClient:    agentClient,
		ragClient:      ragClient,
		toolClient:     toolClient,
		conn:           conn,
		circuitBreaker: circuitBreaker,
		rateLimiter:    rateLimiter,
		config:         config,
		logger:         logger,
		healthy:        true,
	}
	
	// 启动健康检查
	go service.healthCheckLoop()
	
	return service, nil
}

// ExecuteAgent 执行 Agent（同步）
func (s *AIProxyServiceImpl) ExecuteAgent(ctx context.Context, req *AgentRequest) (*AgentResponse, error) {
	// 1. 限流检查
	if !s.rateLimiter.Allow() {
		s.logger.Warn("请求被限流拒绝")
		return nil, errors.NewRateLimitError("请求过于频繁，请稍后再试")
	}
	
	// 2. 熔断检查
	if !s.circuitBreaker.Allow() {
		s.logger.Warn("熔断器开启，拒绝请求")
		return nil, errors.NewServiceUnavailableError("AI服务暂时不可用，请稍后再试")
	}
	
	// 3. 设置超时
	timeout := s.config.Timeout
	if req.Options != nil && req.Options.TimeoutSeconds > 0 {
		timeout = time.Duration(req.Options.TimeoutSeconds) * time.Second
	}
	ctx, cancel := context.WithTimeout(ctx, timeout)
	defer cancel()
	
	// 4. 转换请求
	pbReq := &pb.AgentRequest{
		AgentType: req.AgentType,
		Task:      req.Task,
		Context:   req.Context,
		Tools:     req.Tools,
		UserId:    req.UserID,
		ProjectId: req.ProjectID,
		Metadata: &pb.Metadata{
			RequestId: generateRequestID(),
			UserId:    req.UserID,
			ProjectId: req.ProjectID,
			Timestamp: time.Now().Unix(),
		},
	}
	
	if req.Options != nil {
		pbReq.Options = &pb.AgentOptions{
			Model:           req.Options.Model,
			Temperature:     req.Options.Temperature,
			MaxTokens:       int32(req.Options.MaxTokens),
			MaxRetries:      int32(req.Options.MaxRetries),
			TimeoutSeconds:  int32(req.Options.TimeoutSeconds),
			EnableReasoning: req.Options.EnableReasoning,
		}
	}
	
	// 5. 调用 Python 服务
	s.logger.Info("调用 Python AI 服务执行 Agent",
		"agent_type", req.AgentType,
		"task_len", len(req.Task),
		"tools", req.Tools,
	)
	
	start := time.Now()
	resp, err := s.agentClient.ExecuteAgent(ctx, pbReq)
	duration := time.Since(start)
	
	if err != nil {
		s.circuitBreaker.RecordFailure()
		s.logger.Error("调用 Python AI 服务失败",
			"error", err,
			"duration", duration,
		)
		return nil, s.convertError(err)
	}
	
	s.circuitBreaker.RecordSuccess()
	s.logger.Info("Python AI 服务调用成功",
		"duration", duration,
		"tokens_used", resp.Stats.TokensUsed,
		"tool_calls", resp.Stats.ToolCallsCount,
	)
	
	// 6. 记录指标
	if s.config.EnableMetrics {
		recordAgentMetrics(req.AgentType, duration, resp.Status, resp.Stats)
	}
	
	// 7. 转换响应
	return s.convertAgentResponse(resp), nil
}

// ExecuteAgentStream 执行 Agent（流式）
func (s *AIProxyServiceImpl) ExecuteAgentStream(ctx context.Context, req *AgentRequest) (<-chan *StreamChunk, error) {
	// 1. 限流和熔断检查
	if !s.rateLimiter.Allow() {
		return nil, errors.NewRateLimitError("请求过于频繁")
	}
	if !s.circuitBreaker.Allow() {
		return nil, errors.NewServiceUnavailableError("AI服务暂时不可用")
	}
	
	// 2. 转换请求
	pbReq := &pb.AgentRequest{
		AgentType: req.AgentType,
		Task:      req.Task,
		Context:   req.Context,
		Tools:     req.Tools,
		UserId:    req.UserID,
		ProjectId: req.ProjectID,
	}
	
	// 3. 调用 gRPC 流式接口
	s.logger.Info("调用 Python AI 服务流式执行 Agent", "agent_type", req.AgentType)
	
	stream, err := s.agentClient.ExecuteAgentStream(ctx, pbReq)
	if err != nil {
		s.circuitBreaker.RecordFailure()
		s.logger.Error("创建流式调用失败", "error", err)
		return nil, s.convertError(err)
	}
	
	// 4. 创建输出 channel
	chunkChan := make(chan *StreamChunk, 100)
	
	// 5. 异步接收流式数据
	go s.handleAgentStream(ctx, stream, chunkChan)
	
	return chunkChan, nil
}

// handleAgentStream 处理 Agent 流式响应
func (s *AIProxyServiceImpl) handleAgentStream(
	ctx context.Context,
	stream pb.AIAgentService_ExecuteAgentStreamClient,
	chunkChan chan<- *StreamChunk,
) {
	defer close(chunkChan)
	
	start := time.Now()
	chunkCount := 0
	
	for {
		select {
		case <-ctx.Done():
			s.logger.Warn("流式调用被取消", "reason", ctx.Err())
			chunkChan <- &StreamChunk{
				Error: "请求已取消",
			}
			return
			
		default:
			chunk, err := stream.Recv()
			if err == io.EOF {
				// 流结束
				s.circuitBreaker.RecordSuccess()
				s.logger.Info("流式调用完成",
					"duration", time.Since(start),
					"chunks", chunkCount,
				)
				return
			}
			
			if err != nil {
				s.circuitBreaker.RecordFailure()
				s.logger.Error("流式接收失败", "error", err)
				chunkChan <- &StreamChunk{
					Error: s.convertError(err).Error(),
				}
				return
			}
			
			// 发送 chunk
			chunkChan <- &StreamChunk{
				Delta:     chunk.Delta,
				ChunkType: chunk.ChunkType,
				Metadata:  chunk.Metadata,
				IsFinal:   chunk.IsFinal,
			}
			chunkCount++
		}
	}
}

// convertAgentResponse 转换 Agent 响应
func (s *AIProxyServiceImpl) convertAgentResponse(resp *pb.AgentResponse) *AgentResponse {
	toolCalls := make([]ToolCallRecord, len(resp.ToolCalls))
	for i, tc := range resp.ToolCalls {
		var params map[string]interface{}
		json.Unmarshal([]byte(tc.Parameters), &params)
		
		var result interface{}
		json.Unmarshal([]byte(tc.Result), &result)
		
		toolCalls[i] = ToolCallRecord{
			ToolName:   tc.ToolName,
			Parameters: params,
			Result:     result,
			DurationMs: tc.DurationMs,
			Success:    tc.Status != nil && tc.Status.Code == 0,
		}
	}
	
	return &AgentResponse{
		Output:    resp.Output,
		ToolCalls: toolCalls,
		Status:    resp.Status,
		Reasoning: resp.Reasoning,
		Stats: &AgentStats{
			TokensUsed:     int(resp.Stats.TokensUsed),
			DurationMs:     resp.Stats.DurationMs,
			ToolCallsCount: int(resp.Stats.ToolCallsCount),
			RetryCount:     int(resp.Stats.RetryCount),
		},
	}
}

// convertError 错误转换
func (s *AIProxyServiceImpl) convertError(err error) error {
	st, ok := status.FromError(err)
	if !ok {
		return errors.NewInternalError("AI服务调用失败").WithCause(err)
	}
	
	switch st.Code() {
	case codes.DeadlineExceeded:
		return errors.NewTimeoutError("AI服务响应超时")
	case codes.Unavailable:
		return errors.NewServiceUnavailableError("AI服务不可用")
	case codes.InvalidArgument:
		return errors.NewValidationError(st.Message())
	case codes.ResourceExhausted:
		return errors.NewRateLimitError("AI服务资源耗尽")
	default:
		return errors.NewInternalError(st.Message()).WithCause(err)
	}
}

// Health 健康检查
func (s *AIProxyServiceImpl) Health(ctx context.Context) error {
	ctx, cancel := context.WithTimeout(ctx, 5*time.Second)
	defer cancel()
	
	resp, err := s.agentClient.HealthCheck(ctx, &pb.HealthRequest{})
	if err != nil {
		return fmt.Errorf("健康检查失败: %w", err)
	}
	
	if resp.Status != "healthy" {
		return fmt.Errorf("服务状态异常: %s", resp.Status)
	}
	
	return nil
}

// healthCheckLoop 健康检查循环
func (s *AIProxyServiceImpl) healthCheckLoop() {
	ticker := time.NewTicker(30 * time.Second)
	defer ticker.Stop()
	
	for range ticker.C {
		err := s.Health(context.Background())
		
		s.mu.Lock()
		s.healthy = (err == nil)
		s.mu.Unlock()
		
		if err != nil {
			s.logger.Warn("健康检查失败", "error", err)
		}
	}
}

// Close 关闭连接
func (s *AIProxyServiceImpl) Close() error {
	if s.conn != nil {
		return s.conn.Close()
	}
	return nil
}

// generateRequestID 生成请求 ID
func generateRequestID() string {
	return fmt.Sprintf("req_%d_%s", time.Now().UnixNano(), uuid.New().String()[:8])
}
```

---

## 三、流式响应代理

### 3.1 SSE 流式处理

```go
// api/v1/ai/stream_handler.go
package ai

import (
	"fmt"
	"net/http"
	
	"github.com/gin-gonic/gin"
	
	"Qingyu_backend/service/ai"
)

// StreamSSE SSE 流式响应
func StreamSSE(c *gin.Context, chunkChan <-chan *ai.StreamChunk) {
	// 设置 SSE 响应头
	c.Header("Content-Type", "text/event-stream")
	c.Header("Cache-Control", "no-cache")
	c.Header("Connection", "keep-alive")
	c.Header("X-Accel-Buffering", "no") // 禁用 Nginx 缓冲
	
	// 设置 Flusher
	flusher, ok := c.Writer.(http.Flusher)
	if !ok {
		c.JSON(http.StatusInternalServerError, gin.H{"error": "不支持流式响应"})
		return
	}
	
	// 流式推送
	for chunk := range chunkChan {
		// 检查错误
		if chunk.Error != "" {
			c.SSEvent("error", gin.H{
				"error": chunk.Error,
			})
			flusher.Flush()
			break
		}
		
		// 发送数据
		c.SSEvent("message", gin.H{
			"delta":     chunk.Delta,
			"type":      chunk.ChunkType,
			"metadata":  chunk.Metadata,
			"is_final":  chunk.IsFinal,
		})
		flusher.Flush()
		
		// 检查是否最后一块
		if chunk.IsFinal {
			c.SSEvent("done", gin.H{"status": "completed"})
			flusher.Flush()
			break
		}
	}
}
```

### 3.2 WebSocket 流式处理

```go
// api/v1/ai/websocket_handler.go
package ai

import (
	"github.com/gin-gonic/gin"
	"github.com/gorilla/websocket"
	
	"Qingyu_backend/service/ai"
)

var upgrader = websocket.Upgrader{
	CheckOrigin: func(r *http.Request) bool {
		return true // 生产环境需要检查 Origin
	},
}

// StreamWebSocket WebSocket 流式响应
func StreamWebSocket(c *gin.Context, chunkChan <-chan *ai.StreamChunk) {
	// 升级到 WebSocket
	conn, err := upgrader.Upgrade(c.Writer, c.Request, nil)
	if err != nil {
		return
	}
	defer conn.Close()
	
	// 流式推送
	for chunk := range chunkChan {
		// 检查错误
		if chunk.Error != "" {
			conn.WriteJSON(map[string]interface{}{
				"type":  "error",
				"error": chunk.Error,
			})
			break
		}
		
		// 发送数据
		err := conn.WriteJSON(map[string]interface{}{
			"type":      "chunk",
			"delta":     chunk.Delta,
			"chunk_type": chunk.ChunkType,
			"metadata":  chunk.Metadata,
			"is_final":  chunk.IsFinal,
		})
		
		if err != nil {
			break
		}
		
		// 检查是否最后一块
		if chunk.IsFinal {
			conn.WriteJSON(map[string]interface{}{
				"type":   "done",
				"status": "completed",
			})
			break
		}
	}
}
```

---

## 四、错误处理和重试

### 4.1 错误分类和转换

```go
// pkg/errors/ai_errors.go
package errors

// AI 服务错误类型
const (
	CategoryAI ErrorCategory = "ai"
)

// NewAIError 创建 AI 错误
func NewAIError(code int, message string) *UnifiedError {
	return &UnifiedError{
		Code:       code,
		Category:   CategoryAI,
		Message:    message,
		HTTPStatus: 500,
		Service:    "ai_proxy",
	}
}

// AI 特定错误码
const (
	ErrCodeAgentExecutionFailed = 5001
	ErrCodeRAGSearchFailed      = 5002
	ErrCodeToolCallFailed       = 5003
	ErrCodeModelNotAvailable    = 5004
)
```

### 4.2 重试策略

```go
// service/ai/retry.go
package ai

import (
	"context"
	"time"
	
	"github.com/avast/retry-go"
)

// WithRetry 带重试的执行
func (s *AIProxyServiceImpl) WithRetry(
	ctx context.Context,
	operation func(context.Context) error,
) error {
	return retry.Do(
		func() error {
			return operation(ctx)
		},
		retry.Attempts(uint(s.config.MaxRetries)),
		retry.Delay(1*time.Second),
		retry.DelayType(retry.BackOffDelay),
		retry.OnRetry(func(n uint, err error) {
			s.logger.Warn("重试执行",
				"attempt", n+1,
				"error", err,
			)
		}),
		retry.RetryIf(func(err error) bool {
			// 只重试临时性错误
			return isRetryableError(err)
		}),
	)
}

// isRetryableError 判断是否可重试错误
func isRetryableError(err error) bool {
	if err == nil {
		return false
	}
	
	// 超时错误可重试
	if errors.IsTimeout(err) {
		return true
	}
	
	// 服务不可用可重试
	if errors.IsServiceUnavailable(err) {
		return true
	}
	
	// 限流错误不重试
	if errors.IsRateLimit(err) {
		return false
	}
	
	return false
}
```

---

## 五、监控和指标

### 5.1 Prometheus 指标

```go
// service/ai/metrics.go
package ai

import (
	"time"
	
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promauto"
)

var (
	// Agent 请求计数
	agentRequestsTotal = promauto.NewCounterVec(
		prometheus.CounterOpts{
			Name: "ai_agent_requests_total",
			Help: "Total number of agent requests",
		},
		[]string{"agent_type", "status"},
	)
	
	// Agent 执行时长
	agentDurationSeconds = promauto.NewHistogramVec(
		prometheus.HistogramOpts{
			Name:    "ai_agent_duration_seconds",
			Help:    "Agent execution duration in seconds",
			Buckets: prometheus.DefBuckets,
		},
		[]string{"agent_type"},
	)
	
	// Token 使用量
	agentTokensUsed = promauto.NewHistogramVec(
		prometheus.HistogramOpts{
			Name:    "ai_agent_tokens_used",
			Help:    "Number of tokens used by agent",
			Buckets: []float64{100, 500, 1000, 2000, 5000, 10000},
		},
		[]string{"agent_type"},
	)
	
	// 工具调用计数
	toolCallsTotal = promauto.NewCounterVec(
		prometheus.CounterOpts{
			Name: "ai_tool_calls_total",
			Help: "Total number of tool calls",
		},
		[]string{"tool_name", "status"},
	)
)

// recordAgentMetrics 记录 Agent 指标
func recordAgentMetrics(agentType string, duration time.Duration, status string, stats *AgentStats) {
	agentRequestsTotal.WithLabelValues(agentType, status).Inc()
	agentDurationSeconds.WithLabelValues(agentType).Observe(duration.Seconds())
	agentTokensUsed.WithLabelValues(agentType).Observe(float64(stats.TokensUsed))
}
```

---

## 六、部署和配置

### 6.1 配置示例

```yaml
# config/config.yaml
ai:
  proxy:
    python_addr: "localhost:50051"
    timeout: 60s
    max_retries: 3
    rate_limit: 100  # 100 QPS
    circuit_max_fails: 5
    circuit_reset_time: 30s
    enable_metrics: true
```

### 6.2 服务初始化

```go
// cmd/server/main.go
func initAIProxyService(cfg *config.Config) ai.AIProxyService {
	proxyConfig := &ai.ProxyConfig{
		PythonAddr:       cfg.AI.Proxy.PythonAddr,
		Timeout:          cfg.AI.Proxy.Timeout,
		MaxRetries:       cfg.AI.Proxy.MaxRetries,
		RateLimit:        cfg.AI.Proxy.RateLimit,
		CircuitMaxFails:  cfg.AI.Proxy.CircuitMaxFails,
		CircuitResetTime: cfg.AI.Proxy.CircuitResetTime,
		EnableMetrics:    cfg.AI.Proxy.EnableMetrics,
	}
	
	proxyService, err := ai.NewAIProxyService(proxyConfig, logger)
	if err != nil {
		log.Fatal("初始化 AI 代理服务失败:", err)
	}
	
	// 健康检查
	if err := proxyService.Health(context.Background()); err != nil {
		log.Warn("Python AI 服务健康检查失败:", err)
	}
	
	return proxyService
}
```

---

## 七、测试策略

### 7.1 单元测试

```go
// service/ai/proxy_service_test.go
package ai

import (
	"context"
	"testing"
	
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/mock"
)

// 使用 mock gRPC 客户端测试
func TestExecuteAgent(t *testing.T) {
	// Mock gRPC 客户端
	mockClient := new(MockAIAgentServiceClient)
	
	service := &AIProxyServiceImpl{
		agentClient: mockClient,
		// ...
	}
	
	// 设置 mock 期望
	mockClient.On("ExecuteAgent", mock.Anything, mock.Anything).
		Return(&pb.AgentResponse{
			Output: "Test output",
			Status: "completed",
		}, nil)
	
	// 执行测试
	result, err := service.ExecuteAgent(context.Background(), &AgentRequest{
		AgentType: "creative",
		Task:      "Test task",
	})
	
	assert.NoError(t, err)
	assert.Equal(t, "Test output", result.Output)
	assert.Equal(t, "completed", result.Status)
}
```

---

## 八、总结

本文档详细定义了 Go 后端与 Python AI 服务之间的通信协议，包括：

- ✅ 完整的 gRPC Proto 定义
- ✅ Go AI Proxy Service 实现
- ✅ 流式响应代理机制（SSE/WebSocket）
- ✅ 错误处理和重试策略
- ✅ 监控指标和可观测性
- ✅ 部署配置和测试策略

**后续工作**：
- 实现 Python 端的 gRPC Server
- 完善流式响应处理
- 性能测试和优化

---

**文档版本**: v1.0
**创建时间**: 2025-10-27
**维护者**: AI架构组
