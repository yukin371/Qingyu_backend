> ⚠️ **文档状态**: 已归档（2025-10-21）
> 
> 本文档基于v2.0架构设计，已被新的v2.1架构取代。
> 
> **替代文档**: 10.RAG检索增强系统设计.md
> 
> 详见：[青羽平台模块化架构设计v2.1](../../青羽平台模块化架构设计v2.1.md)

---

# AI上下文管理设计

## 1. 需求概述

### 1.1 功能描述
为青语小说创作平台设计智能上下文管理系统，解决长篇小说创作中的上下文连贯性问题，提供结构化的记忆管理和智能上下文构建能力。

### 1.2 业务价值
- **创作连贯性**：保持长篇小说的情节、人物、世界观一致性
- **智能记忆**：自动管理和检索相关的创作元素
- **成本优化**：通过智能上下文压缩降低AI调用成本
- **创作效率**：快速获取相关背景信息，提升创作效率

### 1.3 用户场景
- **长篇创作**：在创作长篇小说时保持前后一致性
- **角色管理**：自动关联和管理小说中的角色信息
- **情节连贯**：确保情节发展的逻辑性和连贯性
- **世界观维护**：保持小说世界观的一致性和完整性

### 1.4 功能边界
- **支持功能**：结构化上下文、智能检索、记忆压缩、相关性分析
- **不支持功能**：自动情节生成、角色性格分析、文学评价
- **技术限制**：依赖现有大纲、角色、时间线系统
- **扩展限制**：单部小说最多支持10万字的上下文管理

## 2. 架构设计

### 2.1 整体架构

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   创作界面      │    │   大纲管理      │    │   角色管理      │
│ - 章节编辑      │    │ - 章节结构      │    │ - 角色信息      │
│ - 上下文提示    │    │ - 情节要点      │    │ - 关系网络      │
│ - 智能建议      │    │ - 进度跟踪      │    │ - 出场记录      │
└─────────────────┘    └─────────────────┘    └─────────────────┘
         │                       │                       │
         └───────────────────────┼───────────────────────┘
                                 │
                    ┌─────────────────┐
                    │   上下文API层   │
                    │ - 上下文构建    │
                    │ - 相关性查询    │
                    │ - 记忆管理      │
                    │ - 智能推荐      │
                    └─────────────────┘
                                 │
                    ┌─────────────────┐
                    │  上下文服务层   │
                    │ - 上下文管理器  │
                    │ - 相关性分析器  │
                    │ - 记忆压缩器    │
                    │ - 检索引擎      │
                    └─────────────────┘
                                 │
         ┌───────────────────────┼───────────────────────┐
         │                       │                       │
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   数据适配层    │    │   缓存层        │    │   存储层        │
│ - 大纲适配器    │    │ - 上下文缓存    │    │ - 大纲数据      │
│ - 角色适配器    │    │ - 相关性缓存    │    │ - 角色数据      │
│ - 时间线适配器  │    │ - 检索缓存      │    │ - 时间线数据    │
│ - 章节适配器    │    │ - 压缩缓存      │    │ - 章节内容      │
└─────────────────┘    └─────────────────┘    └─────────────────┘
         │
┌─────────────────┐
│   现有系统      │
│ - 大纲系统      │
│ - 角色系统      │
│ - 时间线系统    │
│ - 章节系统      │
└─────────────────┘
```

### 2.2 模块划分

#### 2.2.1 上下文管理器 (ContextManager)
**文件路径**：`service/ai/context/context_manager.go`
**职责**：
- 上下文构建和管理
- 上下文窗口控制
- 记忆层级管理
- 上下文压缩

#### 2.2.2 相关性分析器 (RelevanceAnalyzer)
**文件路径**：`service/ai/context/relevance_analyzer.go`
**职责**：
- 内容相关性计算
- 语义相似度分析
- 重要性评分
- 时间衰减计算

#### 2.2.3 记忆压缩器 (MemoryCompressor)
**文件路径**：`service/ai/context/memory_compressor.go`
**职责**：
- 长期记忆压缩
- 关键信息提取
- 摘要生成
- 冗余信息清理

#### 2.2.4 检索引擎 (RetrievalEngine)
**文件路径**：`service/ai/context/retrieval_engine.go`
**职责**：
- 智能内容检索
- 多维度搜索
- 结果排序
- 检索优化

#### 2.2.5 数据适配层 (DataAdapters)
**文件路径**：`service/ai/context/adapters/`
**职责**：
- 现有系统数据适配
- 数据格式转换
- 关联关系映射
- 数据同步

### 2.3 数据流向
1. 用户创作请求 → 上下文API层 → 参数解析
2. 上下文管理器 → 数据适配层 → 获取相关数据
3. 相关性分析器 → 计算内容相关性 → 筛选重要信息
4. 记忆压缩器 → 压缩历史信息 → 生成结构化上下文
5. 检索引擎 → 智能检索 → 返回相关内容
6. 上下文构建 → 缓存层 → 返回给AI服务

### 2.4 技术选型
- **相关性计算**：TF-IDF + 语义相似度
- **记忆存储**：分层存储（Redis + MongoDB）
- **检索算法**：倒排索引 + 向量检索
- **压缩算法**：关键词提取 + 摘要生成
- **缓存策略**：LRU + TTL
- **数据同步**：事件驱动 + 定时同步

## 3. 详细设计

### 3.1 上下文管理器设计

**核心结构**：
```go
type ContextManager struct {
    relevanceAnalyzer *RelevanceAnalyzer
    memoryCompressor  *MemoryCompressor
    retrievalEngine   *RetrievalEngine
    dataAdapters      map[string]DataAdapter
    cache            CacheService
    config           *ContextConfig
}

type ContextConfig struct {
    MaxTokens        int     `json:"max_tokens"`
    WindowSize       int     `json:"window_size"`
    RelevanceThreshold float64 `json:"relevance_threshold"`
    CompressionRatio   float64 `json:"compression_ratio"`
    CacheTTL          int     `json:"cache_ttl"`
}

type Context struct {
    NovelID      string           `json:"novel_id"`
    ChapterID    string           `json:"chapter_id"`
    CurrentText  string           `json:"current_text"`
    ShortTerm    *ShortTermMemory `json:"short_term"`
    MidTerm      *MidTermMemory   `json:"mid_term"`
    LongTerm     *LongTermMemory  `json:"long_term"`
    Metadata     *ContextMetadata `json:"metadata"`
}
```

**上下文构建流程**：
```go
func (cm *ContextManager) BuildContext(request *ContextRequest) (*Context, error) {
    // 1. 获取当前章节信息
    currentChapter, err := cm.getCurrentChapter(request.ChapterID)
    if err != nil {
        return nil, err
    }
    
    // 2. 构建短期记忆（当前章节相关）
    shortTerm, err := cm.buildShortTermMemory(currentChapter, request)
    if err != nil {
        return nil, err
    }
    
    // 3. 构建中期记忆（相关章节）
    midTerm, err := cm.buildMidTermMemory(request.NovelID, currentChapter, request)
    if err != nil {
        return nil, err
    }
    
    // 4. 构建长期记忆（全局背景）
    longTerm, err := cm.buildLongTermMemory(request.NovelID, request)
    if err != nil {
        return nil, err
    }
    
    // 5. 组装上下文
    context := &Context{
        NovelID:     request.NovelID,
        ChapterID:   request.ChapterID,
        CurrentText: request.CurrentText,
        ShortTerm:   shortTerm,
        MidTerm:     midTerm,
        LongTerm:    longTerm,
        Metadata:    cm.buildMetadata(request),
    }
    
    // 6. 检查token限制并压缩
    if cm.exceedsTokenLimit(context) {
        context, err = cm.compressContext(context)
        if err != nil {
            return nil, err
        }
    }
    
    return context, nil
}
```

### 3.2 记忆层级设计

**短期记忆（Short-term Memory）**：
```go
type ShortTermMemory struct {
    CurrentChapter   *ChapterInfo     `json:"current_chapter"`
    RecentParagraphs []string         `json:"recent_paragraphs"`
    ActiveCharacters []*CharacterInfo `json:"active_characters"`
    CurrentScene     *SceneInfo       `json:"current_scene"`
    WritingContext   *WritingContext  `json:"writing_context"`
}

type ChapterInfo struct {
    ID          string   `json:"id"`
    Title       string   `json:"title"`
    Summary     string   `json:"summary"`
    KeyEvents   []string `json:"key_events"`
    Characters  []string `json:"characters"`
    Locations   []string `json:"locations"`
    WordCount   int      `json:"word_count"`
    Status      string   `json:"status"`
}

type WritingContext struct {
    LastSentence    string            `json:"last_sentence"`
    WritingStyle    string            `json:"writing_style"`
    Mood           string            `json:"mood"`
    Perspective    string            `json:"perspective"`
    Tense          string            `json:"tense"`
    Keywords       []string          `json:"keywords"`
    Themes         []string          `json:"themes"`
}
```

**中期记忆（Mid-term Memory）**：
```go
type MidTermMemory struct {
    RelatedChapters  []*ChapterSummary    `json:"related_chapters"`
    PlotThreads      []*PlotThread        `json:"plot_threads"`
    CharacterArcs    []*CharacterArc      `json:"character_arcs"`
    ConflictPoints   []*ConflictPoint     `json:"conflict_points"`
    ThematicElements []*ThematicElement   `json:"thematic_elements"`
}

type ChapterSummary struct {
    ID           string    `json:"id"`
    Title        string    `json:"title"`
    Summary      string    `json:"summary"`
    KeyEvents    []string  `json:"key_events"`
    Relevance    float64   `json:"relevance"`
    Distance     int       `json:"distance"`
    LastAccessed time.Time `json:"last_accessed"`
}

type PlotThread struct {
    ID          string   `json:"id"`
    Name        string   `json:"name"`
    Description string   `json:"description"`
    Status      string   `json:"status"`
    Chapters    []string `json:"chapters"`
    Importance  float64  `json:"importance"`
}
```

**长期记忆（Long-term Memory）**：
```go
type LongTermMemory struct {
    NovelSummary     *NovelSummary      `json:"novel_summary"`
    MainCharacters   []*CharacterProfile `json:"main_characters"`
    WorldBuilding    *WorldBuilding     `json:"world_building"`
    ThematicCore     *ThematicCore      `json:"thematic_core"`
    StyleGuide       *StyleGuide        `json:"style_guide"`
    CompressedHistory *CompressedHistory `json:"compressed_history"`
}

type NovelSummary struct {
    Title       string   `json:"title"`
    Genre       string   `json:"genre"`
    Theme       string   `json:"theme"`
    Setting     string   `json:"setting"`
    MainPlot    string   `json:"main_plot"`
    SubPlots    []string `json:"sub_plots"`
    WordCount   int      `json:"word_count"`
    Progress    float64  `json:"progress"`
}

type WorldBuilding struct {
    Setting      *Setting      `json:"setting"`
    Locations    []*Location   `json:"locations"`
    Timeline     *Timeline     `json:"timeline"`
    Rules        []string      `json:"rules"`
    Cultures     []*Culture    `json:"cultures"`
    Technologies []*Technology `json:"technologies"`
}
```

### 3.3 相关性分析器设计

**相关性计算算法**：
```go
type RelevanceAnalyzer struct {
    tfidfCalculator   *TFIDFCalculator
    semanticAnalyzer  *SemanticAnalyzer
    temporalAnalyzer  *TemporalAnalyzer
    structuralAnalyzer *StructuralAnalyzer
}

func (ra *RelevanceAnalyzer) CalculateRelevance(current *Content, candidate *Content) float64 {
    // 1. 文本相似度（TF-IDF）
    textSimilarity := ra.tfidfCalculator.Calculate(current.Text, candidate.Text)
    
    // 2. 语义相似度
    semanticSimilarity := ra.semanticAnalyzer.Calculate(current, candidate)
    
    // 3. 时间相关性
    temporalRelevance := ra.temporalAnalyzer.Calculate(current.Timestamp, candidate.Timestamp)
    
    // 4. 结构相关性
    structuralRelevance := ra.structuralAnalyzer.Calculate(current.Position, candidate.Position)
    
    // 5. 加权计算最终相关性
    weights := ra.getRelevanceWeights()
    relevance := textSimilarity*weights.Text +
                semanticSimilarity*weights.Semantic +
                temporalRelevance*weights.Temporal +
                structuralRelevance*weights.Structural
    
    return relevance
}

type RelevanceWeights struct {
    Text       float64 `json:"text"`
    Semantic   float64 `json:"semantic"`
    Temporal   float64 `json:"temporal"`
    Structural float64 `json:"structural"`
}
```

**语义相似度计算**：
```go
type SemanticAnalyzer struct {
    characterMatcher  *CharacterMatcher
    locationMatcher   *LocationMatcher
    eventMatcher      *EventMatcher
    themeMatcher      *ThemeMatcher
}

func (sa *SemanticAnalyzer) Calculate(current, candidate *Content) float64 {
    var similarity float64
    
    // 角色相关性
    characterSim := sa.characterMatcher.Match(current.Characters, candidate.Characters)
    similarity += characterSim * 0.3
    
    // 地点相关性
    locationSim := sa.locationMatcher.Match(current.Locations, candidate.Locations)
    similarity += locationSim * 0.2
    
    // 事件相关性
    eventSim := sa.eventMatcher.Match(current.Events, candidate.Events)
    similarity += eventSim * 0.3
    
    // 主题相关性
    themeSim := sa.themeMatcher.Match(current.Themes, candidate.Themes)
    similarity += themeSim * 0.2
    
    return similarity
}
```

### 3.4 记忆压缩器设计

**压缩策略**：
```go
type MemoryCompressor struct {
    summaryGenerator  *SummaryGenerator
    keywordExtractor  *KeywordExtractor
    importanceScorer  *ImportanceScorer
    redundancyRemover *RedundancyRemover
}

func (mc *MemoryCompressor) CompressMemory(memory *Memory, targetSize int) (*CompressedMemory, error) {
    // 1. 重要性评分
    scored := mc.importanceScorer.Score(memory.Items)
    
    // 2. 按重要性排序
    sort.Slice(scored, func(i, j int) bool {
        return scored[i].Importance > scored[j].Importance
    })
    
    // 3. 选择重要内容
    selected := mc.selectImportantItems(scored, targetSize)
    
    // 4. 生成摘要
    summaries := mc.summaryGenerator.GenerateSummaries(selected)
    
    // 5. 提取关键词
    keywords := mc.keywordExtractor.Extract(selected)
    
    // 6. 去除冗余
    compressed := mc.redundancyRemover.Remove(summaries, keywords)
    
    return &CompressedMemory{
        Summaries: compressed.Summaries,
        Keywords:  compressed.Keywords,
        Metadata:  compressed.Metadata,
    }, nil
}

type CompressedMemory struct {
    Summaries []Summary `json:"summaries"`
    Keywords  []Keyword `json:"keywords"`
    Metadata  Metadata  `json:"metadata"`
}

type Summary struct {
    Type        string  `json:"type"`
    Content     string  `json:"content"`
    Importance  float64 `json:"importance"`
    SourceIDs   []string `json:"source_ids"`
    Timestamp   time.Time `json:"timestamp"`
}
```

**关键信息提取**：
```go
type KeywordExtractor struct {
    stopWords    map[string]bool
    entityRecognizer *EntityRecognizer
    phraseExtractor  *PhraseExtractor
}

func (ke *KeywordExtractor) Extract(content []*Content) []Keyword {
    var keywords []Keyword
    
    for _, item := range content {
        // 1. 实体识别
        entities := ke.entityRecognizer.Recognize(item.Text)
        for _, entity := range entities {
            keywords = append(keywords, Keyword{
                Text:       entity.Text,
                Type:       entity.Type,
                Importance: entity.Confidence,
                Context:    item.ID,
            })
        }
        
        // 2. 关键短语提取
        phrases := ke.phraseExtractor.Extract(item.Text)
        for _, phrase := range phrases {
            keywords = append(keywords, Keyword{
                Text:       phrase.Text,
                Type:       "phrase",
                Importance: phrase.Score,
                Context:    item.ID,
            })
        }
    }
    
    // 3. 去重和排序
    keywords = ke.deduplicateAndSort(keywords)
    
    return keywords
}

type Keyword struct {
    Text       string  `json:"text"`
    Type       string  `json:"type"`
    Importance float64 `json:"importance"`
    Context    string  `json:"context"`
    Frequency  int     `json:"frequency"`
}
```

### 3.5 检索引擎设计

**多维度检索**：
```go
type RetrievalEngine struct {
    textIndex      *TextIndex
    semanticIndex  *SemanticIndex
    structuralIndex *StructuralIndex
    temporalIndex  *TemporalIndex
    cache         CacheService
}

func (re *RetrievalEngine) Search(query *SearchQuery) (*SearchResult, error) {
    // 1. 多维度检索
    textResults := re.textIndex.Search(query.Text)
    semanticResults := re.semanticIndex.Search(query.Entities)
    structuralResults := re.structuralIndex.Search(query.Structure)
    temporalResults := re.temporalIndex.Search(query.TimeRange)
    
    // 2. 结果合并
    merged := re.mergeResults(textResults, semanticResults, structuralResults, temporalResults)
    
    // 3. 相关性排序
    sorted := re.sortByRelevance(merged, query)
    
    // 4. 结果过滤
    filtered := re.filterResults(sorted, query.Filters)
    
    return &SearchResult{
        Items:     filtered,
        Total:     len(filtered),
        Query:     query,
        Timestamp: time.Now(),
    }, nil
}

type SearchQuery struct {
    Text      string            `json:"text"`
    Entities  []Entity          `json:"entities"`
    Structure *StructureQuery   `json:"structure"`
    TimeRange *TimeRange        `json:"time_range"`
    Filters   map[string]string `json:"filters"`
    Limit     int               `json:"limit"`
    Offset    int               `json:"offset"`
}

type SearchResult struct {
    Items     []*SearchItem `json:"items"`
    Total     int           `json:"total"`
    Query     *SearchQuery  `json:"query"`
    Timestamp time.Time     `json:"timestamp"`
}
```

**智能排序算法**：
```go
func (re *RetrievalEngine) sortByRelevance(items []*SearchItem, query *SearchQuery) []*SearchItem {
    for _, item := range items {
        score := 0.0
        
        // 文本匹配分数
        textScore := re.calculateTextScore(item, query.Text)
        score += textScore * 0.4
        
        // 语义匹配分数
        semanticScore := re.calculateSemanticScore(item, query.Entities)
        score += semanticScore * 0.3
        
        // 时间相关性分数
        temporalScore := re.calculateTemporalScore(item, query.TimeRange)
        score += temporalScore * 0.2
        
        // 结构相关性分数
        structuralScore := re.calculateStructuralScore(item, query.Structure)
        score += structuralScore * 0.1
        
        item.RelevanceScore = score
    }
    
    sort.Slice(items, func(i, j int) bool {
        return items[i].RelevanceScore > items[j].RelevanceScore
    })
    
    return items
}
```

## 4. 数据设计

### 4.1 上下文数据模型

**上下文存储结构**：
```go
type ContextStorage struct {
    ID           primitive.ObjectID `bson:"_id,omitempty" json:"id"`
    NovelID      primitive.ObjectID `bson:"novel_id" json:"novel_id"`
    ChapterID    primitive.ObjectID `bson:"chapter_id" json:"chapter_id"`
    Type         string             `bson:"type" json:"type"`
    Content      interface{}        `bson:"content" json:"content"`
    Relevance    float64            `bson:"relevance" json:"relevance"`
    Importance   float64            `bson:"importance" json:"importance"`
    AccessCount  int                `bson:"access_count" json:"access_count"`
    LastAccessed time.Time          `bson:"last_accessed" json:"last_accessed"`
    CreatedAt    time.Time          `bson:"created_at" json:"created_at"`
    UpdatedAt    time.Time          `bson:"updated_at" json:"updated_at"`
    ExpiresAt    time.Time          `bson:"expires_at" json:"expires_at"`
}
```

**记忆索引结构**：
```go
type MemoryIndex struct {
    ID         primitive.ObjectID `bson:"_id,omitempty" json:"id"`
    NovelID    primitive.ObjectID `bson:"novel_id" json:"novel_id"`
    ContentID  primitive.ObjectID `bson:"content_id" json:"content_id"`
    IndexType  string             `bson:"index_type" json:"index_type"`
    Keywords   []string           `bson:"keywords" json:"keywords"`
    Entities   []Entity           `bson:"entities" json:"entities"`
    Vector     []float64          `bson:"vector" json:"vector"`
    Metadata   map[string]string  `bson:"metadata" json:"metadata"`
    CreatedAt  time.Time          `bson:"created_at" json:"created_at"`
    UpdatedAt  time.Time          `bson:"updated_at" json:"updated_at"`
}

type Entity struct {
    Text       string  `bson:"text" json:"text"`
    Type       string  `bson:"type" json:"type"`
    Confidence float64 `bson:"confidence" json:"confidence"`
    StartPos   int     `bson:"start_pos" json:"start_pos"`
    EndPos     int     `bson:"end_pos" json:"end_pos"`
}
```

### 4.2 数据关系设计

**关联关系映射**：
```go
type RelationshipMapping struct {
    ID           primitive.ObjectID `bson:"_id,omitempty" json:"id"`
    NovelID      primitive.ObjectID `bson:"novel_id" json:"novel_id"`
    SourceType   string             `bson:"source_type" json:"source_type"`
    SourceID     primitive.ObjectID `bson:"source_id" json:"source_id"`
    TargetType   string             `bson:"target_type" json:"target_type"`
    TargetID     primitive.ObjectID `bson:"target_id" json:"target_id"`
    Relationship string             `bson:"relationship" json:"relationship"`
    Strength     float64            `bson:"strength" json:"strength"`
    Metadata     map[string]string  `bson:"metadata" json:"metadata"`
    CreatedAt    time.Time          `bson:"created_at" json:"created_at"`
    UpdatedAt    time.Time          `bson:"updated_at" json:"updated_at"`
}
```

### 4.3 索引策略

```javascript
// context_storage集合
db.context_storage.createIndex({"novel_id": 1, "chapter_id": 1})
db.context_storage.createIndex({"type": 1, "relevance": -1})
db.context_storage.createIndex({"importance": -1})
db.context_storage.createIndex({"last_accessed": -1})
db.context_storage.createIndex({"expires_at": 1}, {"expireAfterSeconds": 0})

// memory_index集合
db.memory_index.createIndex({"novel_id": 1, "index_type": 1})
db.memory_index.createIndex({"keywords": 1})
db.memory_index.createIndex({"entities.text": 1, "entities.type": 1})
db.memory_index.createIndex({"content_id": 1})

// relationship_mapping集合
db.relationship_mapping.createIndex({"novel_id": 1})
db.relationship_mapping.createIndex({"source_type": 1, "source_id": 1})
db.relationship_mapping.createIndex({"target_type": 1, "target_id": 1})
db.relationship_mapping.createIndex({"relationship": 1, "strength": -1})
```

### 4.4 缓存设计

**分层缓存策略**：
```go
// Redis缓存键设计
const (
    ContextCacheKey     = "context:%s:%s"        // 上下文缓存
    RelevanceCacheKey   = "relevance:%s:%s"      // 相关性缓存
    MemoryCacheKey      = "memory:%s:%s"         // 记忆缓存
    IndexCacheKey       = "index:%s:%s"          // 索引缓存
    SearchCacheKey      = "search:%s"            // 搜索结果缓存
)

// 缓存过期时间
const (
    ContextCacheTTL     = 2 * time.Hour     // 上下文缓存2小时
    RelevanceCacheTTL   = 1 * time.Hour     // 相关性缓存1小时
    MemoryCacheTTL      = 6 * time.Hour     // 记忆缓存6小时
    IndexCacheTTL       = 24 * time.Hour    // 索引缓存24小时
    SearchCacheTTL      = 30 * time.Minute  // 搜索缓存30分钟
)
```

## 5. 接口设计

### 5.1 API规范
遵循RESTful设计原则，提供统一的JSON响应格式。

### 5.2 核心接口

#### 5.2.1 构建上下文
```http
POST /api/v1/ai/context/build
Authorization: Bearer <token>
Content-Type: application/json

{
  "novel_id": "novel_123456789",
  "chapter_id": "chapter_123456789",
  "current_text": "主角走进了神秘的森林...",
  "context_type": "writing_assistance",
  "options": {
    "max_tokens": 4000,
    "include_characters": true,
    "include_locations": true,
    "include_plot_threads": true,
    "relevance_threshold": 0.6
  }
}
```

**响应**：
```json
{
  "code": 0,
  "message": "success",
  "data": {
    "context_id": "ctx_123456789",
    "novel_id": "novel_123456789",
    "chapter_id": "chapter_123456789",
    "short_term": {
      "current_chapter": {
        "title": "神秘森林",
        "summary": "主角进入森林寻找线索",
        "key_events": ["进入森林", "遇到神秘生物"],
        "active_characters": ["主角", "神秘生物"]
      },
      "recent_paragraphs": ["前面的段落内容..."],
      "writing_context": {
        "mood": "紧张",
        "perspective": "第三人称",
        "tense": "过去时"
      }
    },
    "mid_term": {
      "related_chapters": [
        {
          "title": "森林传说",
          "summary": "关于森林的传说",
          "relevance": 0.85
        }
      ],
      "plot_threads": [
        {
          "name": "寻找真相",
          "status": "进行中",
          "importance": 0.9
        }
      ]
    },
    "long_term": {
      "novel_summary": {
        "title": "神秘之旅",
        "theme": "探索与成长",
        "main_plot": "主角寻找失踪的朋友"
      },
      "main_characters": [
        {
          "name": "李明",
          "role": "主角",
          "personality": "勇敢、好奇"
        }
      ]
    },
    "metadata": {
      "token_count": 3500,
      "compression_ratio": 0.7,
      "build_time": 150
    }
  },
  "timestamp": 1703123456789
}
```

#### 5.2.2 智能检索
```http
POST /api/v1/ai/context/search
Authorization: Bearer <token>
Content-Type: application/json

{
  "novel_id": "novel_123456789",
  "query": {
    "text": "森林中的神秘生物",
    "entities": [
      {"text": "森林", "type": "location"},
      {"text": "神秘生物", "type": "character"}
    ],
    "time_range": {
      "start": "2023-11-01T00:00:00Z",
      "end": "2023-12-01T00:00:00Z"
    }
  },
  "options": {
    "limit": 10,
    "include_summaries": true,
    "min_relevance": 0.5
  }
}
```

**响应**：
```json
{
  "code": 0,
  "message": "success",
  "data": {
    "results": [
      {
        "id": "content_123456789",
        "type": "chapter",
        "title": "森林传说",
        "content": "关于森林中神秘生物的传说...",
        "relevance_score": 0.92,
        "entities": [
          {"text": "森林", "type": "location", "confidence": 0.95},
          {"text": "神秘生物", "type": "character", "confidence": 0.88}
        ],
        "metadata": {
          "chapter_id": "chapter_987654321",
          "word_count": 500,
          "created_at": "2023-11-15T10:00:00Z"
        }
      }
    ],
    "total": 5,
    "query_time": 45
  },
  "timestamp": 1703123456789
}
```

#### 5.2.3 记忆压缩
```http
POST /api/v1/ai/context/compress
Authorization: Bearer <token>
Content-Type: application/json

{
  "novel_id": "novel_123456789",
  "memory_type": "long_term",
  "target_size": 2000,
  "compression_options": {
    "preserve_characters": true,
    "preserve_plot_points": true,
    "min_importance": 0.7
  }
}
```

**响应**：
```json
{
  "code": 0,
  "message": "success",
  "data": {
    "compressed_memory": {
      "summaries": [
        {
          "type": "character",
          "content": "李明：主角，勇敢好奇的年轻人，正在寻找失踪的朋友",
          "importance": 0.95,
          "source_ids": ["char_123", "char_456"]
        },
        {
          "type": "plot",
          "content": "主线剧情：寻找失踪朋友的过程中发现了神秘森林的秘密",
          "importance": 0.90,
          "source_ids": ["plot_123", "plot_456"]
        }
      ],
      "keywords": [
        {"text": "神秘森林", "importance": 0.88, "frequency": 15},
        {"text": "失踪朋友", "importance": 0.85, "frequency": 12}
      ]
    },
    "compression_stats": {
      "original_size": 8000,
      "compressed_size": 2000,
      "compression_ratio": 0.25,
      "preserved_importance": 0.92
    }
  },
  "timestamp": 1703123456789
}
```

#### 5.2.4 相关性分析
```http
POST /api/v1/ai/context/relevance
Authorization: Bearer <token>
Content-Type: application/json

{
  "novel_id": "novel_123456789",
  "current_content": {
    "text": "主角走进了神秘的森林",
    "type": "chapter_content",
    "metadata": {
      "chapter_id": "chapter_123456789",
      "position": 1500
    }
  },
  "candidate_contents": [
    {
      "id": "content_1",
      "text": "森林中传说有神秘的生物",
      "type": "background_info"
    },
    {
      "id": "content_2", 
      "text": "主角的朋友在城市中失踪了",
      "type": "plot_point"
    }
  ]
}
```

**响应**：
```json
{
  "code": 0,
  "message": "success",
  "data": {
    "relevance_scores": [
      {
        "content_id": "content_1",
        "relevance_score": 0.85,
        "score_breakdown": {
          "text_similarity": 0.75,
          "semantic_similarity": 0.90,
          "temporal_relevance": 0.80,
          "structural_relevance": 0.95
        },
        "explanation": "内容与当前场景高度相关，都涉及森林和神秘元素"
      },
      {
        "content_id": "content_2",
        "relevance_score": 0.45,
        "score_breakdown": {
          "text_similarity": 0.20,
          "semantic_similarity": 0.60,
          "temporal_relevance": 0.70,
          "structural_relevance": 0.30
        },
        "explanation": "与主线剧情相关，但与当前场景关联度较低"
      }
    ],
    "analysis_time": 25
  },
  "timestamp": 1703123456789
}
```

### 5.3 错误处理
```json
{
  "code": 5001,
  "message": "上下文构建失败",
  "details": [
    {
      "field": "novel_id",
      "message": "指定的小说不存在或无权访问"
    }
  ],
  "timestamp": 1703123456789
}
```

### 5.4 性能要求
- **上下文构建**：< 200ms响应时间
- **智能检索**：< 100ms查询时间
- **相关性分析**：< 50ms计算时间
- **记忆压缩**：< 500ms处理时间

## 6. 安全设计

### 6.1 数据访问控制
```go
type AccessController struct {
    userService    UserService
    novelService   NovelService
    permissionCache map[string]*Permission
    mutex          sync.RWMutex
}

func (ac *AccessController) CheckAccess(userID, novelID string, operation string) error {
    // 检查用户权限
    permission, err := ac.getUserPermission(userID, novelID)
    if err != nil {
        return err
    }
    
    // 验证操作权限
    if !permission.CanPerform(operation) {
        return errors.New("权限不足")
    }
    
    return nil
}

type Permission struct {
    UserID     string   `json:"user_id"`
    NovelID    string   `json:"novel_id"`
    Role       string   `json:"role"`
    Operations []string `json:"operations"`
    ExpiresAt  time.Time `json:"expires_at"`
}
```

### 6.2 数据脱敏
```go
type DataSanitizer struct {
    sensitivePatterns []*regexp.Regexp
    replacementMap    map[string]string
}

func (ds *DataSanitizer) SanitizeContent(content string) string {
    sanitized := content
    
    // 移除敏感信息
    for _, pattern := range ds.sensitivePatterns {
        sanitized = pattern.ReplaceAllString(sanitized, "[REDACTED]")
    }
    
    // 替换敏感词汇
    for sensitive, replacement := range ds.replacementMap {
        sanitized = strings.ReplaceAll(sanitized, sensitive, replacement)
    }
    
    return sanitized
}
```

### 6.3 缓存安全
```go
type SecureCache struct {
    cache     CacheService
    encryptor Encryptor
    ttl       time.Duration
}

func (sc *SecureCache) Set(key string, value interface{}) error {
    // 加密敏感数据
    encrypted, err := sc.encryptor.Encrypt(value)
    if err != nil {
        return err
    }
    
    return sc.cache.Set(key, encrypted, sc.ttl)
}

func (sc *SecureCache) Get(key string, dest interface{}) error {
    encrypted, err := sc.cache.Get(key)
    if err != nil {
        return err
    }
    
    // 解密数据
    return sc.encryptor.Decrypt(encrypted, dest)
}
```

## 7. 测试设计

### 7.1 测试策略
- **单元测试**：各组件功能测试
- **集成测试**：系统集成测试
- **性能测试**：相关性计算性能测试
- **准确性测试**：上下文构建准确性测试

### 7.2 测试用例

#### 7.2.1 上下文管理器测试
```go
func TestContextManager_BuildContext(t *testing.T) {
    manager := NewContextManager(mockConfig)
    
    request := &ContextRequest{
        NovelID:     "novel123",
        ChapterID:   "chapter123",
        CurrentText: "主角走进森林",
    }
    
    context, err := manager.BuildContext(request)
    assert.NoError(t, err)
    assert.NotNil(t, context.ShortTerm)
    assert.NotNil(t, context.MidTerm)
    assert.NotNil(t, context.LongTerm)
    assert.True(t, context.Metadata.TokenCount > 0)
}
```

#### 7.2.2 相关性分析测试
```go
func TestRelevanceAnalyzer_CalculateRelevance(t *testing.T) {
    analyzer := NewRelevanceAnalyzer()
    
    current := &Content{
        Text: "主角在森林中遇到了神秘生物",
        Characters: []string{"主角", "神秘生物"},
        Locations: []string{"森林"},
    }
    
    candidate := &Content{
        Text: "森林深处隐藏着古老的秘密",
        Characters: []string{},
        Locations: []string{"森林"},
    }
    
    relevance := analyzer.CalculateRelevance(current, candidate)
    assert.True(t, relevance > 0.5)
    assert.True(t, relevance <= 1.0)
}
```

#### 7.2.3 记忆压缩测试
```go
func TestMemoryCompressor_CompressMemory(t *testing.T) {
    compressor := NewMemoryCompressor()
    
    memory := &Memory{
        Items: generateTestMemoryItems(1000), // 生成1000个测试项
    }
    
    compressed, err := compressor.CompressMemory(memory, 200)
    assert.NoError(t, err)
    assert.True(t, len(compressed.Summaries) <= 200)
    assert.True(t, len(compressed.Keywords) > 0)
    
    // 验证重要信息保留
    importantItems := filterImportantItems(memory.Items)
    for _, item := range importantItems {
        assert.True(t, containsInSummaries(compressed.Summaries, item))
    }
}
```

#### 7.2.4 检索引擎测试
```go
func TestRetrievalEngine_Search(t *testing.T) {
    engine := NewRetrievalEngine(mockIndex)
    
    query := &SearchQuery{
        Text: "神秘森林",
        Entities: []Entity{
            {Text: "森林", Type: "location"},
        },
        Limit: 10,
    }
    
    result, err := engine.Search(query)
    assert.NoError(t, err)
    assert.True(t, len(result.Items) <= 10)
    assert.True(t, result.Total >= len(result.Items))
    
    // 验证结果按相关性排序
    for i := 1; i < len(result.Items); i++ {
        assert.True(t, result.Items[i-1].RelevanceScore >= result.Items[i].RelevanceScore)
    }
}
```

### 7.3 性能基准测试
```go
func BenchmarkContextManager_BuildContext(b *testing.B) {
    manager := NewContextManager(testConfig)
    request := &ContextRequest{
        NovelID:   "novel123",
        ChapterID: "chapter123",
        CurrentText: "测试文本",
    }
    
    b.ResetTimer()
    for i := 0; i < b.N; i++ {
        _, err := manager.BuildContext(request)
        if err != nil {
            b.Fatal(err)
        }
    }
}

func BenchmarkRelevanceAnalyzer_CalculateRelevance(b *testing.B) {
    analyzer := NewRelevanceAnalyzer()
    current := generateTestContent()
    candidate := generateTestContent()
    
    b.ResetTimer()
    for i := 0; i < b.N; i++ {
        analyzer.CalculateRelevance(current, candidate)
    }
}
```

### 7.4 准确性测试
```go
func TestContextAccuracy(t *testing.T) {
    // 使用真实小说数据进行准确性测试
    testCases := loadTestCases("testdata/novels")
    
    for _, testCase := range testCases {
        context, err := buildContextForTest(testCase)
        assert.NoError(t, err)
        
        // 验证上下文包含期望的关键信息
        expectedElements := testCase.ExpectedElements
        for _, element := range expectedElements {
            assert.True(t, contextContains(context, element),
                "上下文应包含: %s", element)
        }
        
        // 验证上下文不包含不相关信息
        irrelevantElements := testCase.IrrelevantElements
        for _, element := range irrelevantElements {
            assert.False(t, contextContains(context, element),
                "上下文不应包含: %s", element)
        }
    }
}
```

## 8. 部署和运维

### 8.1 部署架构

#### 8.1.1 微服务部署
```yaml
# docker-compose.yml
version: '3.8'
services:
  context-service:
    image: qingyu/context-service:latest
    ports:
      - "8082:8082"
    environment:
      - MONGODB_URI=${MONGODB_URI}
      - REDIS_URI=${REDIS_URI}
      - ELASTICSEARCH_URI=${ELASTICSEARCH_URI}
    depends_on:
      - mongodb
      - redis
      - elasticsearch
    deploy:
      replicas: 2
      
  relevance-analyzer:
    image: qingyu/relevance-analyzer:latest
    environment:
      - MODEL_PATH=/models
    volumes:
      - ./models:/models
    deploy:
      replicas: 3
      
  memory-compressor:
    image: qingyu/memory-compressor:latest
    environment:
      - COMPRESSION_MODEL_PATH=/models/compression
    volumes:
      - ./models:/models
    deploy:
      replicas: 2

  elasticsearch:
    image: elasticsearch:8.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    volumes:
      - es_data:/usr/share/elasticsearch/data

volumes:
  es_data:
```

### 8.2 监控指标

#### 8.2.1 业务指标
- **上下文构建指标**：构建次数、平均构建时间、成功率
- **检索指标**：查询次数、平均查询时间、命中率
- **压缩指标**：压缩次数、压缩比率、压缩质量
- **相关性指标**：计算次数、平均计算时间、准确率

#### 8.2.2 系统指标
- **内存使用**：上下文缓存使用率、索引内存占用
- **存储使用**：数据库存储增长、索引大小
- **计算资源**：CPU使用率、GPU使用率（如有）
- **网络I/O**：数据传输量、请求响应时间

#### 8.2.3 质量指标
- **准确性指标**：上下文相关性准确率、检索精确率
- **完整性指标**：重要信息保留率、关键元素覆盖率
- **一致性指标**：多次构建结果一致性、时间一致性

### 8.3 告警配置
```yaml
groups:
- name: context-service
  rules:
  - alert: HighContextBuildTime
    expr: histogram_quantile(0.95, rate(context_build_duration_seconds_bucket[5m])) > 0.5
    for: 3m
    labels:
      severity: warning
    annotations:
      summary: "上下文构建时间过长"
      
  - alert: LowRelevanceAccuracy
    expr: relevance_accuracy_ratio < 0.8
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "相关性分析准确率过低"
      
  - alert: HighMemoryUsage
    expr: context_cache_memory_usage_ratio > 0.9
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "上下文缓存内存使用率过高"
```

### 8.4 数据备份和恢复
```go
type BackupManager struct {
    storage     StorageService
    compressor  CompressionService
    encryptor   EncryptionService
    scheduler   *cron.Cron
}

func (bm *BackupManager) ScheduleBackup() {
    // 每日备份上下文数据
    bm.scheduler.AddFunc("0 2 * * *", func() {
        err := bm.backupContextData()
        if err != nil {
            log.Errorf("上下文数据备份失败: %v", err)
        }
    })
    
    // 每周备份索引数据
    bm.scheduler.AddFunc("0 3 * * 0", func() {
        err := bm.backupIndexData()
        if err != nil {
            log.Errorf("索引数据备份失败: %v", err)
        }
    })
}

func (bm *BackupManager) RestoreFromBackup(backupID string) error {
    // 恢复上下文数据
    contextData, err := bm.loadBackup(backupID, "context")
    if err != nil {
        return err
    }
    
    err = bm.restoreContextData(contextData)
    if err != nil {
        return err
    }
    
    // 重建索引
    return bm.rebuildIndexes()
}
```

## 9. 风险评估

### 9.1 技术风险

#### 9.1.1 相关性计算准确性
- **风险**：相关性算法准确性不足
- **影响**：上下文质量下降，AI生成效果差
- **应对**：多算法融合、人工标注数据训练、持续优化

#### 9.1.2 内存和存储压力
- **风险**：大量上下文数据导致内存和存储压力
- **影响**：系统性能下降，成本增加
- **应对**：智能缓存策略、数据压缩、定期清理

#### 9.1.3 计算复杂度
- **风险**：复杂的相关性计算导致响应时间过长
- **影响**：用户体验下降
- **应对**：算法优化、并行计算、预计算缓存

### 9.2 业务风险

#### 9.2.1 上下文质量不稳定
- **风险**：不同场景下上下文质量差异较大
- **影响**：用户体验不一致
- **应对**：场景化优化、质量评估机制、用户反馈收集

#### 9.2.2 依赖现有系统
- **风险**：过度依赖现有大纲、角色等系统
- **影响**：系统耦合度高，维护困难
- **应对**：接口抽象、适配器模式、降级策略

### 9.3 数据风险

#### 9.3.1 数据一致性
- **风险**：多系统数据同步不一致
- **影响**：上下文信息错误或过时
- **应对**：事件驱动同步、数据校验、定期同步

#### 9.3.2 隐私保护
- **风险**：用户创作内容隐私泄露
- **影响**：法律风险、用户信任度下降
- **应对**：数据加密、访问控制、审计日志

## 10. 实施计划

### 10.1 开发阶段

#### 第一阶段（3周）：基础架构
- [ ] 上下文管理器框架
- [ ] 数据适配层实现
- [ ] 基础缓存策略
- [ ] 数据模型设计

#### 第二阶段（3周）：核心算法
- [ ] 相关性分析算法
- [ ] 记忆压缩算法
- [ ] 检索引擎实现
- [ ] 智能排序算法

#### 第三阶段（2周）：系统集成
- [ ] 现有系统集成
- [ ] API接口实现
- [ ] 缓存优化
- [ ] 性能调优

#### 第四阶段（1周）：测试和优化
- [ ] 单元测试编写
- [ ] 集成测试执行
- [ ] 性能测试和优化
- [ ] 准确性验证

### 10.2 测试阶段

#### 功能测试（1周）
- [ ] 上下文构建测试
- [ ] 相关性分析测试
- [ ] 记忆压缩测试
- [ ] 检索功能测试

#### 性能测试（3天）
- [ ] 响应时间测试
- [ ] 并发处理测试
- [ ] 内存使用测试
- [ ] 存储性能测试

#### 准确性测试（4天）
- [ ] 相关性准确率测试
- [ ] 上下文质量评估
- [ ] 用户场景测试
- [ ] 对比测试

### 10.3 上线计划

#### 灰度发布（1周）
- [ ] 小范围用户测试
- [ ] 质量指标监控
- [ ] 问题修复和优化
- [ ] 用户反馈收集

#### 正式发布（3天）
- [ ] 全量用户发布
- [ ] 监控告警配置
- [ ] 运维文档交付
- [ ] 使用指南编写

### 10.4 后续优化

#### 算法优化（持续）
- [ ] 相关性算法改进
- [ ] 压缩算法优化
- [ ] 检索算法升级
- [ ] 新技术引入

#### 功能增强（季度）
- [ ] 多模态上下文支持
- [ ] 个性化上下文定制
- [ ] 协作上下文管理
- [ ] 智能推荐功能