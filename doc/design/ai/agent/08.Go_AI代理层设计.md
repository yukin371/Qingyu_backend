# Go AI代理层设计

> **文档版本**: v1.0  
> **创建时间**: 2025-10-21  
> **实施状态**: 设计阶段

## 📋 文档概述

本文档详细设计Go AI代理层的架构，作为Gin后端与Python AI Agent Service之间的桥梁，负责请求转发、流式响应代理、熔断限流、错误转换等关键功能。

## 🎯 设计目标

1. **高性能代理**：低延迟的请求转发，高并发处理能力
2. **流式响应**：SSE/WebSocket流式响应代理，提升用户体验
3. **服务保护**：熔断器、限流器、超时控制，保护Python服务
4. **错误转换**：将Python异常转换为统一的Go错误格式
5. **可观测性**：完善的日志、监控、追踪

---

## 一、架构设计

### 1.1 整体架构图

```
┌────────────────────────────────────────────────────────────┐
│                  Gin Web Framework                         │
│                                                              │
│  ┌──────────────────────────────────────────────────┐      │
│  │            Router Layer                          │      │
│  │  POST /api/v1/ai/generate                        │      │
│  │  POST /api/v1/ai/chat                            │      │
│  │  GET  /api/v1/ai/rag/search                      │      │
│  └──────────────────┬───────────────────────────────┘      │
│                     │                                       │
│  ┌──────────────────▼───────────────────────────────┐      │
│  │            API Layer                             │      │
│  │  - 参数验证 (validator)                          │      │
│  │  - 认证授权 (JWT middleware)                     │      │
│  │  - 请求日志                                       │      │
│  └──────────────────┬───────────────────────────────┘      │
│                     │                                       │
│  ┌──────────────────▼───────────────────────────────┐      │
│  │         AI Proxy Service                         │      │
│  │                                                    │      │
│  │  ┌──────────────────────────────────────────┐    │      │
│  │  │  Request Handler                         │    │      │
│  │  │  - 参数转换                              │    │      │
│  │  │  - 上下文传递                            │    │      │
│  │  └──────────┬───────────────────────────────┘    │      │
│  │             │                                     │      │
│  │  ┌──────────▼───────────────────────────────┐    │      │
│  │  │  Service Protection Layer                │    │      │
│  │  │                                           │    │      │
│  │  │  ┌────────────┬──────────┬────────────┐ │    │      │
│  │  │  │Rate Limiter│Circuit   │Timeout     │ │    │      │
│  │  │  │(限流器)    │Breaker   │Control     │ │    │      │
│  │  │  │            │(熔断器)  │(超时控制)  │ │    │      │
│  │  │  └────────────┴──────────┴────────────┘ │    │      │
│  │  └──────────┬───────────────────────────────┘    │      │
│  │             │                                     │      │
│  │  ┌──────────▼───────────────────────────────┐    │      │
│  │  │  gRPC Client Pool                        │    │      │
│  │  │  - 连接池管理                            │    │      │
│  │  │  - 负载均衡                              │    │      │
│  │  │  - 健康检查                              │    │      │
│  │  └──────────┬───────────────────────────────┘    │      │
│  │             │                                     │      │
│  │  ┌──────────▼───────────────────────────────┐    │      │
│  │  │  Stream Response Handler                 │    │      │
│  │  │  - gRPC Stream → SSE                     │    │      │
│  │  │  - WebSocket support                     │    │      │
│  │  │  - 错误恢复                              │    │      │
│  │  └──────────┬───────────────────────────────┘    │      │
│  │             │                                     │      │
│  │  ┌──────────▼───────────────────────────────┐    │      │
│  │  │  Error Converter                         │    │      │
│  │  │  - gRPC错误 → Go错误                     │    │      │
│  │  │  - 错误码映射                            │    │      │
│  │  │  - 错误日志                              │    │      │
│  │  └──────────────────────────────────────────┘    │      │
│  └────────────────────────────────────────────────┘      │
└──────────────────┬───────────────────────────────────────┘
                   │ gRPC
┌──────────────────▼───────────────────────────────────────┐
│          Python AI Agent Service                         │
│                (gRPC Server)                              │
└──────────────────────────────────────────────────────────┘
```

### 1.2 模块职责

| 模块 | 职责 | 不负责 |
|------|------|--------|
| **AI Proxy Service** | 请求转发、流式代理、熔断限流、错误转换 | AI逻辑、工具执行、RAG检索 |
| **gRPC Client Pool** | 连接管理、负载均衡、健康检查 | 业务逻辑 |
| **Stream Handler** | 流式响应代理、SSE转换 | 数据生成 |
| **Circuit Breaker** | 服务保护、故障隔离 | 服务实现 |

---

## 二、核心组件设计

### 2.1 AI Proxy Service接口

```go
package ai

import (
    "context"
    "io"
    "time"
)

// AIProxyService AI代理服务接口
type AIProxyService interface {
    // 文本生成
    GenerateText(ctx context.Context, req *GenerateRequest) (*GenerateResponse, error)
    GenerateTextStream(ctx context.Context, req *GenerateRequest) (<-chan *StreamChunk, error)
    
    // 对话
    Chat(ctx context.Context, req *ChatRequest) (*ChatResponse, error)
    ChatStream(ctx context.Context, req *ChatRequest) (<-chan *StreamChunk, error)
    
    // RAG增强生成
    RAGGenerate(ctx context.Context, req *RAGRequest) (*RAGResponse, error)
    
    // Agent执行
    ExecuteAgent(ctx context.Context, req *AgentRequest) (*AgentResponse, error)
    
    // 健康检查
    Health(ctx context.Context) error
    
    // 关闭连接
    Close() error
}

// GenerateRequest 生成请求
type GenerateRequest struct {
    Prompt      string            `json:"prompt" validate:"required"`
    Model       string            `json:"model"`
    Temperature float32           `json:"temperature"`
    MaxTokens   int               `json:"maxTokens"`
    Stream      bool              `json:"stream"`
    Metadata    map[string]string `json:"metadata"`
}

// StreamChunk 流式响应块
type StreamChunk struct {
    Delta   string `json:"delta"`
    IsFinal bool   `json:"isFinal"`
    Error   string `json:"error,omitempty"`
}

// ChatRequest 对话请求
type ChatRequest struct {
    SessionID   string    `json:"sessionId"`
    Messages    []Message `json:"messages" validate:"required"`
    Model       string    `json:"model"`
    Temperature float32   `json:"temperature"`
    Stream      bool      `json:"stream"`
}

// Message 消息
type Message struct {
    Role    string `json:"role" validate:"required,oneof=system user assistant"`
    Content string `json:"content" validate:"required"`
}

// AgentRequest Agent执行请求
type AgentRequest struct {
    AgentType string            `json:"agentType" validate:"required,oneof=creative analysis review assistant"`
    Task      string            `json:"task" validate:"required"`
    Context   map[string]string `json:"context"`
    Tools     []string          `json:"tools"`
}

// AgentResponse Agent执行响应
type AgentResponse struct {
    Result    string     `json:"result"`
    ToolCalls []ToolCall `json:"toolCalls"`
    Status    string     `json:"status"`
    Reasoning []string   `json:"reasoning"`
}

// ToolCall 工具调用记录
type ToolCall struct {
    ToolName   string                 `json:"toolName"`
    Parameters map[string]interface{} `json:"parameters"`
    Result     interface{}            `json:"result"`
}
```

### 2.2 AI Proxy Service实现

```go
package ai

import (
    "context"
    "fmt"
    "io"
    "sync"
    "time"
    
    "google.golang.org/grpc"
    "google.golang.org/grpc/codes"
    "google.golang.org/grpc/status"
    
    pb "Qingyu_backend/proto/ai"
    "Qingyu_backend/pkg/errors"
    "Qingyu_backend/pkg/logger"
)

// AIProxyServiceImpl AI代理服务实现
type AIProxyServiceImpl struct {
    // gRPC客户端
    grpcClient pb.AIAgentServiceClient
    conn       *grpc.ClientConn
    
    // 服务保护组件
    circuitBreaker *CircuitBreaker
    rateLimiter    *RateLimiter
    
    // 配置
    config *ProxyConfig
    
    // 日志
    logger logger.Logger
    
    // 连接池
    pool *ConnectionPool
}

// ProxyConfig 代理配置
type ProxyConfig struct {
    PythonAddr      string        `mapstructure:"python_addr"`
    Timeout         time.Duration `mapstructure:"timeout"`
    MaxRetries      int           `mapstructure:"max_retries"`
    RateLimit       int           `mapstructure:"rate_limit"` // QPS
    CircuitMaxFails int           `mapstructure:"circuit_max_fails"`
    CircuitResetTime time.Duration `mapstructure:"circuit_reset_time"`
}

// NewAIProxyService 创建AI代理服务
func NewAIProxyService(config *ProxyConfig, logger logger.Logger) (*AIProxyServiceImpl, error) {
    // 1. 建立gRPC连接
    conn, err := grpc.Dial(
        config.PythonAddr,
        grpc.WithInsecure(),
        grpc.WithBlock(),
        grpc.WithTimeout(10*time.Second),
        grpc.WithKeepaliveParams(keepalive.ClientParameters{
            Time:                10 * time.Second,
            Timeout:             3 * time.Second,
            PermitWithoutStream: true,
        }),
    )
    if err != nil {
        return nil, fmt.Errorf("连接Python AI服务失败: %w", err)
    }
    
    // 2. 创建gRPC客户端
    client := pb.NewAIAgentServiceClient(conn)
    
    // 3. 创建服务保护组件
    circuitBreaker := NewCircuitBreaker(
        config.CircuitMaxFails,
        config.CircuitResetTime,
    )
    
    rateLimiter := NewRateLimiter(
        config.RateLimit,
        time.Second,
    )
    
    return &AIProxyServiceImpl{
        grpcClient:     client,
        conn:           conn,
        circuitBreaker: circuitBreaker,
        rateLimiter:    rateLimiter,
        config:         config,
        logger:         logger,
    }, nil
}

// GenerateText 文本生成（同步）
func (s *AIProxyServiceImpl) GenerateText(ctx context.Context, req *GenerateRequest) (*GenerateResponse, error) {
    // 1. 限流检查
    if !s.rateLimiter.Allow() {
        s.logger.Warn("请求被限流拒绝")
        return nil, errors.NewRateLimitError("请求过于频繁，请稍后再试")
    }
    
    // 2. 熔断检查
    if !s.circuitBreaker.Allow() {
        s.logger.Warn("熔断器开启，拒绝请求")
        return nil, errors.NewServiceUnavailableError("AI服务暂时不可用，请稍后再试")
    }
    
    // 3. 设置超时
    ctx, cancel := context.WithTimeout(ctx, s.config.Timeout)
    defer cancel()
    
    // 4. 转换请求
    pbReq := &pb.GenerateRequest{
        Prompt:      req.Prompt,
        Model:       req.Model,
        Temperature: req.Temperature,
        MaxTokens:   int32(req.MaxTokens),
        Metadata:    req.Metadata,
    }
    
    // 5. 调用Python服务
    s.logger.Info("调用Python AI服务生成文本", 
        "model", req.Model,
        "prompt_len", len(req.Prompt))
    
    start := time.Now()
    resp, err := s.grpcClient.GenerateText(ctx, pbReq)
    duration := time.Since(start)
    
    if err != nil {
        s.circuitBreaker.RecordFailure()
        s.logger.Error("调用Python AI服务失败", 
            "error", err,
            "duration", duration)
        return nil, s.convertError(err)
    }
    
    s.circuitBreaker.RecordSuccess()
    s.logger.Info("Python AI服务调用成功",
        "duration", duration,
        "tokens_used", resp.TokensUsed)
    
    // 6. 转换响应
    return &GenerateResponse{
        Text:       resp.Text,
        TokensUsed: int(resp.TokensUsed),
        Model:      resp.Model,
    }, nil
}

// GenerateTextStream 流式文本生成
func (s *AIProxyServiceImpl) GenerateTextStream(ctx context.Context, req *GenerateRequest) (<-chan *StreamChunk, error) {
    // 1. 限流和熔断检查
    if !s.rateLimiter.Allow() {
        return nil, errors.NewRateLimitError("请求过于频繁")
    }
    if !s.circuitBreaker.Allow() {
        return nil, errors.NewServiceUnavailableError("AI服务暂时不可用")
    }
    
    // 2. 转换请求
    pbReq := &pb.GenerateRequest{
        Prompt:      req.Prompt,
        Model:       req.Model,
        Temperature: req.Temperature,
        MaxTokens:   int32(req.MaxTokens),
    }
    
    // 3. 调用gRPC流式接口
    s.logger.Info("调用Python AI服务流式生成", "model", req.Model)
    
    stream, err := s.grpcClient.GenerateTextStream(ctx, pbReq)
    if err != nil {
        s.circuitBreaker.RecordFailure()
        s.logger.Error("创建流式调用失败", "error", err)
        return nil, s.convertError(err)
    }
    
    // 4. 创建输出channel
    chunkChan := make(chan *StreamChunk, 100)
    
    // 5. 异步接收流式数据
    go s.handleStream(ctx, stream, chunkChan)
    
    return chunkChan, nil
}

// handleStream 处理流式响应
func (s *AIProxyServiceImpl) handleStream(
    ctx context.Context,
    stream pb.AIAgentService_GenerateTextStreamClient,
    chunkChan chan<- *StreamChunk,
) {
    defer close(chunkChan)
    
    start := time.Now()
    chunkCount := 0
    
    for {
        select {
        case <-ctx.Done():
            s.logger.Warn("流式调用被取消", "reason", ctx.Err())
            chunkChan <- &StreamChunk{
                Error: "请求已取消",
            }
            return
            
        default:
            chunk, err := stream.Recv()
            if err == io.EOF {
                // 流结束
                s.circuitBreaker.RecordSuccess()
                s.logger.Info("流式调用完成",
                    "duration", time.Since(start),
                    "chunks", chunkCount)
                return
            }
            
            if err != nil {
                s.circuitBreaker.RecordFailure()
                s.logger.Error("流式接收失败", "error", err)
                chunkChan <- &StreamChunk{
                    Error: s.convertError(err).Error(),
                }
                return
            }
            
            // 发送chunk
            chunkChan <- &StreamChunk{
                Delta:   chunk.Delta,
                IsFinal: chunk.IsFinal,
            }
            chunkCount++
        }
    }
}

// ChatStream 流式对话
func (s *AIProxyServiceImpl) ChatStream(ctx context.Context, req *ChatRequest) (<-chan *StreamChunk, error) {
    if !s.rateLimiter.Allow() {
        return nil, errors.NewRateLimitError("请求过于频繁")
    }
    if !s.circuitBreaker.Allow() {
        return nil, errors.NewServiceUnavailableError("AI服务暂时不可用")
    }
    
    // 转换消息
    messages := make([]*pb.Message, len(req.Messages))
    for i, msg := range req.Messages {
        messages[i] = &pb.Message{
            Role:    msg.Role,
            Content: msg.Content,
        }
    }
    
    pbReq := &pb.ChatRequest{
        SessionId:   req.SessionID,
        Messages:    messages,
        Model:       req.Model,
        Temperature: req.Temperature,
    }
    
    stream, err := s.grpcClient.ChatStream(ctx, pbReq)
    if err != nil {
        s.circuitBreaker.RecordFailure()
        return nil, s.convertError(err)
    }
    
    chunkChan := make(chan *StreamChunk, 100)
    go s.handleStream(ctx, stream, chunkChan)
    
    return chunkChan, nil
}

// ExecuteAgent 执行Agent
func (s *AIProxyServiceImpl) ExecuteAgent(ctx context.Context, req *AgentRequest) (*AgentResponse, error) {
    if !s.rateLimiter.Allow() {
        return nil, errors.NewRateLimitError("请求过于频繁")
    }
    if !s.circuitBreaker.Allow() {
        return nil, errors.NewServiceUnavailableError("AI服务暂时不可用")
    }
    
    ctx, cancel := context.WithTimeout(ctx, 5*time.Minute) // Agent任务可能较长
    defer cancel()
    
    pbReq := &pb.AgentRequest{
        AgentType: req.AgentType,
        Task:      req.Task,
        Context:   req.Context,
        Tools:     req.Tools,
    }
    
    s.logger.Info("执行Agent任务", "type", req.AgentType, "task", req.Task)
    
    start := time.Now()
    resp, err := s.grpcClient.ExecuteAgent(ctx, pbReq)
    duration := time.Since(start)
    
    if err != nil {
        s.circuitBreaker.RecordFailure()
        s.logger.Error("Agent执行失败", "error", err, "duration", duration)
        return nil, s.convertError(err)
    }
    
    s.circuitBreaker.RecordSuccess()
    s.logger.Info("Agent执行成功", "duration", duration, "tool_calls", len(resp.ToolCalls))
    
    // 转换工具调用
    toolCalls := make([]ToolCall, len(resp.ToolCalls))
    for i, tc := range resp.ToolCalls {
        var params map[string]interface{}
        json.Unmarshal([]byte(tc.Parameters), &params)
        
        toolCalls[i] = ToolCall{
            ToolName:   tc.ToolName,
            Parameters: params,
            Result:     tc.Result,
        }
    }
    
    return &AgentResponse{
        Result:    resp.Result,
        ToolCalls: toolCalls,
        Status:    resp.Status,
    }, nil
}

// Health 健康检查
func (s *AIProxyServiceImpl) Health(ctx context.Context) error {
    ctx, cancel := context.WithTimeout(ctx, 5*time.Second)
    defer cancel()
    
    resp, err := s.grpcClient.HealthCheck(ctx, &pb.HealthRequest{})
    if err != nil {
        return fmt.Errorf("健康检查失败: %w", err)
    }
    
    if resp.Status != "healthy" {
        return fmt.Errorf("服务状态异常: %s", resp.Status)
    }
    
    return nil
}

// Close 关闭连接
func (s *AIProxyServiceImpl) Close() error {
    if s.conn != nil {
        return s.conn.Close()
    }
    return nil
}

// convertError 错误转换
func (s *AIProxyServiceImpl) convertError(err error) error {
    // 转换gRPC错误为Go错误
    st, ok := status.FromError(err)
    if !ok {
        return errors.NewInternalError("AI服务调用失败").WithCause(err)
    }
    
    switch st.Code() {
    case codes.DeadlineExceeded:
        return errors.NewTimeoutError("AI服务响应超时")
    case codes.Unavailable:
        return errors.NewServiceUnavailableError("AI服务不可用")
    case codes.InvalidArgument:
        return errors.NewValidationError(st.Message())
    case codes.ResourceExhausted:
        return errors.NewRateLimitError("AI服务资源耗尽")
    default:
        return errors.NewInternalError(st.Message()).WithCause(err)
    }
}
```

### 2.3 熔断器实现

```go
package ai

import (
    "sync"
    "time"
)

// CircuitState 熔断器状态
type CircuitState int

const (
    StateClosed   CircuitState = iota // 关闭（正常）
    StateHalfOpen                      // 半开（尝试恢复）
    StateOpen                          // 开启（拒绝请求）
)

// CircuitBreaker 熔断器
type CircuitBreaker struct {
    maxFailures int           // 最大失败次数
    resetTime   time.Duration // 重置时间
    
    mu           sync.RWMutex
    state        CircuitState
    failures     int
    lastFailTime time.Time
}

// NewCircuitBreaker 创建熔断器
func NewCircuitBreaker(maxFailures int, resetTime time.Duration) *CircuitBreaker {
    return &CircuitBreaker{
        maxFailures: maxFailures,
        resetTime:   resetTime,
        state:       StateClosed,
    }
}

// Allow 是否允许请求
func (cb *CircuitBreaker) Allow() bool {
    cb.mu.Lock()
    defer cb.mu.Unlock()
    
    now := time.Now()
    
    switch cb.state {
    case StateClosed:
        return true
        
    case StateOpen:
        // 检查是否可以尝试恢复
        if now.Sub(cb.lastFailTime) > cb.resetTime {
            cb.state = StateHalfOpen
            return true
        }
        return false
        
    case StateHalfOpen:
        return true
        
    default:
        return false
    }
}

// RecordSuccess 记录成功
func (cb *CircuitBreaker) RecordSuccess() {
    cb.mu.Lock()
    defer cb.mu.Unlock()
    
    cb.failures = 0
    if cb.state == StateHalfOpen {
        cb.state = StateClosed
    }
}

// RecordFailure 记录失败
func (cb *CircuitBreaker) RecordFailure() {
    cb.mu.Lock()
    defer cb.mu.Unlock()
    
    cb.failures++
    cb.lastFailTime = time.Now()
    
    if cb.failures >= cb.maxFailures {
        cb.state = StateOpen
    }
}

// GetState 获取状态
func (cb *CircuitBreaker) GetState() CircuitState {
    cb.mu.RLock()
    defer cb.mu.RUnlock()
    return cb.state
}
```

### 2.4 限流器实现

```go
package ai

import (
    "sync"
    "time"
)

// RateLimiter 限流器（令牌桶算法）
type RateLimiter struct {
    capacity int           // 桶容量
    refillRate time.Duration // 补充速率
    
    mu sync.Mutex
    tokens int
    lastRefill time.Time
}

// NewRateLimiter 创建限流器
func NewRateLimiter(ratePerSecond int, interval time.Duration) *RateLimiter {
    return &RateLimiter{
        capacity:   ratePerSecond,
        refillRate: interval,
        tokens:     ratePerSecond,
        lastRefill: time.Now(),
    }
}

// Allow 是否允许请求
func (rl *RateLimiter) Allow() bool {
    rl.mu.Lock()
    defer rl.mu.Unlock()
    
    // 补充令牌
    rl.refill()
    
    if rl.tokens > 0 {
        rl.tokens--
        return true
    }
    
    return false
}

// refill 补充令牌
func (rl *RateLimiter) refill() {
    now := time.Now()
    elapsed := now.Sub(rl.lastRefill)
    
    tokensToAdd := int(elapsed / rl.refillRate)
    if tokensToAdd > 0 {
        rl.tokens += tokensToAdd
        if rl.tokens > rl.capacity {
            rl.tokens = rl.capacity
        }
        rl.lastRefill = now
    }
}
```

---

## 三、API层集成

### 3.1 HTTP Handler

```go
package api

import (
    "net/http"
    
    "github.com/gin-gonic/gin"
    
    "Qingyu_backend/service/ai"
    "Qingyu_backend/pkg/response"
)

// AIApi AI API处理器
type AIApi struct {
    proxyService ai.AIProxyService
    validator    *validator.Validate
}

// NewAIApi 创建AI API处理器
func NewAIApi(proxyService ai.AIProxyService) *AIApi {
    return &AIApi{
        proxyService: proxyService,
        validator:    validator.New(),
    }
}

// GenerateText 文本生成
func (api *AIApi) GenerateText(c *gin.Context) {
    var req ai.GenerateRequest
    if err := c.ShouldBindJSON(&req); err != nil {
        response.Error(c, http.StatusBadRequest, "参数错误", err.Error())
        return
    }
    
    if err := api.validator.Struct(&req); err != nil {
        response.ValidationError(c, err)
        return
    }
    
    // 判断是否流式
    if req.Stream {
        api.GenerateTextStream(c, &req)
        return
    }
    
    // 同步生成
    resp, err := api.proxyService.GenerateText(c.Request.Context(), &req)
    if err != nil {
        api.handleError(c, err)
        return
    }
    
    response.Success(c, http.StatusOK, "生成成功", resp)
}

// GenerateTextStream 流式文本生成
func (api *AIApi) GenerateTextStream(c *gin.Context, req *ai.GenerateRequest) {
    // 设置SSE响应头
    c.Header("Content-Type", "text/event-stream")
    c.Header("Cache-Control", "no-cache")
    c.Header("Connection", "keep-alive")
    c.Header("X-Accel-Buffering", "no") // 禁用Nginx缓冲
    
    // 获取流式channel
    chunkChan, err := api.proxyService.GenerateTextStream(c.Request.Context(), req)
    if err != nil {
        api.handleError(c, err)
        return
    }
    
    // 流式推送
    c.Stream(func(w io.Writer) bool {
        if chunk, ok := <-chunkChan; ok {
            if chunk.Error != "" {
                c.SSEvent("error", chunk.Error)
                return false
            }
            
            c.SSEvent("message", gin.H{
                "delta":   chunk.Delta,
                "isFinal": chunk.IsFinal,
            })
            
            return !chunk.IsFinal
        }
        return false
    })
}

// ExecuteAgent 执行Agent
func (api *AIApi) ExecuteAgent(c *gin.Context) {
    var req ai.AgentRequest
    if err := c.ShouldBindJSON(&req); err != nil {
        response.Error(c, http.StatusBadRequest, "参数错误", err.Error())
        return
    }
    
    if err := api.validator.Struct(&req); err != nil {
        response.ValidationError(c, err)
        return
    }
    
    resp, err := api.proxyService.ExecuteAgent(c.Request.Context(), &req)
    if err != nil {
        api.handleError(c, err)
        return
    }
    
    response.Success(c, http.StatusOK, "执行成功", resp)
}

// handleError 错误处理
func (api *AIApi) handleError(c *gin.Context, err error) {
    // 根据错误类型返回相应的HTTP状态码
    switch e := err.(type) {
    case *errors.RateLimitError:
        response.Error(c, http.StatusTooManyRequests, e.Message, e.Details)
    case *errors.ServiceUnavailableError:
        response.Error(c, http.StatusServiceUnavailable, e.Message, e.Details)
    case *errors.TimeoutError:
        response.Error(c, http.StatusGatewayTimeout, e.Message, e.Details)
    case *errors.ValidationError:
        response.Error(c, http.StatusBadRequest, e.Message, e.Details)
    default:
        response.Error(c, http.StatusInternalServerError, "服务错误", err.Error())
    }
}
```

### 3.2 路由注册

```go
package router

func InitAIRouter(r *gin.RouterGroup, container *service.ServiceContainer) {
    // 获取AI Proxy Service
    proxyService := container.GetAIProxyService()
    
    aiApi := api.NewAIApi(proxyService)
    
    aiGroup := r.Group("/ai")
    aiGroup.Use(middleware.JWTAuth()) // 需要认证
    {
        // 文本生成
        aiGroup.POST("/generate", aiApi.GenerateText)
        
        // 对话
        aiGroup.POST("/chat", aiApi.Chat)
        
        // Agent执行
        aiGroup.POST("/agent/execute", aiApi.ExecuteAgent)
        
        // RAG检索
        aiGroup.POST("/rag/search", aiApi.RAGSearch)
        
        // 健康检查（无需认证）
        aiGroup.GET("/health", aiApi.Health)
    }
}
```

---

## 四、监控与可观测性

### 4.1 Prometheus指标

```go
package ai

import (
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

var (
    // 请求计数
    requestsTotal = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "ai_proxy_requests_total",
            Help: "Total number of AI proxy requests",
        },
        []string{"method", "status"},
    )
    
    // 请求延迟
    requestDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "ai_proxy_request_duration_seconds",
            Help:    "AI proxy request duration in seconds",
            Buckets: prometheus.DefBuckets,
        },
        []string{"method"},
    )
    
    // 熔断器状态
    circuitBreakerState = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "ai_proxy_circuit_breaker_state",
            Help: "Circuit breaker state (0=closed, 1=half-open, 2=open)",
        },
        []string{"service"},
    )
    
    // 限流拒绝数
    rateLimitRejections = promauto.NewCounter(
        prometheus.CounterOpts{
            Name: "ai_proxy_rate_limit_rejections_total",
            Help: "Total number of requests rejected by rate limiter",
        },
    )
)

// 记录指标
func (s *AIProxyServiceImpl) recordMetrics(method string, duration time.Duration, err error) {
    status := "success"
    if err != nil {
        status = "error"
    }
    
    requestsTotal.WithLabelValues(method, status).Inc()
    requestDuration.WithLabelValues(method).Observe(duration.Seconds())
    
    circuitBreakerState.WithLabelValues("python_ai").Set(float64(s.circuitBreaker.GetState()))
}
```

### 4.2 结构化日志

```go
// 使用结构化日志
s.logger.Info("AI请求开始",
    "method", "GenerateText",
    "user_id", userID,
    "request_id", requestID,
    "model", req.Model,
)

s.logger.Error("AI请求失败",
    "method", "GenerateText",
    "error", err,
    "duration", duration,
    "circuit_state", s.circuitBreaker.GetState(),
)
```

---

## 五、部署与配置

### 5.1 配置示例

```yaml
# config.yaml
ai:
  proxy:
    python_addr: "localhost:50051"
    timeout: 30s
    max_retries: 3
    rate_limit: 100  # 100 QPS
    circuit_max_fails: 5
    circuit_reset_time: 30s
```

### 5.2 服务初始化

```go
// cmd/server/main.go
func initAIProxyService(cfg *config.Config) ai.AIProxyService {
    proxyConfig := &ai.ProxyConfig{
        PythonAddr:       cfg.AI.Proxy.PythonAddr,
        Timeout:          cfg.AI.Proxy.Timeout,
        MaxRetries:       cfg.AI.Proxy.MaxRetries,
        RateLimit:        cfg.AI.Proxy.RateLimit,
        CircuitMaxFails:  cfg.AI.Proxy.CircuitMaxFails,
        CircuitResetTime: cfg.AI.Proxy.CircuitResetTime,
    }
    
    proxyService, err := ai.NewAIProxyService(proxyConfig, logger)
    if err != nil {
        log.Fatal("初始化AI代理服务失败:", err)
    }
    
    // 健康检查
    if err := proxyService.Health(context.Background()); err != nil {
        log.Warn("Python AI服务健康检查失败:", err)
    }
    
    return proxyService
}
```

---

**文档版本**: v1.0  
**创建时间**: 2025-10-21  
**负责人**: 后端团队  
**审核状态**: 待评审

