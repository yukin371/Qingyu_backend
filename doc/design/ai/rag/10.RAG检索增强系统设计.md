# RAGæ£€ç´¢å¢å¼ºç³»ç»Ÿè®¾è®¡

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
> **åˆ›å»ºæ—¶é—´**: 2025-10-21

## ğŸ“‹ æ–‡æ¡£æ¦‚è¿°

æœ¬æ–‡æ¡£è®¾è®¡é’ç¾½å¹³å°çš„RAGï¼ˆRetrieval Augmented Generationï¼‰æ£€ç´¢å¢å¼ºç³»ç»Ÿï¼Œç”¨äºæ™ºèƒ½å†™ä½œç»­å†™ã€è®¾å®šé—®ç­”ã€é˜…è¯»åŠ©æ‰‹ç­‰åœºæ™¯ã€‚

---

## ä¸€ã€ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               RAG System Architecture                 â”‚
â”‚                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚      Vectorization Engine (å‘é‡åŒ–å¼•æ“)       â”‚   â”‚
â”‚  â”‚  - Text Preprocessing                        â”‚   â”‚
â”‚  â”‚  - Chunk Splitting (æ™ºèƒ½åˆ†å—)               â”‚   â”‚
â”‚  â”‚  - Embedding (BGE/M3E/OpenAI)                â”‚   â”‚
â”‚  â”‚  - Batch Processing                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚      Knowledge Base Management               â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚  â”‚  â”‚ User Private KB (ç”¨æˆ·ç§æœ‰çŸ¥è¯†åº“)   â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  - é¡¹ç›®æ–‡æ¡£                          â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  - è§’è‰²å¡                            â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  - å¤§çº²                              â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  - è®¾å®šç™¾ç§‘                          â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  - å¯¹è¯å†å²                          â”‚    â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚  â”‚  â”‚ Platform KB (å¹³å°çŸ¥è¯†åº“)           â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  - ä¼˜ç§€ä½œå“                          â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  - å†™ä½œæŠ€å·§                          â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  - ç±»å‹å¥—è·¯                          â”‚    â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Vector Database (Milvus/Qdrant)           â”‚   â”‚
â”‚  â”‚  - Indexing (HNSW, IVF)                      â”‚   â”‚
â”‚  â”‚  - Similarity Search                         â”‚   â”‚
â”‚  â”‚  - Filtering                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚      Retrieval Engine (æ£€ç´¢å¼•æ“)            â”‚   â”‚
â”‚  â”‚  - Semantic Search (å‘é‡ç›¸ä¼¼åº¦)             â”‚   â”‚
â”‚  â”‚  - Keyword Search (BM25)                     â”‚   â”‚
â”‚  â”‚  - Hybrid Search (æ··åˆæ£€ç´¢)                 â”‚   â”‚
â”‚  â”‚  - Rerank (é‡æ’åº)                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚      RAG Workflow Engine                     â”‚   â”‚
â”‚  â”‚  1. Query Understanding (æŸ¥è¯¢ç†è§£)          â”‚   â”‚
â”‚  â”‚  2. Multi-source Retrieval (å¤šæºæ£€ç´¢)       â”‚   â”‚
â”‚  â”‚  3. Context Building (ä¸Šä¸‹æ–‡æ„å»º)           â”‚   â”‚
â”‚  â”‚  4. Prompt Enhancement (æç¤ºè¯å¢å¼º)         â”‚   â”‚
â”‚  â”‚  5. Generation (ç”Ÿæˆ)                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## äºŒã€å‘é‡åŒ–å¼•æ“

### 2.1 æ–‡æœ¬é¢„å¤„ç†

```python
class TextPreprocessor:
    """æ–‡æœ¬é¢„å¤„ç†"""
    
    def preprocess(self, text: str) -> str:
        """é¢„å¤„ç†æ–‡æœ¬"""
        # 1. æ¸…ç†HTMLæ ‡ç­¾
        text = self.remove_html_tags(text)
        
        # 2. æ ‡å‡†åŒ–ç©ºç™½å­—ç¬¦
        text = self.normalize_whitespace(text)
        
        # 3. ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼ˆä¿ç•™ä¸­è‹±æ–‡å’Œæ ‡ç‚¹ï¼‰
        text = self.remove_special_chars(text)
        
        return text
```

### 2.2 æ™ºèƒ½åˆ†å—ç­–ç•¥

```python
class ChunkSplitter:
    """æ™ºèƒ½åˆ†å—"""
    
    def split(self, text: str, chunk_size: int = 500, overlap: int = 50) -> List[str]:
        """åˆ†å—ç­–ç•¥"""
        # 1. æŒ‰æ®µè½åˆ†å‰²
        paragraphs = text.split('\n\n')
        
        chunks = []
        current_chunk = ""
        
        for para in paragraphs:
            if len(current_chunk) + len(para) < chunk_size:
                current_chunk += para + "\n\n"
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = para + "\n\n"
        
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        # 2. æ·»åŠ é‡å 
        return self.add_overlap(chunks, overlap)
```

### 2.3 å‘é‡ç¼–ç 

```python
from sentence_transformers import SentenceTransformer

class EmbeddingEngine:
    """å‘é‡ç¼–ç å¼•æ“"""
    
    def __init__(self, model_name: str = "BAAI/bge-large-zh-v1.5"):
        self.model = SentenceTransformer(model_name)
    
    def encode(self, texts: List[str]) -> np.ndarray:
        """æ‰¹é‡ç¼–ç """
        return self.model.encode(texts, batch_size=32, show_progress_bar=True)
```

---

## ä¸‰ã€çŸ¥è¯†åº“ç®¡ç†

### 3.1 çŸ¥è¯†åº“æ•°æ®æ¨¡å‹

```python
from pydantic import BaseModel
from typing import List, Dict

class Document(BaseModel):
    """æ–‡æ¡£æ¨¡å‹"""
    id: str
    user_id: str
    project_id: str
    content: str
    content_type: str  # 'chapter', 'character', 'setting', 'outline'
    metadata: Dict[str, Any]
    created_at: datetime
    
class VectorDocument(BaseModel):
    """å‘é‡æ–‡æ¡£æ¨¡å‹"""
    id: str
    document_id: str
    chunk_index: int
    chunk_text: str
    embedding: List[float]
    metadata: Dict[str, Any]
```

### 3.2 ç´¢å¼•ç®¡ç†

```python
class KnowledgeBaseManager:
    """çŸ¥è¯†åº“ç®¡ç†å™¨"""
    
    def __init__(self, vector_db, embedding_engine):
        self.vector_db = vector_db
        self.embedding_engine = embedding_engine
    
    async def index_document(self, document: Document):
        """ç´¢å¼•æ–‡æ¡£"""
        # 1. åˆ†å—
        chunks = self.chunk_splitter.split(document.content)
        
        # 2. å‘é‡åŒ–
        embeddings = self.embedding_engine.encode(chunks)
        
        # 3. å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
        for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):
            vector_doc = VectorDocument(
                id=f"{document.id}_{i}",
                document_id=document.id,
                chunk_index=i,
                chunk_text=chunk,
                embedding=embedding.tolist(),
                metadata={
                    'user_id': document.user_id,
                    'project_id': document.project_id,
                    'content_type': document.content_type
                }
            )
            await self.vector_db.insert(vector_doc)
    
    async def delete_document(self, document_id: str):
        """åˆ é™¤æ–‡æ¡£ç´¢å¼•"""
        await self.vector_db.delete_by_filter({'document_id': document_id})
```

---

## å››ã€æ£€ç´¢å¼•æ“

### 4.1 æ··åˆæ£€ç´¢

```python
class HybridSearchEngine:
    """æ··åˆæ£€ç´¢å¼•æ“"""
    
    async def search(
        self,
        query: str,
        user_id: str,
        project_id: str,
        top_k: int = 10
    ) -> List[SearchResult]:
        """æ··åˆæ£€ç´¢"""
        # 1. è¯­ä¹‰æ£€ç´¢
        semantic_results = await self.semantic_search(query, user_id, project_id, top_k)
        
        # 2. å…³é”®è¯æ£€ç´¢ï¼ˆBM25ï¼‰
        keyword_results = await self.keyword_search(query, user_id, project_id, top_k)
        
        # 3. èåˆç»“æœï¼ˆRRF - Reciprocal Rank Fusionï¼‰
        fused_results = self.fuse_results(semantic_results, keyword_results)
        
        # 4. é‡æ’åº
        reranked_results = await self.rerank(query, fused_results, top_k)
        
        return reranked_results
    
    async def semantic_search(self, query: str, user_id: str, project_id: str, top_k: int):
        """è¯­ä¹‰æ£€ç´¢"""
        # å‘é‡åŒ–æŸ¥è¯¢
        query_embedding = self.embedding_engine.encode([query])[0]
        
        # å‘é‡æ•°æ®åº“æœç´¢
        results = await self.vector_db.search(
            vector=query_embedding,
            filter={'user_id': user_id, 'project_id': project_id},
            top_k=top_k
        )
        
        return results
```

---

## äº”ã€RAGå·¥ä½œæµå¼•æ“

### 5.1 æŸ¥è¯¢å¤„ç†

```python
class RAGWorkflowEngine:
    """RAGå·¥ä½œæµå¼•æ“"""
    
    async def query(
        self,
        query: str,
        user_id: str,
        project_id: str,
        include_citations: bool = True
    ) -> RAGResponse:
        """RAGæŸ¥è¯¢"""
        # 1. æŸ¥è¯¢ç†è§£
        understood_query = await self.understand_query(query)
        
        # 2. å¤šæºæ£€ç´¢
        retrieved_docs = await self.retrieve(understood_query, user_id, project_id)
        
        # 3. æ„å»ºä¸Šä¸‹æ–‡
        context = self.build_context(retrieved_docs)
        
        # 4. å¢å¼ºPrompt
        enhanced_prompt = self.enhance_prompt(query, context)
        
        # 5. ç”Ÿæˆ
        answer = await self.llm_client.generate(enhanced_prompt)
        
        # 6. æ„å»ºå“åº”
        return RAGResponse(
            answer=answer,
            sources=retrieved_docs if include_citations else [],
            confidence=self.calculate_confidence(retrieved_docs)
        )
    
    def build_context(self, docs: List[SearchResult]) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡"""
        context_parts = []
        
        for doc in docs:
            citation = f"[æ¥æº: {doc.metadata['content_type']}]"
            context_parts.append(f"{citation}\n{doc.chunk_text}\n")
        
        return "\n".join(context_parts)
    
    def enhance_prompt(self, query: str, context: str) -> str:
        """å¢å¼ºPrompt"""
        template = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å†™ä½œåŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹å‚è€ƒèµ„æ–™å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

å‚è€ƒèµ„æ–™ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{query}

è¯·åŸºäºå‚è€ƒèµ„æ–™æä¾›å‡†ç¡®ã€æœ‰å¸®åŠ©çš„å›ç­”ã€‚å¦‚æœå‚è€ƒèµ„æ–™ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚
"""
        return template
```

---

## å…­ã€åº”ç”¨åœºæ™¯

### 6.1 æ™ºèƒ½å†™ä½œç»­å†™

```python
async def intelligent_continue_writing(
    project_id: str,
    chapter_id: str,
    previous_content: str,
    user_id: str
):
    """æ™ºèƒ½ç»­å†™"""
    # 1. æ£€ç´¢ç›¸å…³è§’è‰²ä¿¡æ¯
    characters = await rag_engine.search(
        query=f"æ£€ç´¢{project_id}çš„è§’è‰²ä¿¡æ¯",
        user_id=user_id,
        project_id=project_id,
        content_types=['character']
    )
    
    # 2. æ£€ç´¢ç›¸å…³è®¾å®š
    settings = await rag_engine.search(
        query="æ£€ç´¢ä¸–ç•Œè§‚è®¾å®š",
        user_id=user_id,
        project_id=project_id,
        content_types=['setting', 'worldview']
    )
    
    # 3. æ„å»ºç»­å†™ä¸Šä¸‹æ–‡
    context = build_writing_context(characters, settings, previous_content)
    
    # 4. ç”Ÿæˆç»­å†™
    continuation = await agent.execute({
        'task': 'continue_writing',
        'context': context
    })
    
    return continuation
```

---

## ä¸ƒã€å®æ–½å»ºè®®

### 7.1 æŠ€æœ¯é€‰å‹

| ç»„ä»¶ | æ¨èæ–¹æ¡ˆ | ç†ç”± |
|------|---------|------|
| **å‘é‡æ¨¡å‹** | BGE-large-zh-v1.5 | ä¸­æ–‡æ•ˆæœå¥½ |
| **å‘é‡æ•°æ®åº“** | Milvus | é«˜æ€§èƒ½ã€æ”¯æŒæ··åˆæ£€ç´¢ |
| **é‡æ’åºæ¨¡å‹** | bge-reranker-large | æå‡æ£€ç´¢ç²¾åº¦ |

### 7.2 æ€§èƒ½ä¼˜åŒ–

1. **æ‰¹é‡å‘é‡åŒ–**ï¼šæå‡10å€æ•ˆç‡
2. **ç´¢å¼•ä¼˜åŒ–**ï¼šä½¿ç”¨HNSWç´¢å¼•
3. **ç¼“å­˜ç­–ç•¥**ï¼šç¼“å­˜å¸¸ç”¨æŸ¥è¯¢
4. **å¼‚æ­¥å¤„ç†**ï¼šå¼‚æ­¥å‘é‡åŒ–å’Œç´¢å¼•

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¶é—´**: 2025-10-21

