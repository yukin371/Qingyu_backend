# RAG检索增强系统设计

> **文档版本**: v1.0  
> **创建时间**: 2025-10-21

## 📋 文档概述

本文档设计青羽平台的RAG（Retrieval Augmented Generation）检索增强系统，用于智能写作续写、设定问答、阅读助手等场景。

---

## 一、系统架构

```
┌──────────────────────────────────────────────────────┐
│               RAG System Architecture                 │
│                                                        │
│  ┌──────────────────────────────────────────────┐   │
│  │      Vectorization Engine (向量化引擎)       │   │
│  │  - Text Preprocessing                        │   │
│  │  - Chunk Splitting (智能分块)               │   │
│  │  - Embedding (BGE/M3E/OpenAI)                │   │
│  │  - Batch Processing                          │   │
│  └──────────────────┬───────────────────────────┘   │
│                     │                                 │
│  ┌──────────────────▼───────────────────────────┐   │
│  │      Knowledge Base Management               │   │
│  │  ┌─────────────────────────────────────┐    │   │
│  │  │ User Private KB (用户私有知识库)   │    │   │
│  │  │  - 项目文档                          │    │   │
│  │  │  - 角色卡                            │    │   │
│  │  │  - 大纲                              │    │   │
│  │  │  - 设定百科                          │    │   │
│  │  │  - 对话历史                          │    │   │
│  │  └─────────────────────────────────────┘    │   │
│  │  ┌─────────────────────────────────────┐    │   │
│  │  │ Platform KB (平台知识库)           │    │   │
│  │  │  - 优秀作品                          │    │   │
│  │  │  - 写作技巧                          │    │   │
│  │  │  - 类型套路                          │    │   │
│  │  └─────────────────────────────────────┘    │   │
│  └──────────────────┬───────────────────────────┘   │
│                     │                                 │
│  ┌──────────────────▼───────────────────────────┐   │
│  │   Vector Database (Milvus/Qdrant)           │   │
│  │  - Indexing (HNSW, IVF)                      │   │
│  │  - Similarity Search                         │   │
│  │  - Filtering                                 │   │
│  └──────────────────┬───────────────────────────┘   │
│                     │                                 │
│  ┌──────────────────▼───────────────────────────┐   │
│  │      Retrieval Engine (检索引擎)            │   │
│  │  - Semantic Search (向量相似度)             │   │
│  │  - Keyword Search (BM25)                     │   │
│  │  - Hybrid Search (混合检索)                 │   │
│  │  - Rerank (重排序)                           │   │
│  └──────────────────┬───────────────────────────┘   │
│                     │                                 │
│  ┌──────────────────▼───────────────────────────┐   │
│  │      RAG Workflow Engine                     │   │
│  │  1. Query Understanding (查询理解)          │   │
│  │  2. Multi-source Retrieval (多源检索)       │   │
│  │  3. Context Building (上下文构建)           │   │
│  │  4. Prompt Enhancement (提示词增强)         │   │
│  │  5. Generation (生成)                        │   │
│  └──────────────────────────────────────────────┘   │
└──────────────────────────────────────────────────────┘
```

---

## 二、向量化引擎

### 2.1 文本预处理

```python
class TextPreprocessor:
    """文本预处理"""
    
    def preprocess(self, text: str) -> str:
        """预处理文本"""
        # 1. 清理HTML标签
        text = self.remove_html_tags(text)
        
        # 2. 标准化空白字符
        text = self.normalize_whitespace(text)
        
        # 3. 移除特殊字符（保留中英文和标点）
        text = self.remove_special_chars(text)
        
        return text
```

### 2.2 智能分块策略

```python
class ChunkSplitter:
    """智能分块"""
    
    def split(self, text: str, chunk_size: int = 500, overlap: int = 50) -> List[str]:
        """分块策略"""
        # 1. 按段落分割
        paragraphs = text.split('\n\n')
        
        chunks = []
        current_chunk = ""
        
        for para in paragraphs:
            if len(current_chunk) + len(para) < chunk_size:
                current_chunk += para + "\n\n"
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = para + "\n\n"
        
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        # 2. 添加重叠
        return self.add_overlap(chunks, overlap)
```

### 2.3 向量编码

```python
from sentence_transformers import SentenceTransformer

class EmbeddingEngine:
    """向量编码引擎"""
    
    def __init__(self, model_name: str = "BAAI/bge-large-zh-v1.5"):
        self.model = SentenceTransformer(model_name)
    
    def encode(self, texts: List[str]) -> np.ndarray:
        """批量编码"""
        return self.model.encode(texts, batch_size=32, show_progress_bar=True)
```

---

## 三、知识库管理

### 3.1 知识库数据模型

```python
from pydantic import BaseModel
from typing import List, Dict

class Document(BaseModel):
    """文档模型"""
    id: str
    user_id: str
    project_id: str
    content: str
    content_type: str  # 'chapter', 'character', 'setting', 'outline'
    metadata: Dict[str, Any]
    created_at: datetime
    
class VectorDocument(BaseModel):
    """向量文档模型"""
    id: str
    document_id: str
    chunk_index: int
    chunk_text: str
    embedding: List[float]
    metadata: Dict[str, Any]
```

### 3.2 索引管理

```python
class KnowledgeBaseManager:
    """知识库管理器"""
    
    def __init__(self, vector_db, embedding_engine):
        self.vector_db = vector_db
        self.embedding_engine = embedding_engine
    
    async def index_document(self, document: Document):
        """索引文档"""
        # 1. 分块
        chunks = self.chunk_splitter.split(document.content)
        
        # 2. 向量化
        embeddings = self.embedding_engine.encode(chunks)
        
        # 3. 存储到向量数据库
        for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):
            vector_doc = VectorDocument(
                id=f"{document.id}_{i}",
                document_id=document.id,
                chunk_index=i,
                chunk_text=chunk,
                embedding=embedding.tolist(),
                metadata={
                    'user_id': document.user_id,
                    'project_id': document.project_id,
                    'content_type': document.content_type
                }
            )
            await self.vector_db.insert(vector_doc)
    
    async def delete_document(self, document_id: str):
        """删除文档索引"""
        await self.vector_db.delete_by_filter({'document_id': document_id})
```

---

## 四、检索引擎

### 4.1 混合检索

```python
class HybridSearchEngine:
    """混合检索引擎"""
    
    async def search(
        self,
        query: str,
        user_id: str,
        project_id: str,
        top_k: int = 10
    ) -> List[SearchResult]:
        """混合检索"""
        # 1. 语义检索
        semantic_results = await self.semantic_search(query, user_id, project_id, top_k)
        
        # 2. 关键词检索（BM25）
        keyword_results = await self.keyword_search(query, user_id, project_id, top_k)
        
        # 3. 融合结果（RRF - Reciprocal Rank Fusion）
        fused_results = self.fuse_results(semantic_results, keyword_results)
        
        # 4. 重排序
        reranked_results = await self.rerank(query, fused_results, top_k)
        
        return reranked_results
    
    async def semantic_search(self, query: str, user_id: str, project_id: str, top_k: int):
        """语义检索"""
        # 向量化查询
        query_embedding = self.embedding_engine.encode([query])[0]
        
        # 向量数据库搜索
        results = await self.vector_db.search(
            vector=query_embedding,
            filter={'user_id': user_id, 'project_id': project_id},
            top_k=top_k
        )
        
        return results
```

---

## 五、RAG工作流引擎

### 5.1 查询处理

```python
class RAGWorkflowEngine:
    """RAG工作流引擎"""
    
    async def query(
        self,
        query: str,
        user_id: str,
        project_id: str,
        include_citations: bool = True
    ) -> RAGResponse:
        """RAG查询"""
        # 1. 查询理解
        understood_query = await self.understand_query(query)
        
        # 2. 多源检索
        retrieved_docs = await self.retrieve(understood_query, user_id, project_id)
        
        # 3. 构建上下文
        context = self.build_context(retrieved_docs)
        
        # 4. 增强Prompt
        enhanced_prompt = self.enhance_prompt(query, context)
        
        # 5. 生成
        answer = await self.llm_client.generate(enhanced_prompt)
        
        # 6. 构建响应
        return RAGResponse(
            answer=answer,
            sources=retrieved_docs if include_citations else [],
            confidence=self.calculate_confidence(retrieved_docs)
        )
    
    def build_context(self, docs: List[SearchResult]) -> str:
        """构建上下文"""
        context_parts = []
        
        for doc in docs:
            citation = f"[来源: {doc.metadata['content_type']}]"
            context_parts.append(f"{citation}\n{doc.chunk_text}\n")
        
        return "\n".join(context_parts)
    
    def enhance_prompt(self, query: str, context: str) -> str:
        """增强Prompt"""
        template = f"""
你是一位专业的写作助手。请根据以下参考资料回答用户的问题。

参考资料：
{context}

用户问题：{query}

请基于参考资料提供准确、有帮助的回答。如果参考资料中没有相关信息，请明确说明。
"""
        return template
```

---

## 六、应用场景

### 6.1 智能写作续写

```python
async def intelligent_continue_writing(
    project_id: str,
    chapter_id: str,
    previous_content: str,
    user_id: str
):
    """智能续写"""
    # 1. 检索相关角色信息
    characters = await rag_engine.search(
        query=f"检索{project_id}的角色信息",
        user_id=user_id,
        project_id=project_id,
        content_types=['character']
    )
    
    # 2. 检索相关设定
    settings = await rag_engine.search(
        query="检索世界观设定",
        user_id=user_id,
        project_id=project_id,
        content_types=['setting', 'worldview']
    )
    
    # 3. 构建续写上下文
    context = build_writing_context(characters, settings, previous_content)
    
    # 4. 生成续写
    continuation = await agent.execute({
        'task': 'continue_writing',
        'context': context
    })
    
    return continuation
```

---

## 七、实施建议

### 7.1 技术选型

| 组件 | 推荐方案 | 理由 |
|------|---------|------|
| **向量模型** | BGE-large-zh-v1.5 | 中文效果好 |
| **向量数据库** | Milvus | 高性能、支持混合检索 |
| **重排序模型** | bge-reranker-large | 提升检索精度 |

### 7.2 性能优化

1. **批量向量化**：提升10倍效率
2. **索引优化**：使用HNSW索引
3. **缓存策略**：缓存常用查询
4. **异步处理**：异步向量化和索引

---

**文档版本**: v1.0  
**创建时间**: 2025-10-21

