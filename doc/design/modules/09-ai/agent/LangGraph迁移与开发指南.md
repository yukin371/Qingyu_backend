# LangGraphè¿ç§»ä¸å¼€å‘æŒ‡å—

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
> **åˆ›å»ºæ—¶é—´**: 2025-10-21  
> **é€‚ç”¨å¯¹è±¡**: é’ç¾½å¹³å°AIå¼€å‘å›¢é˜Ÿ

## ğŸ“‹ æ–‡æ¡£æ¦‚è¿°

æœ¬æ–‡æ¡£ä¸ºé’ç¾½å¹³å°AIæ¨¡å—ä»LangChainè¿ç§»åˆ°LangGraphæä¾›å®Œæ•´æŒ‡å—ï¼ŒåŒ…æ‹¬ï¼š
- ä¸ºä»€ä¹ˆé€‰æ‹©LangGraph
- æ ¸å¿ƒæ¦‚å¿µå¯¹æ¯”
- è¿ç§»æ­¥éª¤
- æœ€ä½³å®è·µ
- å¸¸è§é—®é¢˜

**é˜…è¯»å‰æ**ï¼š
- å·²é˜…è¯» [Agentæ¡†æ¶æŠ€æœ¯é€‰å‹å¯¹æ¯”](./Agentæ¡†æ¶æŠ€æœ¯é€‰å‹å¯¹æ¯”_LangChain_vs_Others.md)
- äº†è§£åŸºç¡€çš„LangChainæ¦‚å¿µï¼ˆå¯é€‰ï¼‰
- ç†Ÿæ‚‰Pythonå¼‚æ­¥ç¼–ç¨‹

---

## ğŸ¯ ä¸ºä»€ä¹ˆè¿ç§»åˆ°LangGraph

### æ ¸å¿ƒç†ç”±

| ç»´åº¦ | LangChain | LangGraph | é’ç¾½é¡¹ç›®éœ€æ±‚ |
|------|-----------|-----------|------------|
| **å·¥ä½œæµç±»å‹** | é“¾å¼ï¼ˆSequentialï¼‰ | å›¾çŠ¶ï¼ˆGraph-basedï¼‰ | âœ… éœ€è¦å›¾çŠ¶ï¼ˆå®¡æ ¸å¾ªç¯ã€æ¡ä»¶åˆ†æ”¯ï¼‰ |
| **æµç¨‹æ§åˆ¶** | if-elseæ‰‹åŠ¨æ§åˆ¶ | å£°æ˜å¼è¾¹å’Œæ¡ä»¶è·¯ç”± | âœ… éœ€è¦å¤æ‚æµç¨‹ç¼–æ’ |
| **çŠ¶æ€ç®¡ç†** | éšå¼ï¼ˆMemoryï¼‰ | æ˜¾å¼ï¼ˆTypedDict Stateï¼‰ | âœ… éœ€è¦å¯è°ƒè¯•ã€å¯æŒä¹…åŒ– |
| **å·¥å…·è°ƒç”¨** | æ‰‹åŠ¨è°ƒç”¨ | ToolNodeè‡ªåŠ¨è§£æ | âœ… ç®€åŒ–å·¥å…·è°ƒç”¨ |
| **ç”Ÿæ€å…¼å®¹** | - | 100%ç»§æ‰¿LangChain | âœ… ä¿ç•™LangChainå·¥å…·å’ŒRAG |

### å®é™…åœºæ™¯å¯¹æ¯”

**åœºæ™¯**ï¼šåˆ›ä½œAgentéœ€è¦æ‰§è¡Œ"ç†è§£ä»»åŠ¡ â†’ RAGæ£€ç´¢ â†’ ç”Ÿæˆå†…å®¹ â†’ å®¡æ ¸ â†’ ä¸é€šè¿‡åˆ™é‡æ–°ç”Ÿæˆ"

#### LangChainå®ç°ï¼ˆæ‰‹åŠ¨æ§åˆ¶ï¼‰

```python
# âŒ å¤æ‚ä¸”éš¾ä»¥ç»´æŠ¤
from langchain.chains import LLMChain

class CreativeAgent:
    def run(self, task):
        # 1. ç†è§£ä»»åŠ¡
        understanding = self.understand_chain.run(task)
        
        # 2. RAGæ£€ç´¢
        rag_results = self.rag_retriever.search(understanding)
        
        # 3. ç”Ÿæˆå†…å®¹
        retry_count = 0
        while retry_count < 3:
            content = self.generation_chain.run(rag_results)
            
            # 4. å®¡æ ¸
            review = self.review_chain.run(content)
            
            if review['passed']:
                return content  # âœ… å®¡æ ¸é€šè¿‡
            else:
                retry_count += 1  # âŒ é‡æ–°ç”Ÿæˆ
        
        return content  # è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°
```

**é—®é¢˜**ï¼š
- âŒ æ‰‹åŠ¨whileå¾ªç¯ï¼Œéš¾ä»¥å¯è§†åŒ–
- âŒ çŠ¶æ€éšå¼ï¼Œè°ƒè¯•å›°éš¾
- âŒ æ— æ³•æŒä¹…åŒ–ä¸­é—´çŠ¶æ€
- âŒ ä»£ç ç»“æ„æ··ä¹±

#### LangGraphå®ç°ï¼ˆå£°æ˜å¼ï¼‰

```python
# âœ… æ¸…æ™°ã€å¯ç»´æŠ¤ã€å¯è§†åŒ–
from langgraph.graph import StateGraph, END
from typing import TypedDict

class AgentState(TypedDict):
    task: str
    understanding: str
    rag_results: list
    content: str
    review: dict
    retry_count: int

# å®šä¹‰èŠ‚ç‚¹
def understand_node(state): ...
def rag_node(state): ...
def generate_node(state): ...
def review_node(state): ...

# å®šä¹‰æ¡ä»¶è·¯ç”±
def should_regenerate(state):
    if state['review']['passed']:
        return 'end'
    elif state['retry_count'] < 3:
        return 'regenerate'
    else:
        return 'end'

# æ„å»ºå›¾
workflow = StateGraph(AgentState)
workflow.add_node("understand", understand_node)
workflow.add_node("rag", rag_node)
workflow.add_node("generate", generate_node)
workflow.add_node("review", review_node)

workflow.set_entry_point("understand")
workflow.add_edge("understand", "rag")
workflow.add_edge("rag", "generate")
workflow.add_edge("generate", "review")
workflow.add_conditional_edges(
    "review",
    should_regenerate,
    {
        "regenerate": "generate",  # å¾ªç¯
        "end": END
    }
)

app = workflow.compile()
```

**ä¼˜åŠ¿**ï¼š
- âœ… å·¥ä½œæµä¸€ç›®äº†ç„¶ï¼ˆå¯è§†åŒ–ï¼‰
- âœ… æ˜¾å¼çŠ¶æ€ï¼Œæ˜“äºè°ƒè¯•
- âœ… æ”¯æŒæŒä¹…åŒ–ï¼ˆCheckpointerï¼‰
- âœ… ä»£ç ç»“æ„æ¸…æ™°

---

## ğŸ“– æ ¸å¿ƒæ¦‚å¿µå¯¹æ¯”

### 1. çŠ¶æ€ç®¡ç†

#### LangChainï¼šéšå¼Memory

```python
# LangChainæ–¹å¼
from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory()
chain = LLMChain(llm=llm, memory=memory)

# âŒ é—®é¢˜ï¼š
# - çŠ¶æ€åˆ†æ•£åœ¨Memoryå¯¹è±¡ä¸­
# - ä¸æ”¯æŒç±»å‹æ£€æŸ¥
# - æŒä¹…åŒ–å›°éš¾
```

#### LangGraphï¼šæ˜¾å¼State

```python
# LangGraphæ–¹å¼
from typing import TypedDict, Annotated
import operator

class AgentState(TypedDict):
    messages: Annotated[list, operator.add]  # è‡ªåŠ¨åˆå¹¶
    user_id: str
    context: dict
    retry_count: int

# âœ… ä¼˜åŠ¿ï¼š
# - ç±»å‹å®‰å…¨ï¼ˆTypedDictï¼‰
# - çŠ¶æ€é›†ä¸­ç®¡ç†
# - æ”¯æŒReducerï¼ˆå¦‚operator.addï¼‰
# - æ˜“äºæŒä¹…åŒ–
```

### 2. å·¥ä½œæµå®šä¹‰

#### LangChainï¼šé“¾å¼ç»„åˆ

```python
# LangChainæ–¹å¼
from langchain.chains import SequentialChain

chain = SequentialChain(chains=[
    chain1,  # ç†è§£ä»»åŠ¡
    chain2,  # RAGæ£€ç´¢
    chain3,  # ç”Ÿæˆå†…å®¹
])

# âŒ é—®é¢˜ï¼š
# - åªèƒ½é¡ºåºæ‰§è¡Œï¼Œæ— æ¡ä»¶åˆ†æ”¯
# - å¾ªç¯éœ€è¦æ‰‹åŠ¨while
# - ä¸æ”¯æŒå¹¶è¡Œ
```

#### LangGraphï¼šå›¾çŠ¶å·¥ä½œæµ

```python
# LangGraphæ–¹å¼
workflow = StateGraph(AgentState)
workflow.add_node("understand", node1)
workflow.add_node("rag", node2)
workflow.add_node("generate", node3)
workflow.add_node("review", node4)

workflow.add_edge("understand", "rag")
workflow.add_conditional_edges(
    "review",
    condition_func,
    {
        "pass": END,
        "retry": "generate"  # å¾ªç¯
    }
)

# âœ… ä¼˜åŠ¿ï¼š
# - æ”¯æŒæ¡ä»¶åˆ†æ”¯
# - å£°æ˜å¼å¾ªç¯
# - æ”¯æŒå¹¶è¡ŒèŠ‚ç‚¹
# - å¯è§†åŒ–å·¥ä½œæµ
```

### 3. å·¥å…·è°ƒç”¨

#### LangChainï¼šæ‰‹åŠ¨è°ƒç”¨

```python
# LangChainæ–¹å¼
from langchain.tools import Tool

tool = Tool(
    name="character_create",
    func=create_character,
    description="åˆ›å»ºè§’è‰²å¡"
)

# æ‰‹åŠ¨è°ƒç”¨
result = tool.run({"name": "æ—é£", "personality": "..."})

# âŒ é—®é¢˜ï¼š
# - éœ€è¦æ‰‹åŠ¨è§£æLLMçš„å·¥å…·è°ƒç”¨è¯·æ±‚
# - é”™è¯¯å¤„ç†å¤æ‚
```

#### LangGraphï¼šToolNodeè‡ªåŠ¨å¤„ç†

```python
# LangGraphæ–¹å¼
from langgraph.prebuilt import ToolNode

tools = [character_create_tool, rag_retrieval_tool]
tool_node = ToolNode(tools)

# æ·»åŠ åˆ°å›¾ä¸­
workflow.add_node("tools", tool_node)

# âœ… ä¼˜åŠ¿ï¼š
# - è‡ªåŠ¨è§£æLLMçš„function_call
# - è‡ªåŠ¨æ‰§è¡Œå·¥å…·
# - è‡ªåŠ¨é”™è¯¯å¤„ç†
# - æ”¯æŒå¹¶è¡Œå·¥å…·è°ƒç”¨
```

### 4. æŒä¹…åŒ–

#### LangChainï¼šéœ€è¦è‡ªå·±å®ç°

```python
# LangChainæ–¹å¼
# âŒ éœ€è¦æ‰‹åŠ¨ä¿å­˜Memoryå’Œä¸­é—´ç»“æœ
import json

state = {
    "memory": memory.to_dict(),
    "context": context
}
with open("state.json", "w") as f:
    json.dump(state, f)
```

#### LangGraphï¼šå†…ç½®Checkpointer

```python
# LangGraphæ–¹å¼
from langgraph.checkpoint.postgres import PostgresSaver

checkpointer = PostgresSaver.from_conn_string(
    "postgresql://user:pass@localhost/db"
)

app = workflow.compile(checkpointer=checkpointer)

# âœ… ä¼˜åŠ¿ï¼š
# - è‡ªåŠ¨ä¿å­˜æ¯ä¸ªèŠ‚ç‚¹çš„çŠ¶æ€
# - æ”¯æŒæ–­ç‚¹æ¢å¤
# - æ”¯æŒäººå·¥ä»‹å…¥ï¼ˆhuman-in-the-loopï¼‰
# - å¤šçº¿ç¨‹/å¤šä¼šè¯ç®¡ç†
```

---

## ğŸš€ è¿ç§»æ­¥éª¤

### é˜¶æ®µ1ï¼šç¯å¢ƒå‡†å¤‡ï¼ˆ1å¤©ï¼‰

#### 1.1 å®‰è£…ä¾èµ–

```bash
# å®‰è£…LangGraphï¼ˆä¼šè‡ªåŠ¨å®‰è£…LangChainï¼‰
pip install langgraph langchain-openai langchain-community

# å¯é€‰ï¼šæŒä¹…åŒ–æ”¯æŒ
pip install langgraph-checkpoint-postgres

# å¯é€‰ï¼šå¯è§†åŒ–æ”¯æŒ
pip install langgraph-studio
```

#### 1.2 é¡¹ç›®ç»“æ„è°ƒæ•´

```
python_ai_service/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_agent.py          # BaseAgentæŠ½è±¡ç±»
â”‚   â”œâ”€â”€ creative_agent.py      # LangGraphå®ç°
â”‚   â”œâ”€â”€ analysis_agent.py
â”‚   â””â”€â”€ nodes/                  # èŠ‚ç‚¹å®šä¹‰
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ understand.py
â”‚       â”œâ”€â”€ rag.py
â”‚       â”œâ”€â”€ generate.py
â”‚       â””â”€â”€ review.py
â”œâ”€â”€ tools/                      # LangChainå·¥å…·
â”‚   â”œâ”€â”€ character_tool.py
â”‚   â”œâ”€â”€ outline_tool.py
â”‚   â””â”€â”€ rag_tool.py
â”œâ”€â”€ graphs/                     # å·¥ä½œæµå®šä¹‰
â”‚   â””â”€â”€ creative_workflow.py
â””â”€â”€ checkpointers/              # æŒä¹…åŒ–
    â””â”€â”€ postgres_saver.py
```

### é˜¶æ®µ2ï¼šå®šä¹‰çŠ¶æ€ï¼ˆ1å¤©ï¼‰

#### 2.1 è®¾è®¡State Schema

```python
# agents/states.py
from typing import TypedDict, Annotated, Sequence
from langchain_core.messages import BaseMessage
import operator

class CreativeAgentState(TypedDict):
    """åˆ›ä½œAgentçŠ¶æ€"""
    # è¾“å…¥
    task_description: str
    user_id: str
    project_id: str
    
    # æ¶ˆæ¯å†å²ï¼ˆè‡ªåŠ¨ç´¯ç§¯ï¼‰
    messages: Annotated[Sequence[BaseMessage], operator.add]
    
    # å·¥ä½œæµçŠ¶æ€
    understanding: dict
    plan: list[dict]
    current_step: int
    
    # RAGç»“æœ
    rag_results: list[str]
    
    # ç”Ÿæˆå†…å®¹
    generated_content: str
    
    # å®¡æ ¸ç»“æœ
    review_result: dict
    review_passed: bool
    retry_count: int
    
    # å·¥å…·è°ƒç”¨è®°å½•
    tool_calls: list[dict]
    
    # æœ€ç»ˆè¾“å‡º
    final_output: str
    reasoning: list[str]
```

#### 2.2 å®šä¹‰Reducerï¼ˆå¯é€‰ï¼‰

```python
# è‡ªå®šä¹‰Reducerç¤ºä¾‹
def merge_reasoning(current: list[str], new: list[str]) -> list[str]:
    """åˆå¹¶æ¨ç†è¿‡ç¨‹ï¼Œé™åˆ¶æœ€å¤§é•¿åº¦"""
    merged = current + new
    return merged[-50:]  # åªä¿ç•™æœ€è¿‘50æ¡

class CreativeAgentState(TypedDict):
    reasoning: Annotated[list[str], merge_reasoning]
```

### é˜¶æ®µ3ï¼šè¿ç§»èŠ‚ç‚¹é€»è¾‘ï¼ˆ2-3å¤©ï¼‰

#### 3.1 å°†LangChainé“¾è½¬æ¢ä¸ºèŠ‚ç‚¹å‡½æ•°

**è¿ç§»å‰ï¼ˆLangChainï¼‰**ï¼š

```python
# æ—§ä»£ç 
from langchain.chains import LLMChain

understand_chain = LLMChain(
    llm=llm,
    prompt=understand_prompt
)

result = understand_chain.run(task)
```

**è¿ç§»åï¼ˆLangGraphï¼‰**ï¼š

```python
# agents/nodes/understand.py
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

def understand_node(state: CreativeAgentState) -> CreativeAgentState:
    """ç†è§£ä»»åŠ¡èŠ‚ç‚¹"""
    llm = ChatOpenAI(model="gpt-4", temperature=0)
    
    prompt = f"""
    åˆ†æä»¥ä¸‹åˆ›ä½œä»»åŠ¡ï¼š
    {state['task_description']}
    
    è¯·æå–ï¼š
    1. ä»»åŠ¡ç±»å‹
    2. å…³é”®è¦ç´ 
    3. æ‰€éœ€å·¥å…·
    """
    
    response = llm.invoke([HumanMessage(content=prompt)])
    
    # æ›´æ–°çŠ¶æ€
    return {
        **state,
        'messages': [HumanMessage(content=prompt), response],
        'understanding': {
            'task_type': '...',
            'key_elements': [...],
            'required_tools': [...]
        },
        'reasoning': state['reasoning'] + [f"ä»»åŠ¡ç†è§£å®Œæˆ"]
    }
```

#### 3.2 è¿ç§»å·¥å…·è°ƒç”¨

**è¿ç§»å‰ï¼ˆLangChainæ‰‹åŠ¨è°ƒç”¨ï¼‰**ï¼š

```python
# æ—§ä»£ç 
from langchain.tools import Tool

character_tool = Tool(
    name="character_create",
    func=create_character,
    description="åˆ›å»ºè§’è‰²å¡"
)

# æ‰‹åŠ¨è°ƒç”¨
result = character_tool.run(params)
```

**è¿ç§»åï¼ˆLangGraph ToolNodeï¼‰**ï¼š

```python
# tools/character_tool.py
from langchain.tools import BaseTool

class CharacterCreateTool(BaseTool):
    name = "character_create"
    description = "åˆ›å»ºå°è¯´è§’è‰²å¡"
    
    def _run(self, name: str, personality: str, **kwargs) -> str:
        # è°ƒç”¨Go API
        import requests
        response = requests.post(
            f"{GO_API_BASE}/api/v1/projects/{kwargs['project_id']}/characters",
            json={"name": name, "personality": personality},
            headers={"Authorization": f"Bearer {kwargs['token']}"}
        )
        return response.json()
    
    async def _arun(self, *args, **kwargs):
        return self._run(*args, **kwargs)

# graphs/creative_workflow.py
from langgraph.prebuilt import ToolNode

tools = [CharacterCreateTool(), OutlineTool(), RAGTool()]
tool_node = ToolNode(tools)

# æ·»åŠ åˆ°å·¥ä½œæµ
workflow.add_node("tools", tool_node)
```

### é˜¶æ®µ4ï¼šæ„å»ºå·¥ä½œæµï¼ˆ2å¤©ï¼‰

#### 4.1 å®šä¹‰èŠ‚ç‚¹

```python
# graphs/creative_workflow.py
from langgraph.graph import StateGraph, END
from agents.states import CreativeAgentState
from agents.nodes import (
    understand_node,
    plan_node,
    execute_node,
    review_node,
    regenerate_node,
    finalize_node
)

workflow = StateGraph(CreativeAgentState)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("understand", understand_node)
workflow.add_node("plan", plan_node)
workflow.add_node("execute", execute_node)
workflow.add_node("tools", tool_node)
workflow.add_node("review", review_node)
workflow.add_node("regenerate", regenerate_node)
workflow.add_node("finalize", finalize_node)
```

#### 4.2 å®šä¹‰è¾¹å’Œæ¡ä»¶è·¯ç”±

```python
# å®šä¹‰æ¡ä»¶å‡½æ•°
def should_continue(state: CreativeAgentState) -> str:
    """å†³å®šæ˜¯å¦ç»§ç»­æ‰§è¡Œæ­¥éª¤"""
    if state['current_step'] < len(state['plan']) - 1:
        return "continue"
    else:
        return "review"

def should_regenerate(state: CreativeAgentState) -> str:
    """å†³å®šæ˜¯å¦é‡æ–°ç”Ÿæˆ"""
    if state['review_passed']:
        return "finalize"
    elif state['retry_count'] < 3:
        return "regenerate"
    else:
        return "finalize"  # å¼ºåˆ¶ç»“æŸ

# å®šä¹‰è¾¹
workflow.set_entry_point("understand")
workflow.add_edge("understand", "plan")
workflow.add_edge("plan", "execute")
workflow.add_edge("execute", "tools")

# æ¡ä»¶è¾¹
workflow.add_conditional_edges(
    "tools",
    should_continue,
    {
        "continue": "execute",
        "review": "review"
    }
)

workflow.add_conditional_edges(
    "review",
    should_regenerate,
    {
        "regenerate": "regenerate",
        "finalize": "finalize"
    }
)

workflow.add_edge("regenerate", "review")  # å¾ªç¯
workflow.add_edge("finalize", END)
```

#### 4.3 ç¼–è¯‘å’ŒæŒä¹…åŒ–

```python
# æ·»åŠ æŒä¹…åŒ–ï¼ˆå¯é€‰ï¼‰
from langgraph.checkpoint.postgres import PostgresSaver

checkpointer = PostgresSaver.from_conn_string(
    "postgresql://user:pass@localhost/qingyu_db"
)

# ç¼–è¯‘
app = workflow.compile(checkpointer=checkpointer)

# å¯¼å‡ºå¯è§†åŒ–
app.get_graph().draw_mermaid_png(output_file_path="workflow.png")
```

### é˜¶æ®µ5ï¼šé›†æˆFastAPIï¼ˆ1å¤©ï¼‰

#### 5.1 åˆ›å»ºAPIç«¯ç‚¹

```python
# main.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

app = FastAPI()

class CreativeRequest(BaseModel):
    task_description: str
    user_id: str
    project_id: str
    token: str

@app.post("/api/ai/creative/generate")
async def generate_creative_content(request: CreativeRequest):
    """åˆ›ä½œå†…å®¹ç”Ÿæˆï¼ˆæµå¼ï¼‰"""
    
    # åˆå§‹åŒ–çŠ¶æ€
    initial_state = {
        "task_description": request.task_description,
        "user_id": request.user_id,
        "project_id": request.project_id,
        "messages": [],
        "plan": [],
        "current_step": 0,
        "generated_content": "",
        "tool_calls": [],
        "review_result": {},
        "review_passed": False,
        "retry_count": 0,
        "final_output": "",
        "reasoning": []
    }
    
    # æ‰§è¡Œå·¥ä½œæµï¼ˆæµå¼ï¼‰
    async for event in app.astream_events(
        initial_state,
        config={"configurable": {"thread_id": f"{request.user_id}_{request.project_id}"}}
    ):
        if event['event'] == 'on_chat_model_stream':
            # æµå¼è¾“å‡ºLLMç”Ÿæˆçš„å†…å®¹
            chunk = event['data']['chunk']
            yield f"data: {chunk}\n\n"
        
        elif event['event'] == 'on_tool_start':
            # å·¥å…·è°ƒç”¨å¼€å§‹
            yield f"data: {{\"type\": \"tool_start\", \"tool\": \"{event['name']}\"}}\n\n"
        
        elif event['event'] == 'on_tool_end':
            # å·¥å…·è°ƒç”¨ç»“æŸ
            yield f"data: {{\"type\": \"tool_end\", \"result\": {event['data']}}}\n\n"
    
    # æœ€ç»ˆç»“æœ
    final_result = await app.ainvoke(initial_state, config=...)
    yield f"data: {{\"type\": \"final\", \"output\": \"{final_result['final_output']}\"}}\n\n"
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. èŠ‚ç‚¹è®¾è®¡åŸåˆ™

#### âœ… å•ä¸€èŒè´£

```python
# âœ… æ¨èï¼šæ¯ä¸ªèŠ‚ç‚¹åªåšä¸€ä»¶äº‹
def understand_node(state):
    """åªè´Ÿè´£ç†è§£ä»»åŠ¡"""
    ...

def rag_node(state):
    """åªè´Ÿè´£RAGæ£€ç´¢"""
    ...

# âŒ ä¸æ¨èï¼šä¸€ä¸ªèŠ‚ç‚¹åšå¤šä»¶äº‹
def understand_and_rag_node(state):
    """åˆç†è§£åˆæ£€ç´¢ï¼ŒèŒè´£ä¸æ¸…"""
    ...
```

#### âœ… çŠ¶æ€ä¸å¯å˜æ€§

```python
# âœ… æ¨èï¼šè¿”å›æ–°çŠ¶æ€ï¼Œä¸ä¿®æ”¹åŸçŠ¶æ€
def my_node(state: AgentState) -> AgentState:
    return {
        **state,
        'new_field': 'value'
    }

# âŒ ä¸æ¨èï¼šç›´æ¥ä¿®æ”¹çŠ¶æ€
def my_node(state: AgentState) -> AgentState:
    state['new_field'] = 'value'  # âŒ
    return state
```

### 2. æ¡ä»¶è·¯ç”±æœ€ä½³å®è·µ

```python
# âœ… æ¨èï¼šæ¸…æ™°çš„æ¡ä»¶é€»è¾‘
def route_after_review(state: AgentState) -> str:
    """å®¡æ ¸åçš„è·¯ç”±å†³ç­–"""
    if state['review_passed']:
        return 'success'
    
    if state['retry_count'] >= 3:
        return 'max_retry_reached'
    
    if state['review_result']['severity'] == 'critical':
        return 'escalate_to_human'
    
    return 'retry'

# ä½¿ç”¨æ—¶
workflow.add_conditional_edges(
    "review",
    route_after_review,
    {
        "success": "finalize",
        "retry": "regenerate",
        "max_retry_reached": "finalize",
        "escalate_to_human": "human_review"
    }
)
```

### 3. é”™è¯¯å¤„ç†

```python
# agents/nodes/generate.py
from langchain_core.messages import HumanMessage

def generate_node(state: AgentState) -> AgentState:
    """ç”Ÿæˆå†…å®¹èŠ‚ç‚¹"""
    try:
        llm = ChatOpenAI(model="gpt-4")
        response = llm.invoke([HumanMessage(content=state['prompt'])])
        
        return {
            **state,
            'generated_content': response.content,
            'error': None
        }
    
    except Exception as e:
        # è®°å½•é”™è¯¯ï¼Œç»§ç»­å·¥ä½œæµï¼ˆé™çº§å¤„ç†ï¼‰
        return {
            **state,
            'generated_content': '',
            'error': str(e),
            'reasoning': state['reasoning'] + [f"ç”Ÿæˆå¤±è´¥ï¼š{e}"]
        }
```

### 4. æŒä¹…åŒ–å’Œæ¢å¤

```python
# ä¿å­˜ä¼šè¯çŠ¶æ€
result = await app.ainvoke(
    initial_state,
    config={
        "configurable": {
            "thread_id": "user123_session001"  # å”¯ä¸€ä¼šè¯ID
        }
    }
)

# æ¢å¤ä¼šè¯ï¼ˆä»æ–­ç‚¹ç»§ç»­ï¼‰
continued_result = await app.ainvoke(
    None,  # ä¸éœ€è¦åˆå§‹çŠ¶æ€ï¼Œä¼šä»checkpointeråŠ è½½
    config={
        "configurable": {
            "thread_id": "user123_session001"
        }
    }
)
```

### 5. äººå·¥ä»‹å…¥ï¼ˆHuman-in-the-Loopï¼‰

```python
from langgraph.graph import interrupt

def review_node(state: AgentState) -> AgentState:
    """å®¡æ ¸èŠ‚ç‚¹"""
    review_result = auto_review(state['generated_content'])
    
    if review_result['needs_human']:
        # ä¸­æ–­å·¥ä½œæµï¼Œç­‰å¾…äººå·¥å®¡æ ¸
        return interrupt({
            "message": "éœ€è¦äººå·¥å®¡æ ¸",
            "content": state['generated_content'],
            "review": review_result
        })
    
    return {
        **state,
        'review_passed': review_result['passed']
    }

# äººå·¥å®¡æ ¸åæ¢å¤
resumed_result = await app.ainvoke(
    {"human_decision": "approved"},  # äººå·¥å†³ç­–
    config={"configurable": {"thread_id": "session001"}}
)
```

---

## ğŸ” è°ƒè¯•å’Œå¯è§†åŒ–

### 1. å¯è§†åŒ–å·¥ä½œæµ

```python
# ç”ŸæˆMermaidå›¾
from IPython.display import Image, display

mermaid_png = app.get_graph().draw_mermaid_png()
display(Image(mermaid_png))

# æˆ–ä¿å­˜åˆ°æ–‡ä»¶
with open("workflow.png", "wb") as f:
    f.write(mermaid_png)
```

### 2. è°ƒè¯•æ‰§è¡Œè¿‡ç¨‹

```python
# æ‰“å°æ¯ä¸ªèŠ‚ç‚¹çš„æ‰§è¡Œ
async for event in app.astream_events(initial_state):
    print(f"Event: {event['event']}")
    print(f"Name: {event['name']}")
    print(f"Data: {event['data']}")
    print("---")
```

### 3. æŸ¥çœ‹çŠ¶æ€å†å²

```python
# è·å–æ‰€æœ‰checkpoint
from langgraph.checkpoint.postgres import PostgresSaver

checkpointer = PostgresSaver.from_conn_string("...")
history = checkpointer.list(
    config={"configurable": {"thread_id": "session001"}}
)

for checkpoint in history:
    print(f"Step: {checkpoint.step}")
    print(f"State: {checkpoint.state}")
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: LangGraphæ˜¯å¦å®Œå…¨å…¼å®¹LangChainå·¥å…·ï¼Ÿ

**A**: æ˜¯çš„ï¼LangGraph 100%å…¼å®¹LangChainå·¥å…·ã€‚

```python
# ä»»ä½•LangChainå·¥å…·éƒ½å¯ä»¥ç›´æ¥ä½¿ç”¨
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_community.retrievers import WikipediaRetriever
from langgraph.prebuilt import ToolNode

tools = [
    TavilySearchResults(),
    WikipediaRetriever(),
    # ... ä½ çš„è‡ªå®šä¹‰å·¥å…·
]

tool_node = ToolNode(tools)
```

### Q2: å¦‚ä½•ä»LangChainçš„Memoryè¿ç§»åˆ°LangGraphçš„Stateï¼Ÿ

**A**: ä½¿ç”¨Annotated + operator.add

```python
# LangChain Memory
from langchain.memory import ConversationBufferMemory
memory = ConversationBufferMemory()

# LangGraph Stateï¼ˆç­‰ä»·ï¼‰
from typing import Annotated, Sequence
import operator
from langchain_core.messages import BaseMessage

class State(TypedDict):
    messages: Annotated[Sequence[BaseMessage], operator.add]
```

### Q3: LangGraphæ€§èƒ½å¦‚ä½•ï¼Ÿ

**A**: 
- **å•æ¬¡è°ƒç”¨**ï¼šä¸LangChainåŸºæœ¬ä¸€è‡´
- **å¤æ‚å·¥ä½œæµ**ï¼šæ›´ä¼˜ï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰
- **æŒä¹…åŒ–å¼€é”€**ï¼šå¢åŠ çº¦10-20msï¼ˆå¯é€‰åŠŸèƒ½ï¼‰

å»ºè®®ï¼š
- å¼€å‘ç¯å¢ƒï¼šå¯ç”¨æŒä¹…åŒ–ï¼ˆä¾¿äºè°ƒè¯•ï¼‰
- ç”Ÿäº§ç¯å¢ƒï¼šæ ¹æ®éœ€æ±‚å†³å®š

### Q4: å¦‚ä½•å¤„ç†é•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡ï¼Ÿ

**A**: ä½¿ç”¨Checkpointer + å¼‚æ­¥ä»»åŠ¡

```python
# å¯åŠ¨é•¿ä»»åŠ¡
task_id = "task_12345"
asyncio.create_task(
    app.ainvoke(
        initial_state,
        config={"configurable": {"thread_id": task_id}}
    )
)

# å®šæœŸæŸ¥è¯¢çŠ¶æ€
checkpointer = PostgresSaver.from_conn_string("...")
current_state = checkpointer.get(
    config={"configurable": {"thread_id": task_id}}
)
```

### Q5: LangGraphæ˜¯å¦æ”¯æŒå¹¶è¡Œæ‰§è¡Œï¼Ÿ

**A**: æ˜¯çš„ï¼

```python
# å¹¶è¡ŒèŠ‚ç‚¹ï¼ˆä¼šè‡ªåŠ¨å¹¶è¡Œæ‰§è¡Œï¼‰
workflow.add_node("rag", rag_node)
workflow.add_node("outline", outline_node)

# ä»åŒä¸€ä¸ªèŠ‚ç‚¹æŒ‡å‘å¤šä¸ªèŠ‚ç‚¹ = å¹¶è¡Œ
workflow.add_edge("understand", "rag")
workflow.add_edge("understand", "outline")

# æ±‡èšç‚¹
workflow.add_edge("rag", "generate")
workflow.add_edge("outline", "generate")
```

---

## ğŸ“š å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£
- [LangGraphå®˜æ–¹æ–‡æ¡£](https://langchain-ai.github.io/langgraph/)
- [LangGraph GitHub](https://github.com/langchain-ai/langgraph)
- [LangChainå®˜æ–¹æ–‡æ¡£](https://python.langchain.com/docs/get_started/introduction)

### é’ç¾½é¡¹ç›®æ–‡æ¡£
- [Agentæ¡†æ¶æŠ€æœ¯é€‰å‹å¯¹æ¯”](./Agentæ¡†æ¶æŠ€æœ¯é€‰å‹å¯¹æ¯”_LangChain_vs_Others.md) - ä¸ºä»€ä¹ˆé€‰æ‹©LangGraph
- [Python AI Agentç³»ç»Ÿæ¶æ„è®¾è®¡](./07.Python_AI_Agentç³»ç»Ÿæ¶æ„è®¾è®¡.md) - å®Œæ•´å®ç°ç¤ºä¾‹
- [Agentå·¥å…·è°ƒç”¨é›†æˆè®¾è®¡](./09.Agentå·¥å…·è°ƒç”¨é›†æˆè®¾è®¡.md) - å·¥å…·è°ƒç”¨è¯¦ç»†è®¾è®¡

### ç¤ºä¾‹ä»£ç 
- [LangGraphç¤ºä¾‹åº“](https://github.com/langchain-ai/langgraph/tree/main/examples)
- [é’ç¾½Agentå®ç°ç¤ºä¾‹](./07.Python_AI_Agentç³»ç»Ÿæ¶æ„è®¾è®¡.md#é™„å½•langgraphå®ç°ç¤ºä¾‹-)

---

## ğŸ“ è¿ç§»æ£€æŸ¥æ¸…å•

### ç¯å¢ƒå‡†å¤‡
- [ ] å®‰è£…LangGraphå’Œç›¸å…³ä¾èµ–
- [ ] è®¾ç½®PostgreSQLï¼ˆå¦‚éœ€æŒä¹…åŒ–ï¼‰
- [ ] è°ƒæ•´é¡¹ç›®ç»“æ„

### ä»£ç è¿ç§»
- [ ] å®šä¹‰State Schema
- [ ] è¿ç§»LangChainé“¾ä¸ºèŠ‚ç‚¹å‡½æ•°
- [ ] è¿ç§»å·¥å…·ä¸ºLangChain BaseTool
- [ ] æ„å»ºStateGraphå·¥ä½œæµ
- [ ] å®šä¹‰æ¡ä»¶è·¯ç”±
- [ ] æ·»åŠ é”™è¯¯å¤„ç†

### é›†æˆæµ‹è¯•
- [ ] å•èŠ‚ç‚¹æµ‹è¯•
- [ ] å·¥ä½œæµç«¯åˆ°ç«¯æµ‹è¯•
- [ ] æŒä¹…åŒ–åŠŸèƒ½æµ‹è¯•
- [ ] æµå¼è¾“å‡ºæµ‹è¯•
- [ ] æ€§èƒ½æµ‹è¯•

### éƒ¨ç½²ä¸Šçº¿
- [ ] æ›´æ–°Dockeré•œåƒ
- [ ] é…ç½®æ•°æ®åº“è¿æ¥
- [ ] é…ç½®ç¯å¢ƒå˜é‡
- [ ] ç›‘æ§å’Œæ—¥å¿—
- [ ] æ–‡æ¡£æ›´æ–°

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¶é—´**: 2025-10-21  
**ç»´æŠ¤è€…**: é’ç¾½AIæ¶æ„ç»„  
**çŠ¶æ€**: âœ… å¯ç”¨

