# 限流中间件设计

> **文档版本**: v1.0  
> **创建日期**: 2025-10-21  
> **最后更新**: 2025-10-21  
> **状态**: ✅ 设计完成

---

## 1. 需求概述

### 1.1 功能描述

限流中间件为青羽后端提供请求频率控制功能，基于令牌桶算法实现，支持多维度限流（IP、用户、API路径），防止系统过载和恶意攻击，确保系统稳定性。

### 1.2 业务价值

- **系统稳定性**：防止流量激增导致系统崩溃
- **资源保护**：保护后端服务和数据库免受过载
- **公平性保障**：防止少数用户占用过多资源
- **攻击防护**：防御DDoS、爬虫、暴力破解等攻击
- **商业模式支持**：为不同VIP等级提供差异化限流策略

### 1.3 应用场景

- **API接口限流**：限制API调用频率
- **用户行为限流**：限制登录、注册等敏感操作
- **IP级别限流**：防止单一IP过度请求
- **AI服务限流**：保护昂贵的AI计算资源
- **VIP差异化限流**：为VIP用户提供更高请求额度

---

## 2. 架构设计

### 2.1 整体架构

```
┌──────────────────────────────────────────────┐
│           限流中间件系统                        │
├──────────────────────────────────────────────┤
│                                              │
│  ┌────────────────────────────────┐         │
│  │   请求到达                      │         │
│  └────────────────────────────────┘         │
│                 ↓                            │
│  ┌────────────────────────────────┐         │
│  │   识别限流Key                   │         │
│  │   - IP地址                      │         │
│  │   - 用户ID                      │         │
│  │   - API路径                     │         │
│  └────────────────────────────────┘         │
│                 ↓                            │
│  ┌────────────────────────────────┐         │
│  │   获取令牌桶限流器               │         │
│  │   - 本地限流器 (内存)            │         │
│  │   - 分布式限流器 (Redis)         │         │
│  └────────────────────────────────┘         │
│                 ↓                            │
│  ┌────────────────────────────────┐         │
│  │   令牌桶算法检查                 │         │
│  │   - 计算当前令牌数               │         │
│  │   - 尝试获取令牌                 │         │
│  └────────────────────────────────┘         │
│          ↙            ↘                      │
│  ┌──────────┐    ┌──────────┐              │
│  │ 有令牌    │    │ 无令牌    │              │
│  │ 放行请求  │    │ 拒绝请求  │              │
│  └──────────┘    └──────────┘              │
│        ↓                ↓                    │
│  ┌──────────┐    ┌──────────┐              │
│  │ 记录指标  │    │ 返回429   │              │
│  └──────────┘    └──────────┘              │
└──────────────────────────────────────────────┘
```

### 2.2 限流算法选择

#### 令牌桶算法 (Token Bucket) ✅ 已选择

**原理**：
- 以固定速率向桶中添加令牌
- 每个请求消耗一个令牌
- 桶满时令牌溢出
- 允许一定程度的突发流量（桶容量）

**优点**：
- ✅ 允许突发流量
- ✅ 平滑限流
- ✅ 实现简单
- ✅ 性能高

**实现**：使用Go标准库 `golang.org/x/time/rate`

```go
import "golang.org/x/time/rate"

// 创建限流器：每秒10个请求，桶容量20
limiter := rate.NewLimiter(rate.Limit(10), 20)

// 检查是否允许请求
if limiter.Allow() {
    // 放行
} else {
    // 拒绝
}
```

#### 其他算法对比

| 算法 | 突发流量 | 平滑度 | 实现复杂度 | 是否采用 |
|------|---------|--------|-----------|---------|
| 令牌桶 | ✅ 支持 | ✅ 平滑 | ⭐ 简单 | ✅ 已采用 |
| 漏桶 | ❌ 不支持 | ✅ 平滑 | ⭐ 简单 | ❌ 未采用 |
| 固定窗口 | ⚠️ 边界突发 | ❌ 不平滑 | ⭐ 简单 | ❌ 未采用 |
| 滑动窗口 | ✅ 支持 | ✅ 平滑 | ⭐⭐⭐ 复杂 | ❌ 未采用 |

---

## 3. 详细设计

### 3.1 核心数据结构

```go
// 限流配置
type RateLimitConfig struct {
    RequestsPerSecond int           `json:"requests_per_second" yaml:"requests_per_second"` // 每秒请求数
    RequestsPerMinute int           `json:"requests_per_minute" yaml:"requests_per_minute"` // 每分钟请求数
    RequestsPerHour   int           `json:"requests_per_hour" yaml:"requests_per_hour"`     // 每小时请求数
    BurstSize         int           `json:"burst_size" yaml:"burst_size"`                   // 突发容量
    KeyFunc           string        `json:"key_func" yaml:"key_func"`                       // 限流key策略
    SkipSuccessful    bool          `json:"skip_successful" yaml:"skip_successful"`         // 是否跳过成功请求
    SkipFailedRequest bool          `json:"skip_failed_request" yaml:"skip_failed_request"` // 是否跳过失败请求
    UseRedis          bool          `json:"use_redis" yaml:"use_redis"`                     // 是否使用Redis分布式限流
    RedisKeyPrefix    string        `json:"redis_key_prefix" yaml:"redis_key_prefix"`       // Redis key前缀
}

// 令牌桶限流器
type TokenBucketLimiter struct {
    limiter       *rate.Limiter
    requestsPerSec int
    burst         int
}

// 限流key策略
type KeyStrategy string

const (
    KeyByIP     KeyStrategy = "ip"      // 按IP限流
    KeyByUser   KeyStrategy = "user"    // 按用户ID限流
    KeyByPath   KeyStrategy = "path"    // 按API路径限流
    KeyByIPPath KeyStrategy = "ip_path" // 按IP+路径限流
    KeyByCustom KeyStrategy = "custom"  // 自定义key
)
```

### 3.2 令牌桶限流器实现

```go
// 实现文件：rate_limit.go

// 创建令牌桶限流器
func NewTokenBucketLimiter(rps int, burst int) *TokenBucketLimiter {
    return &TokenBucketLimiter{
        limiter:        rate.NewLimiter(rate.Limit(rps), burst),
        requestsPerSec: rps,
        burst:          burst,
    }
}

// 检查是否允许请求
func (tbl *TokenBucketLimiter) Allow() bool {
    return tbl.limiter.Allow()
}

// 等待直到可以获取令牌（阻塞式）
func (tbl *TokenBucketLimiter) Wait(ctx context.Context) error {
    return tbl.limiter.Wait(ctx)
}

// 尝试获取N个令牌
func (tbl *TokenBucketLimiter) AllowN(n int) bool {
    return tbl.limiter.AllowN(time.Now(), n)
}

// 获取当前令牌数
func (tbl *TokenBucketLimiter) Tokens() float64 {
    return tbl.limiter.Tokens()
}
```

### 3.3 限流中间件实现

```go
// 实现文件：rate_limit.go

// 默认配置
func DefaultRateLimitConfig() RateLimitConfig {
    return RateLimitConfig{
        RequestsPerSecond: 10,
        BurstSize:         20,
        KeyFunc:           string(KeyByIP),
        SkipSuccessful:    false,
        SkipFailedRequest: false,
        UseRedis:          false,
        RedisKeyPrefix:    "ratelimit:",
    }
}

// 简单限流中间件
func RateLimit() gin.HandlerFunc {
    return RateLimitWithConfig(DefaultRateLimitConfig())
}

// 带配置的限流中间件
func RateLimitWithConfig(config RateLimitConfig) gin.HandlerFunc {
    // 本地限流器存储（key -> limiter）
    var limiterStore sync.Map
    
    // 创建或获取限流器
    getLimiter := func(key string) *TokenBucketLimiter {
        if value, exists := limiterStore.Load(key); exists {
            return value.(*TokenBucketLimiter)
        }
        
        // 创建新限流器
        limiter := NewTokenBucketLimiter(
            config.RequestsPerSecond,
            config.BurstSize,
        )
        limiterStore.Store(key, limiter)
        return limiter
    }
    
    return func(c *gin.Context) {
        // 1. 生成限流key
        key := generateRateLimitKey(c, config.KeyFunc)
        
        // 2. 获取限流器
        limiter := getLimiter(key)
        
        // 3. 检查是否允许请求
        if !limiter.Allow() {
            // 记录限流事件
            logRateLimitExceeded(c, key, config.RequestsPerSecond)
            
            // 返回429错误
            c.JSON(http.StatusTooManyRequests, gin.H{
                "code":        42901,
                "message":     "请求过于频繁，请稍后再试",
                "limit":       config.RequestsPerSecond,
                "retry_after": 1, // 秒
            })
            c.Abort()
            return
        }
        
        // 4. 记录当前令牌数（用于监控）
        c.Set("rate_limit_tokens", limiter.Tokens())
        c.Set("rate_limit_key", key)
        
        c.Next()
    }
}

// 生成限流key
func generateRateLimitKey(c *gin.Context, keyFunc string) string {
    strategy := KeyStrategy(keyFunc)
    
    switch strategy {
    case KeyByIP:
        return fmt.Sprintf("ip:%s", c.ClientIP())
        
    case KeyByUser:
        userID := c.GetString("user_id")
        if userID == "" {
            return fmt.Sprintf("ip:%s", c.ClientIP()) // fallback to IP
        }
        return fmt.Sprintf("user:%s", userID)
        
    case KeyByPath:
        return fmt.Sprintf("path:%s", c.Request.URL.Path)
        
    case KeyByIPPath:
        return fmt.Sprintf("ip:%s:path:%s", c.ClientIP(), c.Request.URL.Path)
        
    default:
        return fmt.Sprintf("ip:%s", c.ClientIP())
    }
}
```

### 3.4 分布式限流（Redis）

```go
// Redis分布式限流实现
type RedisRateLimiter struct {
    client    *redis.Client
    keyPrefix string
    rps       int
    burst     int
}

func NewRedisRateLimiter(client *redis.Client, prefix string, rps int, burst int) *RedisRateLimiter {
    return &RedisRateLimiter{
        client:    client,
        keyPrefix: prefix,
        rps:       rps,
        burst:     burst,
    }
}

// 使用Redis的令牌桶算法
func (rrl *RedisRateLimiter) Allow(ctx context.Context, key string) (bool, error) {
    fullKey := rrl.keyPrefix + key
    now := time.Now().Unix()
    
    // Lua脚本实现原子性令牌桶算法
    script := `
        local key = KEYS[1]
        local capacity = tonumber(ARGV[1])
        local rate = tonumber(ARGV[2])
        local now = tonumber(ARGV[3])
        local requested = tonumber(ARGV[4])
        
        local bucket = redis.call('HMGET', key, 'tokens', 'last_update')
        local tokens = tonumber(bucket[1])
        local last_update = tonumber(bucket[2])
        
        if tokens == nil then
            tokens = capacity
            last_update = now
        end
        
        -- 计算新增令牌数
        local delta = math.max(0, now - last_update)
        tokens = math.min(capacity, tokens + delta * rate)
        
        -- 尝试获取令牌
        local allowed = 0
        if tokens >= requested then
            tokens = tokens - requested
            allowed = 1
        end
        
        -- 更新Redis
        redis.call('HMSET', key, 'tokens', tokens, 'last_update', now)
        redis.call('EXPIRE', key, 3600)  -- 1小时过期
        
        return allowed
    `
    
    result, err := rrl.client.Eval(
        ctx,
        script,
        []string{fullKey},
        rrl.burst,   // capacity
        rrl.rps,     // rate
        now,         // now
        1,           // requested
    ).Int()
    
    if err != nil {
        return false, err
    }
    
    return result == 1, nil
}

// 使用Redis限流的中间件
func RateLimitWithRedis(redisClient *redis.Client, config RateLimitConfig) gin.HandlerFunc {
    limiter := NewRedisRateLimiter(
        redisClient,
        config.RedisKeyPrefix,
        config.RequestsPerSecond,
        config.BurstSize,
    )
    
    return func(c *gin.Context) {
        key := generateRateLimitKey(c, config.KeyFunc)
        
        allowed, err := limiter.Allow(c.Request.Context(), key)
        if err != nil {
            // Redis错误，记录日志但放行请求（优雅降级）
            logger.Error("Redis限流失败", zap.Error(err))
            c.Next()
            return
        }
        
        if !allowed {
            c.JSON(http.StatusTooManyRequests, gin.H{
                "code":    42901,
                "message": "请求过于频繁",
            })
            c.Abort()
            return
        }
        
        c.Next()
    }
}
```

---

## 4. 高级特性

### 4.1 VIP差异化限流

```go
// VIP用户获得更高的请求限制
func VIPAwareRateLimit() gin.HandlerFunc {
    return func(c *gin.Context) {
        userID := c.GetString("user_id")
        vipLevel := c.GetInt("vip_level")
        
        // 根据VIP等级设置不同限流参数
        var rps int
        var burst int
        
        switch vipLevel {
        case 3: // VIP Pro
            rps = 1000
            burst = 2000
        case 2: // VIP Plus
            rps = 500
            burst = 1000
        case 1: // VIP Basic
            rps = 200
            burst = 400
        default: // 免费用户
            rps = 60
            burst = 100
        }
        
        // 创建专属限流器
        limiter := NewTokenBucketLimiter(rps, burst)
        
        if !limiter.Allow() {
            c.JSON(http.StatusTooManyRequests, gin.H{
                "code":    42902,
                "message": "请求频率超限",
                "limit":   rps,
                "vip_tip": "升级VIP可获得更高请求限额",
            })
            c.Abort()
            return
        }
        
        c.Next()
    }
}
```

### 4.2 动态限流调整

```go
// 根据系统负载动态调整限流参数
type DynamicRateLimiter struct {
    baseLimiter   *TokenBucketLimiter
    loadMonitor   *LoadMonitor
    adjustmentFunc func(load float64) (rps int, burst int)
}

func (drl *DynamicRateLimiter) Allow(c *gin.Context) bool {
    // 获取当前系统负载
    currentLoad := drl.loadMonitor.GetLoad()
    
    // 根据负载调整限流参数
    if currentLoad > 0.8 { // 负载超过80%
        // 降低限流阈值
        newRPS, newBurst := drl.adjustmentFunc(currentLoad)
        drl.baseLimiter = NewTokenBucketLimiter(newRPS, newBurst)
    }
    
    return drl.baseLimiter.Allow()
}
```

### 4.3 分级限流

```go
// 不同API路径使用不同限流策略
func PathBasedRateLimit() gin.HandlerFunc {
    // 配置各路径的限流参数
    pathConfigs := map[string]RateLimitConfig{
        "/api/v1/login": {
            RequestsPerSecond: 5,   // 登录限制更严格
            BurstSize:         10,
        },
        "/api/v1/ai/*": {
            RequestsPerSecond: 10,  // AI接口中等限制
            BurstSize:         20,
        },
        "/api/v1/projects": {
            RequestsPerSecond: 100, // 普通接口限制较宽松
            BurstSize:         200,
        },
    }
    
    return func(c *gin.Context) {
        path := c.Request.URL.Path
        
        // 查找匹配的配置
        config := DefaultRateLimitConfig()
        for pattern, cfg := range pathConfigs {
            if matchPath(path, pattern) {
                config = cfg
                break
            }
        }
        
        // 应用限流
        RateLimitWithConfig(config)(c)
    }
}
```

---

## 5. 配置管理

### 5.1 配置文件

```yaml
# config/rate_limit.yaml
rate_limit:
  # 全局配置
  global:
    enabled: true
    requests_per_second: 100
    burst_size: 200
    key_func: "ip"
    use_redis: false
    redis_key_prefix: "ratelimit:"
  
  # 路径级配置
  paths:
    /api/v1/login:
      requests_per_second: 5
      burst_size: 10
      key_func: "ip"
    
    /api/v1/register:
      requests_per_second: 3
      burst_size: 5
      key_func: "ip"
    
    /api/v1/ai/*:
      requests_per_second: 10
      burst_size: 20
      key_func: "user"
    
    /api/v1/projects:
      requests_per_second: 100
      burst_size: 200
      key_func: "user"
  
  # VIP限流配置
  vip:
    enabled: true
    levels:
      free:
        requests_per_second: 60
        burst_size: 100
      basic:
        requests_per_second: 200
        burst_size: 400
      plus:
        requests_per_second: 500
        burst_size: 1000
      pro:
        requests_per_second: 1000
        burst_size: 2000
  
  # Redis配置
  redis:
    enabled: false
    host: "localhost:6379"
    password: ""
    db: 0
    key_prefix: "ratelimit:"
    key_ttl: 3600
```

### 5.2 配置加载

```go
type RateLimitConfigs struct {
    Global RateLimitConfig            `yaml:"global"`
    Paths  map[string]RateLimitConfig `yaml:"paths"`
    VIP    VIPRateLimitConfig         `yaml:"vip"`
    Redis  RedisConfig                `yaml:"redis"`
}

func LoadRateLimitConfig(path string) (*RateLimitConfigs, error) {
    data, err := os.ReadFile(path)
    if err != nil {
        return nil, err
    }
    
    var config RateLimitConfigs
    if err := yaml.Unmarshal(data, &config); err != nil {
        return nil, err
    }
    
    return &config, nil
}
```

---

## 6. 监控与告警

### 6.1 Prometheus指标

```go
// 限流指标
var (
    rateLimitTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "rate_limit_total",
            Help: "Total number of rate limit checks",
        },
        []string{"key_type", "result"},
    )
    
    rateLimitBlockedTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "rate_limit_blocked_total",
            Help: "Total number of blocked requests",
        },
        []string{"key_type", "path"},
    )
    
    rateLimitTokens = prometheus.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "rate_limit_tokens",
            Help: "Current tokens in rate limiter",
        },
        []string{"key"},
    )
)

// 记录限流指标
func recordRateLimitMetrics(key string, allowed bool, tokens float64) {
    result := "allowed"
    if !allowed {
        result = "blocked"
    }
    
    rateLimitTotal.WithLabelValues(extractKeyType(key), result).Inc()
    
    if !allowed {
        rateLimitBlockedTotal.WithLabelValues(
            extractKeyType(key),
            extractPath(key),
        ).Inc()
    }
    
    rateLimitTokens.WithLabelValues(key).Set(tokens)
}
```

### 6.2 告警规则

```yaml
# prometheus/alerts/rate_limit.yml
groups:
  - name: rate_limit
    rules:
      - alert: HighRateLimitBlocked
        expr: rate(rate_limit_blocked_total[5m]) > 100
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "高频限流阻止"
          description: "5分钟内限流阻止超过100次，可能存在攻击"
      
      - alert: RateLimitRedisDown
        expr: rate_limit_redis_errors_total > 10
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Redis限流服务异常"
          description: "Redis限流服务连续错误，已降级到本地限流"
```

---

## 7. 性能优化

### 7.1 限流器复用

```go
// 使用sync.Map复用限流器，减少内存分配
type LimiterPool struct {
    limiters sync.Map
    config   RateLimitConfig
}

func (lp *LimiterPool) GetLimiter(key string) *TokenBucketLimiter {
    if value, exists := lp.limiters.Load(key); exists {
        return value.(*TokenBucketLimiter)
    }
    
    limiter := NewTokenBucketLimiter(
        lp.config.RequestsPerSecond,
        lp.config.BurstSize,
    )
    
    // 尝试存储，如果已存在则使用已存在的
    actual, loaded := lp.limiters.LoadOrStore(key, limiter)
    return actual.(*TokenBucketLimiter)
}
```

### 7.2 限流器清理

```go
// 定期清理不活跃的限流器，释放内存
func (lp *LimiterPool) StartCleanup(interval time.Duration) {
    ticker := time.NewTicker(interval)
    go func() {
        for range ticker.C {
            lp.cleanup()
        }
    }()
}

func (lp *LimiterPool) cleanup() {
    // 清理超过1小时未使用的限流器
    cutoff := time.Now().Add(-1 * time.Hour)
    
    lp.limiters.Range(func(key, value interface{}) bool {
        limiter := value.(*TokenBucketLimiter)
        
        // 检查最后访问时间
        if limiter.LastAccess().Before(cutoff) {
            lp.limiters.Delete(key)
        }
        
        return true
    })
}
```

---

## 8. 测试设计

### 8.1 单元测试

```go
func TestTokenBucketLimiter_Allow(t *testing.T) {
    limiter := NewTokenBucketLimiter(10, 20)
    
    // 前20个请求应该全部通过（桶容量）
    for i := 0; i < 20; i++ {
        assert.True(t, limiter.Allow(), "第%d个请求应该通过", i+1)
    }
    
    // 第21个请求应该被拒绝
    assert.False(t, limiter.Allow(), "第21个请求应该被拒绝")
    
    // 等待100ms（应该补充1个令牌）
    time.Sleep(100 * time.Millisecond)
    assert.True(t, limiter.Allow(), "等待后的请求应该通过")
}

func TestRateLimitMiddleware_Blocking(t *testing.T) {
    gin.SetMode(gin.TestMode)
    
    config := RateLimitConfig{
        RequestsPerSecond: 2,
        BurstSize:         2,
        KeyFunc:           "ip",
    }
    
    router := gin.New()
    router.Use(RateLimitWithConfig(config))
    router.GET("/test", func(c *gin.Context) {
        c.JSON(200, gin.H{"status": "ok"})
    })
    
    // 前2个请求应该通过
    for i := 0; i < 2; i++ {
        w := httptest.NewRecorder()
        req, _ := http.NewRequest("GET", "/test", nil)
        router.ServeHTTP(w, req)
        assert.Equal(t, 200, w.Code)
    }
    
    // 第3个请求应该被限流
    w := httptest.NewRecorder()
    req, _ := http.NewRequest("GET", "/test", nil)
    router.ServeHTTP(w, req)
    assert.Equal(t, 429, w.Code)
}
```

---

## 9. 使用示例

### 9.1 基本使用

```go
// router/enter.go
func InitRoutes(r *gin.Engine) {
    // 全局限流
    r.Use(middleware.RateLimit())
    
    // API分组
    api := r.Group("/api/v1")
    {
        // 登录接口严格限流
        api.POST("/login", 
            middleware.RateLimitWithConfig(middleware.RateLimitConfig{
                RequestsPerSecond: 5,
                BurstSize:         10,
                KeyFunc:           "ip",
            }),
            authApi.Login)
        
        // AI接口VIP差异化限流
        ai := api.Group("/ai")
        ai.Use(middleware.VIPAwareRateLimit())
        {
            ai.POST("/generate", aiApi.Generate)
            ai.POST("/chat", aiApi.Chat)
        }
    }
}
```

### 9.2 Redis分布式限流

```go
// 初始化Redis限流
redisClient := redis.NewClient(&redis.Options{
    Addr: "localhost:6379",
})

rateLimitConfig := middleware.RateLimitConfig{
    RequestsPerSecond: 100,
    BurstSize:         200,
    UseRedis:          true,
    RedisKeyPrefix:    "ratelimit:",
}

router.Use(middleware.RateLimitWithRedis(redisClient, rateLimitConfig))
```

---

## 10. 最佳实践

### 10.1 限流策略建议

1. **敏感操作严格限流**：登录、注册、密码重置等
2. **昂贵操作适度限流**：AI生成、导出等
3. **普通操作宽松限流**：查询、列表等
4. **VIP差异化限流**：提升付费用户体验

### 10.2 使用建议

- ✅ 使用Redis分布式限流（多实例部署）
- ✅ 为不同API路径设置不同限流参数
- ✅ 为VIP用户提供更高限额
- ✅ 监控限流指标，及时调整参数
- ✅ 提供友好的限流提示和重试建议
- ❌ 不要在限流中间件中执行耗时操作
- ❌ 不要设置过于严格的限流参数
- ❌ 不要忽略Redis故障的降级处理

---

## 11. 关联文件

### 实现文件

- `middleware/rate_limit.go` - 限流中间件实现 (~200行)

### 相关设计

- [中间件总体设计](./中间件总体设计.md) - 中间件架构
- [VIP权限中间件](./权限中间件设计.md#vip会员权限中间件) - VIP差异化限流
- [监控中间件](./中间件总体设计.md#监控系统) - 限流指标监控

---

**文档版本**: v1.0  
**创建时间**: 2025-10-21  
**作者**: 青羽架构组

