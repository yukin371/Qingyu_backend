# 写作端内容审核系统设计

> **版本**: v1.0  
> **创建日期**: 2025-10-17  
> **最后更新**: 2025-10-17  
> **维护者**: 青羽写作团队  
> **优先级**: 🔥 MVP高优先级

## 1. 需求概述

### 1.1 功能描述

内容审核系统是青羽写作平台的核心安全模块，旨在实时检测和识别用户创作内容中的敏感词汇、违规表达和不当内容，保障平台内容健康、合规，避免法律风险。系统支持实时检测、批量审核、人工复核等多种审核模式。

### 1.2 业务价值

- **合规保障**：确保平台内容符合国家法律法规，避免法律风险
- **内容质量**：提升平台内容质量，维护良好的社区氛围
- **风险预警**：及时发现和处理违规内容，降低平台运营风险
- **用户体验**：提供实时反馈，帮助作者及时修正内容问题

### 1.3 用户场景

**作者端场景**：
1. **实时写作检测**：作者在编辑器中写作时，系统实时检测敏感词并高亮提示
2. **发布前审核**：作者提交发布时，系统进行全文审核，给出审核结果和修改建议
3. **历史内容复查**：系统定期对已发布内容进行复查，识别新增敏感词
4. **申诉处理**：作者对审核结果有异议时，可提交申诉并等待人工复核

**管理员场景**：
1. **敏感词库管理**：管理员维护和更新敏感词库
2. **人工复核**：对系统标记的疑似违规内容进行人工审核
3. **审核规则配置**：配置不同类型内容的审核策略和严格程度
4. **审核报表统计**：查看审核数据统计和违规趋势分析

### 1.4 功能边界

**包含功能**：
- ✅ 敏感词实时检测（前端高亮提示）
- ✅ 全文内容审核（发布前审核）
- ✅ 敏感词库管理（增删改查、导入导出）
- ✅ 违规内容识别（政治、色情、暴力、广告等）
- ✅ 审核记录管理（审核历史、违规记录）
- ✅ 人工复核流程（申诉、复审、处理）
- ✅ 审核规则配置（审核策略、严格程度）
- ✅ 审核数据统计（违规率、审核量、处理时效）

**不包含功能**：
- ❌ 图片内容审核（后期版本，调用第三方API）
- ❌ 视频内容审核（后期版本）
- ❌ AI自动修正（后期版本，AI改写建议）
- ❌ 实时协作审核（后期版本）

---

## 2. 架构设计

### 2.1 整体架构

```
┌─────────────────────────────────────────────────────────────┐
│                    前端编辑器 (Vue)                            │
│              实时检测 + 高亮显示 + 违规提示                      │
├─────────────────────────────────────────────────────────────┤
│                 Router Layer (路由层)                         │
│              /api/v1/content-audit/*                         │
├─────────────────────────────────────────────────────────────┤
│                  API Layer (接口层)                           │
│        ContentAuditApi / SensitiveWordApi / AppealApi        │
├─────────────────────────────────────────────────────────────┤
│               Service Layer (业务逻辑层)                       │
│  ContentAuditService / SensitiveWordService / AppealService  │
├─────────────────────────────────────────────────────────────┤
│     Strategy Layer (审核策略层) - 算法和规则引擎                │
│   DFAMatcher / RegexMatcher / RuleEngine / AIDetector       │
├─────────────────────────────────────────────────────────────┤
│            Repository Layer (数据访问层)                       │
│  AuditRecordRepo / SensitiveWordRepo / AppealRepo           │
├─────────────────────────────────────────────────────────────┤
│              Model Layer (数据模型层)                          │
│  AuditRecord / SensitiveWord / Appeal / AuditResult         │
├─────────────────────────────────────────────────────────────┤
│              MongoDB + Redis (存储层)                         │
│        MongoDB: 审核记录、敏感词库、申诉记录                    │
│        Redis: 敏感词缓存、审核结果缓存                          │
└─────────────────────────────────────────────────────────────┘
```

### 2.2 模块划分

**核心模块**：
- **ContentAuditService**：内容审核核心服务，协调各检测器完成审核
- **SensitiveWordService**：敏感词库管理服务
- **AppealService**：申诉和人工复核服务
- **DFAMatcher**：DFA（确定有限状态自动机）敏感词匹配器
- **RegexMatcher**：正则表达式匹配器（复杂模式检测）
- **RuleEngine**：规则引擎（基于规则的违规检测）
- **AIDetector**：AI检测器（调用AI服务进行语义分析）

**辅助模块**：
- **AuditStatisticsService**：审核数据统计服务
- **AuditNotificationService**：审核结果通知服务
- **SensitiveWordCacheManager**：敏感词缓存管理

### 2.3 数据流设计

#### 实时检测流程
```
用户输入 → 前端防抖(500ms) → API请求 → Redis缓存查询 
→ DFA快速匹配 → 返回匹配结果 → 前端高亮显示
```

#### 发布审核流程
```
提交发布 → 全文审核请求 → 敏感词检测 → 正则表达式检测 
→ 规则引擎检测 → AI语义分析 → 汇总审核结果 
→ 记录审核日志 → 返回审核结果 → 发布/拒绝
```

#### 人工复核流程
```
用户申诉 → 创建申诉记录 → 通知审核员 → 人工审核 
→ 审核决策 → 更新审核记录 → 通知用户 → 完成
```

---

## 3. 详细设计

### 3.1 Router层设计

**路由分组**：`/api/v1/content-audit`

**路由定义**：
```go
// 内容审核路由
auditGroup := v1.Group("/content-audit")
auditGroup.Use(middleware.JWTAuth())
{
    // 实时检测（作者使用）
    auditGroup.POST("/check-realtime", contentAuditApi.CheckRealtime)
    
    // 全文审核（发布前审核）
    auditGroup.POST("/check-full", contentAuditApi.CheckFull)
    
    // 批量审核（定期复查）
    auditGroup.POST("/check-batch", contentAuditApi.CheckBatch)
    
    // 审核记录
    auditGroup.GET("/records", contentAuditApi.GetAuditRecords)
    auditGroup.GET("/records/:id", contentAuditApi.GetAuditRecord)
    
    // 申诉管理（作者使用）
    auditGroup.POST("/appeals", appealApi.CreateAppeal)
    auditGroup.GET("/appeals", appealApi.GetMyAppeals)
    auditGroup.GET("/appeals/:id", appealApi.GetAppeal)
}

// 敏感词库管理路由（管理员专用）
adminAuditGroup := admin.Group("/audit")
adminAuditGroup.Use(middleware.AdminPermission())
{
    // 敏感词CRUD
    adminAuditGroup.GET("/sensitive-words", sensitiveWordApi.List)
    adminAuditGroup.POST("/sensitive-words", sensitiveWordApi.Create)
    adminAuditGroup.PUT("/sensitive-words/:id", sensitiveWordApi.Update)
    adminAuditGroup.DELETE("/sensitive-words/:id", sensitiveWordApi.Delete)
    adminAuditGroup.POST("/sensitive-words/import", sensitiveWordApi.Import)
    adminAuditGroup.GET("/sensitive-words/export", sensitiveWordApi.Export)
    
    // 审核规则配置
    adminAuditGroup.GET("/rules", auditRuleApi.GetRules)
    adminAuditGroup.PUT("/rules", auditRuleApi.UpdateRules)
    
    // 人工复核
    adminAuditGroup.GET("/appeals/pending", appealApi.GetPendingAppeals)
    adminAuditGroup.PUT("/appeals/:id/review", appealApi.ReviewAppeal)
    
    // 审核统计
    adminAuditGroup.GET("/statistics", auditStatisticsApi.GetStatistics)
}
```

### 3.2 API层设计

#### 3.2.1 实时检测接口

**请求**：
```json
POST /api/v1/content-audit/check-realtime
{
  "content": "要检测的文本内容",
  "checkType": "sensitive_word" // sensitive_word, regex, full
}
```

**响应**：
```json
{
  "code": 200,
  "message": "检测完成",
  "data": {
    "isSafe": false,
    "matches": [
      {
        "word": "检测到的敏感词",
        "position": [10, 14], // 起始位置和结束位置
        "level": "high", // high, medium, low
        "category": "political", // political, porn, violence, advertising, etc.
        "suggestion": "建议修改为：***"
      }
    ],
    "checkTime": "2025-10-17T10:30:00Z"
  }
}
```

#### 3.2.2 全文审核接口

**请求**：
```json
POST /api/v1/content-audit/check-full
{
  "documentId": "文档ID",
  "content": "全文内容",
  "checkOptions": {
    "enableDFA": true,
    "enableRegex": true,
    "enableRuleEngine": true,
    "enableAI": false // AI检测可选，消耗较高
  }
}
```

**响应**：
```json
{
  "code": 200,
  "message": "审核完成",
  "data": {
    "auditId": "审核记录ID",
    "result": "pass", // pass, warning, reject
    "isSafe": true,
    "riskLevel": "low", // low, medium, high
    "issues": [
      {
        "type": "sensitive_word",
        "level": "medium",
        "category": "political",
        "content": "违规内容片段",
        "position": [100, 110],
        "suggestion": "修改建议"
      }
    ],
    "statistics": {
      "totalWords": 5000,
      "sensitiveWords": 2,
      "violationWords": 0,
      "checkDuration": "150ms"
    },
    "nextAction": "请修改标记的内容后重新提交" // 给用户的建议
  }
}
```

#### 3.2.3 创建申诉接口

**请求**：
```json
POST /api/v1/content-audit/appeals
{
  "auditId": "审核记录ID",
  "documentId": "文档ID",
  "reason": "申诉原因说明",
  "evidence": "证据材料（可选）",
  "contactInfo": "联系方式"
}
```

**响应**：
```json
{
  "code": 200,
  "message": "申诉已提交",
  "data": {
    "appealId": "申诉ID",
    "status": "pending", // pending, reviewing, approved, rejected
    "submittedAt": "2025-10-17T10:30:00Z",
    "estimatedReviewTime": "24小时内"
  }
}
```

### 3.3 Service层设计

#### ContentAuditService 核心方法

```go
type ContentAuditService struct {
    auditRecordRepo     repository.AuditRecordRepository
    sensitiveWordRepo   repository.SensitiveWordRepository
    dfaMatcher          *DFAMatcher
    regexMatcher        *RegexMatcher
    ruleEngine          *RuleEngine
    aiDetector          *AIDetector
    cacheManager        *SensitiveWordCacheManager
    eventBus            base.EventBus
}

// CheckRealtime 实时检测（快速模式，仅DFA）
func (s *ContentAuditService) CheckRealtime(ctx context.Context, req *CheckRealtimeRequest) (*CheckRealtimeResponse, error) {
    // 1. 参数验证
    if req.Content == "" || len(req.Content) > 10000 {
        return nil, errors.NewValidationError("内容为空或超长")
    }
    
    // 2. 从缓存获取敏感词库
    words, err := s.cacheManager.GetSensitiveWords(ctx)
    if err != nil {
        return nil, errors.NewInternalError("获取敏感词库失败").WithCause(err)
    }
    
    // 3. DFA快速匹配
    matches := s.dfaMatcher.Match(req.Content, words)
    
    // 4. 构建响应
    return &CheckRealtimeResponse{
        IsSafe:    len(matches) == 0,
        Matches:   matches,
        CheckTime: time.Now(),
    }, nil
}

// CheckFull 全文审核（完整模式，多种检测器）
func (s *ContentAuditService) CheckFull(ctx context.Context, req *CheckFullRequest) (*CheckFullResponse, error) {
    startTime := time.Now()
    
    // 1. 参数验证
    if err := s.validateCheckFullRequest(req); err != nil {
        return nil, err
    }
    
    // 2. 创建审核记录
    auditRecord := &models.AuditRecord{
        DocumentID: req.DocumentId,
        Content:    req.Content,
        Status:     "checking",
        CreatedAt:  time.Now(),
    }
    if err := s.auditRecordRepo.Create(ctx, auditRecord); err != nil {
        return nil, errors.NewInternalError("创建审核记录失败").WithCause(err)
    }
    
    // 3. 多种检测器并行检测
    var (
        dfaIssues   []AuditIssue
        regexIssues []AuditIssue
        ruleIssues  []AuditIssue
        aiIssues    []AuditIssue
        wg          sync.WaitGroup
        mu          sync.Mutex
    )
    
    // 3.1 DFA检测（必选）
    if req.CheckOptions.EnableDFA {
        wg.Add(1)
        go func() {
            defer wg.Done()
            issues := s.dfaMatcher.Detect(req.Content)
            mu.Lock()
            dfaIssues = issues
            mu.Unlock()
        }()
    }
    
    // 3.2 正则表达式检测（可选）
    if req.CheckOptions.EnableRegex {
        wg.Add(1)
        go func() {
            defer wg.Done()
            issues := s.regexMatcher.Detect(req.Content)
            mu.Lock()
            regexIssues = issues
            mu.Unlock()
        }()
    }
    
    // 3.3 规则引擎检测（可选）
    if req.CheckOptions.EnableRuleEngine {
        wg.Add(1)
        go func() {
            defer wg.Done()
            issues := s.ruleEngine.Detect(req.Content)
            mu.Lock()
            ruleIssues = issues
            mu.Unlock()
        }()
    }
    
    // 3.4 AI检测（可选，较慢）
    if req.CheckOptions.EnableAI {
        wg.Add(1)
        go func() {
            defer wg.Done()
            issues, _ := s.aiDetector.Detect(ctx, req.Content)
            mu.Lock()
            aiIssues = issues
            mu.Unlock()
        }()
    }
    
    wg.Wait()
    
    // 4. 合并检测结果
    allIssues := s.mergeIssues(dfaIssues, regexIssues, ruleIssues, aiIssues)
    
    // 5. 风险评级
    riskLevel, result := s.evaluateRisk(allIssues)
    
    // 6. 更新审核记录
    auditRecord.Status = "completed"
    auditRecord.Result = result
    auditRecord.RiskLevel = riskLevel
    auditRecord.Issues = allIssues
    auditRecord.CheckDuration = time.Since(startTime).Milliseconds()
    if err := s.auditRecordRepo.Update(ctx, auditRecord.ID, auditRecord); err != nil {
        log.Error("更新审核记录失败", "error", err)
    }
    
    // 7. 发布审核事件
    s.publishAuditEvent(ctx, auditRecord)
    
    // 8. 构建响应
    return &CheckFullResponse{
        AuditId:    auditRecord.ID,
        Result:     result,
        IsSafe:     len(allIssues) == 0,
        RiskLevel:  riskLevel,
        Issues:     allIssues,
        Statistics: s.buildStatistics(req.Content, allIssues, startTime),
        NextAction: s.getNextActionSuggestion(result),
    }, nil
}

// evaluateRisk 风险评级
func (s *ContentAuditService) evaluateRisk(issues []AuditIssue) (riskLevel string, result string) {
    if len(issues) == 0 {
        return "low", "pass"
    }
    
    highCount := 0
    mediumCount := 0
    
    for _, issue := range issues {
        switch issue.Level {
        case "high":
            highCount++
        case "medium":
            mediumCount++
        }
    }
    
    // 风险评级规则
    if highCount > 0 {
        return "high", "reject" // 有高风险问题，拒绝发布
    } else if mediumCount >= 3 {
        return "medium", "reject" // 中风险问题过多，拒绝发布
    } else if mediumCount > 0 {
        return "medium", "warning" // 有中风险问题，警告但允许发布
    }
    
    return "low", "pass"
}
```

### 3.4 Repository层设计

#### AuditRecordRepository 接口定义

```go
type AuditRecordRepository interface {
    // 基础CRUD
    Create(ctx context.Context, record *models.AuditRecord) error
    GetByID(ctx context.Context, id string) (*models.AuditRecord, error)
    Update(ctx context.Context, id string, record *models.AuditRecord) error
    Delete(ctx context.Context, id string) error
    
    // 业务查询
    GetByDocumentID(ctx context.Context, documentId string, limit int) ([]*models.AuditRecord, error)
    GetByUserID(ctx context.Context, userId string, filter infrastructure.Filter) ([]*models.AuditRecord, error)
    GetPendingAppeals(ctx context.Context, limit int) ([]*models.AuditRecord, error)
    
    // 统计查询
    CountByResult(ctx context.Context, startDate, endDate time.Time) (map[string]int64, error)
    CountByCategory(ctx context.Context, startDate, endDate time.Time) (map[string]int64, error)
    GetViolationRate(ctx context.Context, startDate, endDate time.Time) (float64, error)
}
```

#### SensitiveWordRepository 接口定义

```go
type SensitiveWordRepository interface {
    // 基础CRUD
    Create(ctx context.Context, word *models.SensitiveWord) error
    BatchCreate(ctx context.Context, words []*models.SensitiveWord) error
    GetByID(ctx context.Context, id string) (*models.SensitiveWord, error)
    Update(ctx context.Context, id string, word *models.SensitiveWord) error
    Delete(ctx context.Context, id string) error
    BatchDelete(ctx context.Context, ids []string) error
    
    // 业务查询
    GetAll(ctx context.Context) ([]*models.SensitiveWord, error)
    GetByCategory(ctx context.Context, category string) ([]*models.SensitiveWord, error)
    GetByLevel(ctx context.Context, level string) ([]*models.SensitiveWord, error)
    Search(ctx context.Context, keyword string, limit int) ([]*models.SensitiveWord, error)
    
    // 缓存管理
    RefreshCache(ctx context.Context) error
}
```

### 3.5 Model层设计

#### AuditRecord 审核记录模型

```go
type AuditRecord struct {
    ID            string       `bson:"_id,omitempty" json:"id"`
    DocumentID    string       `bson:"document_id" json:"documentId"`
    UserID        string       `bson:"user_id" json:"userId"`
    Content       string       `bson:"content" json:"-"` // 不返回到前端
    ContentHash   string       `bson:"content_hash" json:"contentHash"` // MD5哈希
    Status        string       `bson:"status" json:"status"` // checking, completed
    Result        string       `bson:"result" json:"result"` // pass, warning, reject
    RiskLevel     string       `bson:"risk_level" json:"riskLevel"` // low, medium, high
    Issues        []AuditIssue `bson:"issues" json:"issues"`
    CheckDuration int64        `bson:"check_duration" json:"checkDuration"` // 毫秒
    CheckOptions  CheckOptions `bson:"check_options" json:"checkOptions"`
    CreatedAt     time.Time    `bson:"created_at" json:"createdAt"`
    UpdatedAt     time.Time    `bson:"updated_at" json:"updatedAt"`
}

type AuditIssue struct {
    Type       string   `bson:"type" json:"type"` // sensitive_word, regex, rule, ai
    Level      string   `bson:"level" json:"level"` // high, medium, low
    Category   string   `bson:"category" json:"category"` // political, porn, violence, advertising
    Content    string   `bson:"content" json:"content"` // 违规内容
    Position   []int    `bson:"position" json:"position"` // [start, end]
    Suggestion string   `bson:"suggestion" json:"suggestion"` // 修改建议
}

type CheckOptions struct {
    EnableDFA        bool `bson:"enable_dfa" json:"enableDfa"`
    EnableRegex      bool `bson:"enable_regex" json:"enableRegex"`
    EnableRuleEngine bool `bson:"enable_rule_engine" json:"enableRuleEngine"`
    EnableAI         bool `bson:"enable_ai" json:"enableAi"`
}
```

#### SensitiveWord 敏感词模型

```go
type SensitiveWord struct {
    ID          string    `bson:"_id,omitempty" json:"id"`
    Word        string    `bson:"word" json:"word" validate:"required"`
    Level       string    `bson:"level" json:"level"` // high, medium, low
    Category    string    `bson:"category" json:"category"` // political, porn, violence, advertising
    Replacement string    `bson:"replacement" json:"replacement"` // 建议替换词
    IsRegex     bool      `bson:"is_regex" json:"isRegex"` // 是否为正则表达式
    IsEnabled   bool      `bson:"is_enabled" json:"isEnabled"` // 是否启用
    Source      string    `bson:"source" json:"source"` // 来源（官方、用户添加等）
    CreatedBy   string    `bson:"created_by" json:"createdBy"`
    CreatedAt   time.Time `bson:"created_at" json:"createdAt"`
    UpdatedAt   time.Time `bson:"updated_at" json:"updatedAt"`
}
```

#### Appeal 申诉记录模型

```go
type Appeal struct {
    ID            string    `bson:"_id,omitempty" json:"id"`
    AuditID       string    `bson:"audit_id" json:"auditId"`
    DocumentID    string    `bson:"document_id" json:"documentId"`
    UserID        string    `bson:"user_id" json:"userId"`
    Reason        string    `bson:"reason" json:"reason" validate:"required"`
    Evidence      string    `bson:"evidence" json:"evidence"`
    ContactInfo   string    `bson:"contact_info" json:"contactInfo"`
    Status        string    `bson:"status" json:"status"` // pending, reviewing, approved, rejected
    ReviewerID    string    `bson:"reviewer_id" json:"reviewerId"`
    ReviewResult  string    `bson:"review_result" json:"reviewResult"`
    ReviewComment string    `bson:"review_comment" json:"reviewComment"`
    ReviewedAt    time.Time `bson:"reviewed_at" json:"reviewedAt"`
    CreatedAt     time.Time `bson:"created_at" json:"createdAt"`
    UpdatedAt     time.Time `bson:"updated_at" json:"updatedAt"`
}
```

---

## 4. 算法设计

### 4.1 DFA（确定有限状态自动机）算法

**算法原理**：
DFA是一种高效的字符串匹配算法，将敏感词库构建成树形结构（前缀树/Trie树），实现O(n)时间复杂度的多模式匹配。

**实现步骤**：
1. **构建DFA树**：将所有敏感词插入到Trie树中
2. **匹配检测**：遍历文本，在Trie树中查找匹配路径
3. **记录结果**：记录匹配的敏感词位置和内容

**代码实现**：
```go
type DFANode struct {
    Children map[rune]*DFANode
    IsEnd    bool
    Word     string
    Level    string
    Category string
}

type DFAMatcher struct {
    root *DFANode
    mu   sync.RWMutex
}

// BuildTree 构建DFA树
func (m *DFAMatcher) BuildTree(words []*models.SensitiveWord) {
    m.mu.Lock()
    defer m.mu.Unlock()
    
    m.root = &DFANode{Children: make(map[rune]*DFANode)}
    
    for _, word := range words {
        if !word.IsEnabled || word.IsRegex {
            continue // 跳过未启用和正则表达式词
        }
        
        node := m.root
        runes := []rune(word.Word)
        
        for _, r := range runes {
            if _, ok := node.Children[r]; !ok {
                node.Children[r] = &DFANode{Children: make(map[rune]*DFANode)}
            }
            node = node.Children[r]
        }
        
        node.IsEnd = true
        node.Word = word.Word
        node.Level = word.Level
        node.Category = word.Category
    }
}

// Match 匹配敏感词
func (m *DFAMatcher) Match(content string, words []*models.SensitiveWord) []AuditIssue {
    m.mu.RLock()
    defer m.mu.RUnlock()
    
    // 如果树为空，先构建
    if m.root == nil {
        m.mu.RUnlock()
        m.BuildTree(words)
        m.mu.RLock()
    }
    
    var issues []AuditIssue
    runes := []rune(content)
    
    for i := 0; i < len(runes); i++ {
        node := m.root
        j := i
        
        for j < len(runes) {
            r := runes[j]
            if child, ok := node.Children[r]; ok {
                node = child
                j++
                
                if node.IsEnd {
                    // 找到敏感词
                    issues = append(issues, AuditIssue{
                        Type:     "sensitive_word",
                        Level:    node.Level,
                        Category: node.Category,
                        Content:  node.Word,
                        Position: []int{i, j},
                        Suggestion: "建议删除或替换",
                    })
                    break
                }
            } else {
                break
            }
        }
    }
    
    return issues
}
```

### 4.2 正则表达式匹配

用于检测复杂模式的违规内容，例如：
- 变体敏感词（如：广告 → 广-告、广*告）
- 联系方式（手机号、QQ号、微信号）
- 网址链接
- 特殊符号组合

**示例规则**：
```go
var regexPatterns = []struct {
    Pattern  string
    Category string
    Level    string
}{
    {`1[3-9]\d{9}`, "contact", "medium"}, // 手机号
    {`[qQ]{2}[:：]?\d{5,}`, "contact", "medium"}, // QQ号
    {`https?://[^\s]+`, "link", "low"}, // 网址
    {`[广告]{2}`, "advertising", "high"}, // 广告变体
}
```

### 4.3 规则引擎

基于业务规则的违规检测，例如：
- **频繁重复**：同一词语连续出现5次以上
- **特殊符号比例**：特殊符号占比超过20%
- **敏感话题组合**：多个敏感话题同时出现
- **语义异常**：上下文语义不连贯（需结合AI）

### 4.4 AI语义检测

调用AI服务进行深度语义分析，检测：
- **隐晦表达**：用暗语表达违规内容
- **上下文违规**：单独看合规，但组合起来违规
- **情感倾向**：负面情绪、暴力倾向
- **价值观导向**：三观不正、误导性内容

---

## 5. 数据设计

### 5.1 数据模型

见第3.5节Model层设计。

### 5.2 数据关系

```
User (用户)
  ↓ 1:N
Document (文档)
  ↓ 1:N
AuditRecord (审核记录)
  ↓ 0:N
Appeal (申诉记录)

SensitiveWord (敏感词库) - 独立管理
```

### 5.3 索引策略

| 集合名称 | 索引字段 | 索引类型 | 说明 |
|---------|---------|---------|------|
| audit_records | document_id | normal | 查询文档的审核记录 |
| audit_records | user_id + created_at | compound | 查询用户的审核历史 |
| audit_records | result + created_at | compound | 统计审核结果 |
| audit_records | content_hash | normal | 防重复审核 |
| sensitive_words | word | unique | 敏感词唯一索引 |
| sensitive_words | category + level | compound | 按分类和等级查询 |
| sensitive_words | is_enabled | normal | 查询启用的敏感词 |
| appeals | audit_id | normal | 关联审核记录 |
| appeals | status + created_at | compound | 查询待处理申诉 |

### 5.4 缓存策略

**Redis缓存**：
- **Key**: `audit:sensitive_words:all`
- **Value**: 所有启用的敏感词列表（JSON）
- **TTL**: 1小时
- **更新策略**: 敏感词库变更时主动刷新

---

## 6. 安全设计

### 6.1 权限控制

- **作者权限**：只能查看自己文档的审核记录和申诉
- **管理员权限**：可以管理敏感词库、处理申诉、查看所有审核记录
- **审核员权限**：可以处理申诉，但不能修改敏感词库

### 6.2 数据安全

- **敏感词库加密**：敏感词库存储时加密，防止泄露
- **审核内容脱敏**：审核记录中的内容仅保留哈希值，不保留原文
- **日志脱敏**：日志中不记录完整内容，仅记录关键信息

### 6.3 输入验证

- **内容长度限制**：实时检测最多10,000字，全文审核最多50,000字
- **频率限制**：同一用户每分钟最多50次实时检测请求
- **防刷机制**：相同内容1小时内不重复审核

### 6.4 审计日志

记录所有审核操作：
- 审核请求（用户、文档、时间）
- 审核结果（通过、警告、拒绝）
- 敏感词命中情况
- 申诉和复核操作

---

## 7. 性能优化

### 7.1 缓存优化

- **敏感词库缓存**：Redis缓存，1小时TTL
- **DFA树缓存**：内存缓存，敏感词库变更时重建
- **审核结果缓存**：相同内容的审核结果缓存1小时

### 7.2 并发优化

- **检测器并行**：DFA、正则、规则引擎并行检测
- **批量审核**：支持批量提交，后台异步处理
- **连接池**：MongoDB、Redis连接池复用

### 7.3 性能指标

- **实时检测延迟**：< 200ms (99th percentile)
- **全文审核延迟**：< 1s (99th percentile，不含AI）
- **并发处理能力**：500 QPS
- **敏感词库容量**：支持10万+敏感词

---

## 8. 测试设计

### 8.1 单元测试

**DFAMatcher测试**：
```go
func TestDFAMatcher_Match(t *testing.T) {
    words := []*models.SensitiveWord{
        {Word: "敏感词1", Level: "high", Category: "political"},
        {Word: "敏感词2", Level: "medium", Category: "porn"},
    }
    
    matcher := NewDFAMatcher()
    matcher.BuildTree(words)
    
    content := "这是一段包含敏感词1的内容"
    issues := matcher.Match(content, words)
    
    assert.Equal(t, 1, len(issues))
    assert.Equal(t, "敏感词1", issues[0].Content)
}
```

### 8.2 集成测试

**全文审核流程测试**：
```go
func TestContentAuditService_CheckFull(t *testing.T) {
    service := setupAuditService(t)
    
    req := &CheckFullRequest{
        DocumentId: "test-doc-1",
        Content: "测试内容...",
        CheckOptions: CheckOptions{
            EnableDFA:   true,
            EnableRegex: true,
        },
    }
    
    resp, err := service.CheckFull(context.Background(), req)
    
    assert.NoError(t, err)
    assert.NotEmpty(t, resp.AuditId)
    assert.Equal(t, "pass", resp.Result)
}
```

### 8.3 性能测试

**压力测试**：
- 并发用户：100
- 测试时长：5分钟
- 内容长度：1000-5000字
- 预期QPS：> 500

---

## 9. 监控和运维

### 9.1 监控指标

**业务指标**：
- 审核请求量（按时间、类型统计）
- 审核通过率、拒绝率、警告率
- 违规内容分布（按分类统计）
- 申诉量和处理时效

**技术指标**：
- API响应时间（P50、P95、P99）
- 错误率（按错误类型统计）
- 缓存命中率
- 检测器性能（DFA、正则、AI）

### 9.2 告警规则

- 审核拒绝率 > 10%（可能敏感词库配置过严）
- API错误率 > 1%
- 审核延迟 > 2s（P99）
- 待处理申诉 > 100

### 9.3 日志策略

**结构化日志**：
```json
{
  "level": "info",
  "service": "ContentAuditService",
  "operation": "CheckFull",
  "user_id": "user123",
  "document_id": "doc456",
  "result": "reject",
  "risk_level": "high",
  "issues_count": 3,
  "duration_ms": 150,
  "timestamp": "2025-10-17T10:30:00Z"
}
```

---

## 10. 实施计划

### 10.1 开发阶段

**Phase 1: 基础功能 (3天)**
- [ ] 数据模型设计和实现
- [ ] Repository层实现
- [ ] DFA匹配算法实现
- [ ] 实时检测API实现

**Phase 2: 完整审核 (3天)**
- [ ] 正则表达式匹配器实现
- [ ] 规则引擎实现
- [ ] 全文审核API实现
- [ ] 审核记录管理

**Phase 3: 管理功能 (2天)**
- [ ] 敏感词库管理API
- [ ] 申诉流程实现
- [ ] 管理后台集成

**Phase 4: 优化和测试 (2天)**
- [ ] 性能优化（缓存、并发）
- [ ] 单元测试和集成测试
- [ ] 压力测试和调优

**总计**: 10个工作日

### 10.2 测试阶段

- **单元测试**：每个组件独立测试
- **集成测试**：审核流程端到端测试
- **性能测试**：压力测试和性能调优
- **安全测试**：敏感词库泄露防护测试

### 10.3 上线计划

- **灰度发布**：先对部分用户开启审核功能
- **监控观察**：观察审核效果和性能表现
- **全量发布**：逐步开启全部用户的审核功能
- **回滚方案**：准备审核功能降级开关

---

## 11. 风险评估

### 11.1 技术风险

| 风险 | 影响 | 概率 | 应对措施 |
|-----|-----|-----|---------|
| DFA树构建耗时过长 | 高 | 中 | 异步构建，使用旧树继续服务 |
| 敏感词库过大影响性能 | 高 | 中 | 分级加载，高优先级词优先检测 |
| AI检测服务不稳定 | 中 | 高 | AI检测可选，失败不影响主流程 |
| 缓存失效导致性能下降 | 中 | 低 | 多级缓存，降级策略 |

### 11.2 业务风险

| 风险 | 影响 | 概率 | 应对措施 |
|-----|-----|-----|---------|
| 误杀正常内容 | 高 | 中 | 提供申诉流程，人工复核 |
| 敏感词库配置不当 | 高 | 中 | 分级管理，定期review |
| 漏检违规内容 | 高 | 中 | 多检测器组合，AI兜底 |
| 用户体验下降 | 中 | 低 | 实时提示，修改建议 |

### 11.3 合规风险

- **法律风险**：违规内容未及时处理
  - **应对**：建立7x24小时人工审核团队
- **隐私风险**：审核内容泄露
  - **应对**：内容脱敏，敏感词库加密
- **数据安全**：敏感词库被窃取
  - **应对**：访问控制，操作审计

---

## 12. 后续迭代

### 12.1 短期优化 (1-3个月)

- [ ] AI图片内容审核（调用第三方API）
- [ ] 敏感词变体自动识别
- [ ] 审核规则智能推荐
- [ ] 审核数据可视化报表

### 12.2 中期规划 (3-6个月)

- [ ] AI自动修正建议
- [ ] 实时协作审核（多人同时审核）
- [ ] 审核模型训练和优化
- [ ] 跨平台审核能力

### 12.3 长期愿景 (6-12个月)

- [ ] 自研AI审核模型
- [ ] 多语言审核支持
- [ ] 视频/音频内容审核
- [ ] 智能审核助手

---

## 13. 参考文档

- [写作端模块设计](./README_写作端模块设计文档总览.md)
- [编辑器系统设计](./编辑器系统设计.md)
- [AI服务架构设计](../ai/01.AI服务架构设计.md)
- [安全设计与威胁建模](../security/安全设计与威胁建模.md)
- [MongoDB应用层优化设计](../database/MongoDB应用层优化设计.md)

---

## 附录

### A. 敏感词分类体系

| 一级分类 | 二级分类 | 示例 |
|---------|---------|-----|
| 政治敏感 | 国家领导人 | ... |
| 政治敏感 | 政治事件 | ... |
| 色情低俗 | 露骨描写 | ... |
| 色情低俗 | 性暗示 | ... |
| 暴力血腥 | 暴力行为 | ... |
| 暴力血腥 | 血腥描写 | ... |
| 违法犯罪 | 毒品赌博 | ... |
| 违法犯罪 | 诈骗传销 | ... |
| 广告营销 | 联系方式 | ... |
| 广告营销 | 外部链接 | ... |

### B. 审核规则配置示例

```yaml
audit_rules:
  # 敏感词检测
  sensitive_word:
    enabled: true
    strictness: medium # low, medium, high
    categories:
      - political
      - porn
      - violence
  
  # 正则表达式检测
  regex:
    enabled: true
    patterns:
      - pattern: '1[3-9]\d{9}'
        category: contact
        level: medium
  
  # 规则引擎
  rule_engine:
    enabled: true
    rules:
      - name: frequent_repeat
        condition: word_repeat_count > 5
        level: low
      - name: special_char_ratio
        condition: special_char_ratio > 0.2
        level: medium
  
  # AI检测
  ai_detector:
    enabled: false # 默认关闭，按需开启
    model: "content-moderation-v1"
    threshold: 0.7
```

---

**文档状态**: ✅ 设计完成  
**最后更新**: 2025-10-17  
**下一步**: 进入开发阶段

